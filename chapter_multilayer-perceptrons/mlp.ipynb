{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3c32b742",
      "metadata": {
        "id": "3c32b742"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dce62645",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dce62645",
        "outputId": "0c5cfc7d-7c02-417c-9113-a835599fb27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l==1.0.3\n",
            "  Downloading d2l-1.0.3-py3-none-any.whl.metadata (556 bytes)\n",
            "Collecting jupyter==1.0.0 (from d2l==1.0.3)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "Collecting numpy==1.23.5 (from d2l==1.0.3)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting matplotlib==3.7.2 (from d2l==1.0.3)\n",
            "  Downloading matplotlib-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting matplotlib-inline==0.1.6 (from d2l==1.0.3)\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting requests==2.31.0 (from d2l==1.0.3)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pandas==2.0.3 (from d2l==1.0.3)\n",
            "  Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting scipy==1.10.1 (from d2l==1.0.3)\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.7)\n",
            "Collecting qtconsole (from jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading qtconsole-5.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (25.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (11.3.0)\n",
            "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib==3.7.2->d2l==1.0.3)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (2.9.0.post0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from matplotlib-inline==0.1.6->d2l==1.0.3) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (2025.7.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l==1.0.3) (1.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.4.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.0.15)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (2.19.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.8.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (25.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.1)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading QtPy-2.4.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.25.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l==1.0.3) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l==1.0.3) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.14.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.26.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.1)\n",
            "Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading matplotlib-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qtconsole-5.6.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.0/125.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading QtPy-2.4.3-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.0/95.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests, qtpy, pyparsing, numpy, matplotlib-inline, jedi, scipy, pandas, matplotlib, qtconsole, jupyter, d2l\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.3\n",
            "    Uninstalling pyparsing-3.2.3:\n",
            "      Successfully uninstalled pyparsing-3.2.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: matplotlib-inline\n",
            "    Found existing installation: matplotlib-inline 0.1.7\n",
            "    Uninstalling matplotlib-inline-0.1.7:\n",
            "      Successfully uninstalled matplotlib-inline-0.1.7\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.0\n",
            "    Uninstalling scipy-1.16.0:\n",
            "      Successfully uninstalled scipy-1.16.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "arviz 0.22.0 requires matplotlib>=3.8, but you have matplotlib 3.7.2 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "arviz 0.22.0 requires pandas>=2.1.0, but you have pandas 2.0.3 which is incompatible.\n",
            "arviz 0.22.0 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "geopandas 1.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "cvxpy 1.6.7 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.31.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\n",
            "chex 0.1.90 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.7.1 requires pandas>=2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 2.12.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed d2l-1.0.3 jedi-0.19.2 jupyter-1.0.0 matplotlib-3.7.2 matplotlib-inline-0.1.6 numpy-1.23.5 pandas-2.0.3 pyparsing-3.0.9 qtconsole-5.6.1 qtpy-2.4.3 requests-2.31.0 scipy-1.10.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "matplotlib_inline",
                  "mpl_toolkits",
                  "numpy",
                  "pyparsing"
                ]
              },
              "id": "e388774839b94edfb6e49834fd4d6ae7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install d2l==1.0.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cad96bd9",
      "metadata": {
        "origin_pos": 1,
        "id": "cad96bd9"
      },
      "source": [
        "# Multilayer Perceptrons\n",
        ":label:`sec_mlp`\n",
        "\n",
        "In :numref:`sec_softmax`, we introduced\n",
        "softmax regression,\n",
        "implementing the algorithm from scratch\n",
        "(:numref:`sec_softmax_scratch`) and using high-level APIs\n",
        "(:numref:`sec_softmax_concise`). This allowed us to\n",
        "train classifiers capable of recognizing\n",
        "10 categories of clothing from low-resolution images.\n",
        "Along the way, we learned how to wrangle data,\n",
        "coerce our outputs into a valid probability distribution,\n",
        "apply an appropriate loss function,\n",
        "and minimize it with respect to our model's parameters.\n",
        "Now that we have mastered these mechanics\n",
        "in the context of simple linear models,\n",
        "we can launch our exploration of deep neural networks,\n",
        "the comparatively rich class of models\n",
        "with which this book is primarily concerned.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cec00ab5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:38:40.016291Z",
          "iopub.status.busy": "2023-08-18T19:38:40.015244Z",
          "iopub.status.idle": "2023-08-18T19:38:43.744461Z",
          "shell.execute_reply": "2023-08-18T19:38:43.741144Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "cec00ab5"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77e62e41",
      "metadata": {
        "origin_pos": 6,
        "id": "77e62e41"
      },
      "source": [
        "## Hidden Layers\n",
        "\n",
        "We described affine transformations in\n",
        ":numref:`subsec_linear_model` as\n",
        "linear transformations with added bias.\n",
        "To begin, recall the model architecture\n",
        "corresponding to our softmax regression example,\n",
        "illustrated in  :numref:`fig_softmaxreg`.\n",
        "This model maps inputs directly to outputs\n",
        "via a single affine transformation,\n",
        "followed by a softmax operation.\n",
        "If our labels truly were related\n",
        "to the input data by a simple affine transformation,\n",
        "then this approach would be sufficient.\n",
        "However, linearity (in affine transformations) is a *strong* assumption.\n",
        "\n",
        "### Limitations of Linear Models\n",
        "\n",
        "For example, linearity implies the *weaker*\n",
        "assumption of *monotonicity*, i.e.,\n",
        "that any increase in our feature must\n",
        "either always cause an increase in our model's output\n",
        "(if the corresponding weight is positive),\n",
        "or always cause a decrease in our model's output\n",
        "(if the corresponding weight is negative).\n",
        "Sometimes that makes sense.\n",
        "For example, if we were trying to predict\n",
        "whether an individual will repay a loan,\n",
        "we might reasonably assume that all other things being equal,\n",
        "an applicant with a higher income\n",
        "would always be more likely to repay\n",
        "than one with a lower income.\n",
        "While monotonic, this relationship likely\n",
        "is not linearly associated with the probability of\n",
        "repayment. An increase in income from \\$0 to \\$50,000\n",
        "likely corresponds to a bigger increase\n",
        "in likelihood of repayment\n",
        "than an increase from \\$1 million to \\$1.05 million.\n",
        "One way to handle this might be to postprocess our outcome\n",
        "such that linearity becomes more plausible,\n",
        "by using the logistic map (and thus the logarithm of the probability of outcome).\n",
        "\n",
        "Note that we can easily come up with examples\n",
        "that violate monotonicity.\n",
        "Say for example that we want to predict health as a function\n",
        "of body temperature.\n",
        "For individuals with a normal body temperature\n",
        "above 37°C (98.6°F),\n",
        "higher temperatures indicate greater risk.\n",
        "However, if the body temperatures drops\n",
        "below 37°C, lower temperatures indicate greater risk!\n",
        "Again, we might resolve the problem\n",
        "with some clever preprocessing, such as using the distance from 37°C\n",
        "as a feature.\n",
        "\n",
        "\n",
        "But what about classifying images of cats and dogs?\n",
        "Should increasing the intensity\n",
        "of the pixel at location (13, 17)\n",
        "always increase (or always decrease)\n",
        "the likelihood that the image depicts a dog?\n",
        "Reliance on a linear model corresponds to the implicit\n",
        "assumption that the only requirement\n",
        "for differentiating cats and dogs is to assess\n",
        "the brightness of individual pixels.\n",
        "This approach is doomed to fail in a world\n",
        "where inverting an image preserves the category.\n",
        "\n",
        "And yet despite the apparent absurdity of linearity here,\n",
        "as compared with our previous examples,\n",
        "it is less obvious that we could address the problem\n",
        "with a simple preprocessing fix.\n",
        "That is, because the significance of any pixel\n",
        "depends in complex ways on its context\n",
        "(the values of the surrounding pixels).\n",
        "While there might exist a representation of our data\n",
        "that would take into account\n",
        "the relevant interactions among our features,\n",
        "on top of which a linear model would be suitable,\n",
        "we simply do not know how to calculate it by hand.\n",
        "With deep neural networks, we used observational data\n",
        "to jointly learn both a representation via hidden layers\n",
        "and a linear predictor that acts upon that representation.\n",
        "\n",
        "This problem of nonlinearity has been studied for at least a\n",
        "century :cite:`Fisher.1928`. For instance, decision trees\n",
        "in their most basic form use a sequence of binary decisions to\n",
        "decide upon class membership :cite:`quinlan2014c4`. Likewise, kernel\n",
        "methods have been used for many decades to model nonlinear dependencies\n",
        ":cite:`Aronszajn.1950`. This has found its way into\n",
        "nonparametric spline models :cite:`Wahba.1990` and kernel methods\n",
        ":cite:`Scholkopf.Smola.2002`. It is also something that the brain solves\n",
        "quite naturally. After all, neurons feed into other neurons which,\n",
        "in turn, feed into other neurons again :cite:`Cajal.Azoulay.1894`.\n",
        "Consequently we have a sequence of relatively simple transformations.\n",
        "\n",
        "### Incorporating Hidden Layers\n",
        "\n",
        "We can overcome the limitations of linear models\n",
        "by incorporating one or more hidden layers.\n",
        "The easiest way to do this is to stack\n",
        "many fully connected layers on top of one another.\n",
        "Each layer feeds into the layer above it,\n",
        "until we generate outputs.\n",
        "We can think of the first $L-1$ layers\n",
        "as our representation and the final layer\n",
        "as our linear predictor.\n",
        "This architecture is commonly called\n",
        "a *multilayer perceptron*,\n",
        "often abbreviated as *MLP* (:numref:`fig_mlp`).\n",
        "\n",
        "![An MLP with a hidden layer of five hidden units.](http://d2l.ai/_images/mlp.svg)\n",
        ":label:`fig_mlp`\n",
        "\n",
        "This MLP has four inputs, three outputs,\n",
        "and its hidden layer contains five hidden units.\n",
        "Since the input layer does not involve any calculations,\n",
        "producing outputs with this network\n",
        "requires implementing the computations\n",
        "for both the hidden and output layers;\n",
        "thus, the number of layers in this MLP is two.\n",
        "Note that both layers are fully connected.\n",
        "Every input influences every neuron in the hidden layer,\n",
        "and each of these in turn influences\n",
        "every neuron in the output layer. Alas, we are not quite\n",
        "done yet.\n",
        "\n",
        "### From Linear to Nonlinear\n",
        "\n",
        "As before, we denote by the matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$\n",
        "a minibatch of $n$ examples where each example has $d$ inputs (features).\n",
        "For a one-hidden-layer MLP whose hidden layer has $h$ hidden units,\n",
        "we denote by $\\mathbf{H} \\in \\mathbb{R}^{n \\times h}$\n",
        "the outputs of the hidden layer, which are\n",
        "*hidden representations*.\n",
        "Since the hidden and output layers are both fully connected,\n",
        "we have hidden-layer weights $\\mathbf{W}^{(1)} \\in \\mathbb{R}^{d \\times h}$ and biases $\\mathbf{b}^{(1)} \\in \\mathbb{R}^{1 \\times h}$\n",
        "and output-layer weights $\\mathbf{W}^{(2)} \\in \\mathbb{R}^{h \\times q}$ and biases $\\mathbf{b}^{(2)} \\in \\mathbb{R}^{1 \\times q}$.\n",
        "This allows us to calculate the outputs $\\mathbf{O} \\in \\mathbb{R}^{n \\times q}$\n",
        "of the one-hidden-layer MLP as follows:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    \\mathbf{H} & = \\mathbf{X} \\mathbf{W}^{(1)} + \\mathbf{b}^{(1)}, \\\\\n",
        "    \\mathbf{O} & = \\mathbf{H}\\mathbf{W}^{(2)} + \\mathbf{b}^{(2)}.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Note that after adding the hidden layer,\n",
        "our model now requires us to track and update\n",
        "additional sets of parameters.\n",
        "So what have we gained in exchange?\n",
        "You might be surprised to find out\n",
        "that---in the model defined above---*we\n",
        "gain nothing for our troubles*!\n",
        "The reason is plain.\n",
        "The hidden units above are given by\n",
        "an affine function of the inputs,\n",
        "and the outputs (pre-softmax) are just\n",
        "an affine function of the hidden units.\n",
        "An affine function of an affine function\n",
        "is itself an affine function.\n",
        "Moreover, our linear model was already\n",
        "capable of representing any affine function.\n",
        "\n",
        "To see this formally we can just collapse out the hidden layer in the above definition,\n",
        "yielding an equivalent single-layer model with parameters\n",
        "$\\mathbf{W} = \\mathbf{W}^{(1)}\\mathbf{W}^{(2)}$ and $\\mathbf{b} = \\mathbf{b}^{(1)} \\mathbf{W}^{(2)} + \\mathbf{b}^{(2)}$:\n",
        "\n",
        "$$\n",
        "\\mathbf{O} = (\\mathbf{X} \\mathbf{W}^{(1)} + \\mathbf{b}^{(1)})\\mathbf{W}^{(2)} + \\mathbf{b}^{(2)} = \\mathbf{X} \\mathbf{W}^{(1)}\\mathbf{W}^{(2)} + \\mathbf{b}^{(1)} \\mathbf{W}^{(2)} + \\mathbf{b}^{(2)} = \\mathbf{X} \\mathbf{W} + \\mathbf{b}.\n",
        "$$\n",
        "\n",
        "In order to realize the potential of multilayer architectures,\n",
        "we need one more key ingredient: a\n",
        "nonlinear *activation function* $\\sigma$\n",
        "to be applied to each hidden unit\n",
        "following the affine transformation. For instance, a popular\n",
        "choice is the ReLU (rectified linear unit) activation function :cite:`Nair.Hinton.2010`\n",
        "$\\sigma(x) = \\mathrm{max}(0, x)$ operating on its arguments elementwise.\n",
        "The outputs of activation functions $\\sigma(\\cdot)$\n",
        "are called *activations*.\n",
        "In general, with activation functions in place,\n",
        "it is no longer possible to collapse our MLP into a linear model:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    \\mathbf{H} & = \\sigma(\\mathbf{X} \\mathbf{W}^{(1)} + \\mathbf{b}^{(1)}), \\\\\n",
        "    \\mathbf{O} & = \\mathbf{H}\\mathbf{W}^{(2)} + \\mathbf{b}^{(2)}.\\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Since each row in $\\mathbf{X}$ corresponds to an example in the minibatch,\n",
        "with some abuse of notation, we define the nonlinearity\n",
        "$\\sigma$ to apply to its inputs in a rowwise fashion,\n",
        "i.e., one example at a time.\n",
        "Note that we used the same notation for softmax\n",
        "when we denoted a rowwise operation in :numref:`subsec_softmax_vectorization`.\n",
        "Quite frequently the activation functions we use apply not merely rowwise but\n",
        "elementwise. That means that after computing the linear portion of the layer,\n",
        "we can calculate each activation\n",
        "without looking at the values taken by the other hidden units.\n",
        "\n",
        "To build more general MLPs, we can continue stacking\n",
        "such hidden layers,\n",
        "e.g., $\\mathbf{H}^{(1)} = \\sigma_1(\\mathbf{X} \\mathbf{W}^{(1)} + \\mathbf{b}^{(1)})$\n",
        "and $\\mathbf{H}^{(2)} = \\sigma_2(\\mathbf{H}^{(1)} \\mathbf{W}^{(2)} + \\mathbf{b}^{(2)})$,\n",
        "one atop another, yielding ever more expressive models.\n",
        "\n",
        "### Universal Approximators\n",
        "\n",
        "We know that the brain is capable of very sophisticated statistical analysis. As such,\n",
        "it is worth asking, just *how powerful* a deep network could be. This question\n",
        "has been answered multiple times, e.g., in :citet:`Cybenko.1989` in the context\n",
        "of MLPs, and in :citet:`micchelli1984interpolation` in the context of reproducing kernel\n",
        "Hilbert spaces in a way that could be seen as radial basis function (RBF) networks with a single hidden layer.\n",
        "These (and related results) suggest that even with a single-hidden-layer network,\n",
        "given enough nodes (possibly absurdly many),\n",
        "and the right set of weights,\n",
        "we can model any function.\n",
        "Actually learning that function is the hard part, though.\n",
        "You might think of your neural network\n",
        "as being a bit like the C programming language.\n",
        "The language, like any other modern language,\n",
        "is capable of expressing any computable program.\n",
        "But actually coming up with a program\n",
        "that meets your specifications is the hard part.\n",
        "\n",
        "Moreover, just because a single-hidden-layer network\n",
        "*can* learn any function\n",
        "does not mean that you should try\n",
        "to solve all of your problems\n",
        "with one. In fact, in this case kernel methods\n",
        "are way more effective, since they are capable of solving the problem\n",
        "*exactly* even in infinite dimensional spaces :cite:`Kimeldorf.Wahba.1971,Scholkopf.Herbrich.Smola.2001`.\n",
        "In fact, we can approximate many functions\n",
        "much more compactly by using deeper (rather than wider) networks :cite:`Simonyan.Zisserman.2014`.\n",
        "We will touch upon more rigorous arguments in subsequent chapters.\n",
        "\n",
        "\n",
        "## Activation Functions\n",
        ":label:`subsec_activation-functions`\n",
        "\n",
        "Activation functions decide whether a neuron should be activated or not by\n",
        "calculating the weighted sum and further adding bias to it.\n",
        "They are differentiable operators for transforming input signals to outputs,\n",
        "while most of them add nonlinearity.\n",
        "Because activation functions are fundamental to deep learning,\n",
        "(**let's briefly survey some common ones**).\n",
        "\n",
        "### ReLU Function\n",
        "\n",
        "The most popular choice,\n",
        "due to both simplicity of implementation and\n",
        "its good performance on a variety of predictive tasks,\n",
        "is the *rectified linear unit* (*ReLU*) :cite:`Nair.Hinton.2010`.\n",
        "[**ReLU provides a very simple nonlinear transformation**].\n",
        "Given an element $x$, the function is defined\n",
        "as the maximum of that element and $0$:\n",
        "\n",
        "$$\\operatorname{ReLU}(x) = \\max(x, 0).$$\n",
        "\n",
        "Informally, the ReLU function retains only positive\n",
        "elements and discards all negative elements\n",
        "by setting the corresponding activations to 0.\n",
        "To gain some intuition, we can plot the function.\n",
        "As you can see, the activation function is piecewise linear.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5881b40d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:38:43.749925Z",
          "iopub.status.busy": "2023-08-18T19:38:43.748740Z",
          "iopub.status.idle": "2023-08-18T19:38:44.145067Z",
          "shell.execute_reply": "2023-08-18T19:38:44.143027Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5881b40d",
        "outputId": "c3fdc354-693a-41e7-fbf4-def6cb2d221c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"320.440625pt\" height=\"183.35625pt\" viewBox=\"0 0 320.440625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-08-06T00:16:02.947142</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 320.440625 183.35625 \nL 320.440625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 34.240625 145.8 \nL 313.240625 145.8 \nL 313.240625 7.2 \nL 34.240625 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 46.922443 145.8 \nL 46.922443 7.2 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"m355636e68b\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m355636e68b\" x=\"46.922443\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −8 -->\n      <g transform=\"translate(39.551349 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 78.826389 145.8 \nL 78.826389 7.2 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m355636e68b\" x=\"78.826389\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −6 -->\n      <g transform=\"translate(71.455295 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 110.730335 145.8 \nL 110.730335 7.2 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m355636e68b\" x=\"110.730335\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −4 -->\n      <g transform=\"translate(103.359241 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 142.634281 145.8 \nL 142.634281 7.2 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m355636e68b\" x=\"142.634281\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- −2 -->\n      <g transform=\"translate(135.263187 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 174.538227 145.8 \nL 174.538227 7.2 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m355636e68b\" x=\"174.538227\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0 -->\n      <g transform=\"translate(171.356977 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 206.442173 145.8 \nL 206.442173 7.2 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m355636e68b\" x=\"206.442173\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2 -->\n      <g transform=\"translate(203.260923 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path d=\"M 238.346118 145.8 \nL 238.346118 7.2 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m355636e68b\" x=\"238.346118\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4 -->\n      <g transform=\"translate(235.164868 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path d=\"M 270.250064 145.8 \nL 270.250064 7.2 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m355636e68b\" x=\"270.250064\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 6 -->\n      <g transform=\"translate(267.068814 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_17\">\n      <path d=\"M 302.15401 145.8 \nL 302.15401 7.2 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#m355636e68b\" x=\"302.15401\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 8 -->\n      <g transform=\"translate(298.97276 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- x -->\n     <g transform=\"translate(170.78125 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \nL 2247 1797 \nL 3578 0 \nL 2900 0 \nL 1881 1375 \nL 863 0 \nL 184 0 \nL 1544 1831 \nL 300 3500 \nL 978 3500 \nL 1906 2253 \nL 2834 3500 \nL 3513 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-78\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_19\">\n      <path d=\"M 34.240625 139.5 \nL 313.240625 139.5 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <defs>\n       <path id=\"mbecabb010c\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mbecabb010c\" x=\"34.240625\" y=\"139.5\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0 -->\n      <g transform=\"translate(20.878125 143.299219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_21\">\n      <path d=\"M 34.240625 107.601264 \nL 313.240625 107.601264 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use xlink:href=\"#mbecabb010c\" x=\"34.240625\" y=\"107.601264\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 2 -->\n      <g transform=\"translate(20.878125 111.400483) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_23\">\n      <path d=\"M 34.240625 75.702529 \nL 313.240625 75.702529 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use xlink:href=\"#mbecabb010c\" x=\"34.240625\" y=\"75.702529\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 4 -->\n      <g transform=\"translate(20.878125 79.501747) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_25\">\n      <path d=\"M 34.240625 43.803793 \nL 313.240625 43.803793 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use xlink:href=\"#mbecabb010c\" x=\"34.240625\" y=\"43.803793\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 6 -->\n      <g transform=\"translate(20.878125 47.603012) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_27\">\n      <path d=\"M 34.240625 11.905057 \nL 313.240625 11.905057 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use xlink:href=\"#mbecabb010c\" x=\"34.240625\" y=\"11.905057\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 8 -->\n      <g transform=\"translate(20.878125 15.704276) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- relu(x) -->\n     <g transform=\"translate(14.798438 92.938281) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"38.863281\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"100.386719\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"128.169922\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"191.548828\"/>\n      <use xlink:href=\"#DejaVuSans-78\" x=\"230.5625\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"289.742188\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 46.922443 139.5 \nL 174.538227 139.5 \nL 300.558807 13.5 \nL 300.558807 13.5 \n\" clip-path=\"url(#pbf637738e6)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 34.240625 145.8 \nL 34.240625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 313.240625 145.8 \nL 313.240625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 34.240625 145.8 \nL 313.240625 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 34.240625 7.2 \nL 313.240625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pbf637738e6\">\n   <rect x=\"34.240625\" y=\"7.2\" width=\"279\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)\n",
        "y = torch.relu(x)\n",
        "d2l.plot(x.detach(), y.detach(), 'x', 'relu(x)', figsize=(5, 2.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afa62b43",
      "metadata": {
        "origin_pos": 11,
        "id": "afa62b43"
      },
      "source": [
        "When the input is negative,\n",
        "the derivative of the ReLU function is 0,\n",
        "and when the input is positive,\n",
        "the derivative of the ReLU function is 1.\n",
        "Note that the ReLU function is not differentiable\n",
        "when the input takes value precisely equal to 0.\n",
        "In these cases, we default to the left-hand-side\n",
        "derivative and say that the derivative is 0 when the input is 0.\n",
        "We can get away with this because\n",
        "the input may never actually be zero (mathematicians would\n",
        "say that it is nondifferentiable on a set of measure zero).\n",
        "There is an old adage that if subtle boundary conditions matter,\n",
        "we are probably doing (*real*) mathematics, not engineering.\n",
        "That conventional wisdom may apply here, or at least, the fact that\n",
        "we are not performing constrained optimization :cite:`Mangasarian.1965,Rockafellar.1970`.\n",
        "We plot the derivative of the ReLU function below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1d36fda0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:38:44.152064Z",
          "iopub.status.busy": "2023-08-18T19:38:44.150649Z",
          "iopub.status.idle": "2023-08-18T19:38:44.554556Z",
          "shell.execute_reply": "2023-08-18T19:38:44.552066Z"
        },
        "origin_pos": 13,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "1d36fda0",
        "outputId": "08dcf88b-7ebe-4c66-aed5-6899710d0591"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"329.98125pt\" height=\"183.35625pt\" viewBox=\"0 0 329.98125 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-08-06T00:16:27.671079</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 329.98125 183.35625 \nL 329.98125 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 145.8 \nL 322.78125 145.8 \nL 322.78125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 56.463068 145.8 \nL 56.463068 7.2 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"mbb14324113\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mbb14324113\" x=\"56.463068\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −8 -->\n      <g transform=\"translate(49.091974 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 88.367014 145.8 \nL 88.367014 7.2 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mbb14324113\" x=\"88.367014\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −6 -->\n      <g transform=\"translate(80.99592 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 120.27096 145.8 \nL 120.27096 7.2 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mbb14324113\" x=\"120.27096\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −4 -->\n      <g transform=\"translate(112.899866 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 152.174906 145.8 \nL 152.174906 7.2 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mbb14324113\" x=\"152.174906\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- −2 -->\n      <g transform=\"translate(144.803812 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 184.078852 145.8 \nL 184.078852 7.2 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mbb14324113\" x=\"184.078852\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0 -->\n      <g transform=\"translate(180.897602 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 215.982798 145.8 \nL 215.982798 7.2 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#mbb14324113\" x=\"215.982798\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2 -->\n      <g transform=\"translate(212.801548 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path d=\"M 247.886743 145.8 \nL 247.886743 7.2 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#mbb14324113\" x=\"247.886743\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4 -->\n      <g transform=\"translate(244.705493 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path d=\"M 279.790689 145.8 \nL 279.790689 7.2 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#mbb14324113\" x=\"279.790689\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 6 -->\n      <g transform=\"translate(276.609439 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_17\">\n      <path d=\"M 311.694635 145.8 \nL 311.694635 7.2 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#mbb14324113\" x=\"311.694635\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 8 -->\n      <g transform=\"translate(308.513385 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- x -->\n     <g transform=\"translate(180.321875 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \nL 2247 1797 \nL 3578 0 \nL 2900 0 \nL 1881 1375 \nL 863 0 \nL 184 0 \nL 1544 1831 \nL 300 3500 \nL 978 3500 \nL 1906 2253 \nL 2834 3500 \nL 3513 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-78\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_19\">\n      <path d=\"M 43.78125 139.5 \nL 322.78125 139.5 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <defs>\n       <path id=\"mb74772a0e3\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mb74772a0e3\" x=\"43.78125\" y=\"139.5\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 143.299219) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_21\">\n      <path d=\"M 43.78125 114.3 \nL 322.78125 114.3 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use xlink:href=\"#mb74772a0e3\" x=\"43.78125\" y=\"114.3\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 118.099219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_23\">\n      <path d=\"M 43.78125 89.1 \nL 322.78125 89.1 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use xlink:href=\"#mb74772a0e3\" x=\"43.78125\" y=\"89.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 92.899219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_25\">\n      <path d=\"M 43.78125 63.9 \nL 322.78125 63.9 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use xlink:href=\"#mb74772a0e3\" x=\"43.78125\" y=\"63.9\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 67.699219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_27\">\n      <path d=\"M 43.78125 38.7 \nL 322.78125 38.7 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use xlink:href=\"#mb74772a0e3\" x=\"43.78125\" y=\"38.7\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 42.499219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_29\">\n      <path d=\"M 43.78125 13.5 \nL 322.78125 13.5 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_30\">\n      <g>\n       <use xlink:href=\"#mb74772a0e3\" x=\"43.78125\" y=\"13.5\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 17.299219) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- grad of relu -->\n     <g transform=\"translate(14.798438 105.542969) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-67\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"104.589844\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"165.869141\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"229.345703\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"261.132812\"/>\n      <use xlink:href=\"#DejaVuSans-66\" x=\"322.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"357.519531\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"389.306641\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"428.169922\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"489.693359\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"517.476562\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 56.463068 139.5 \nL 182.483654 139.5 \nL 184.078852 13.5 \nL 310.099432 13.5 \nL 310.099432 13.5 \n\" clip-path=\"url(#pe6ac8c6e83)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 145.8 \nL 43.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 322.78125 145.8 \nL 322.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 145.8 \nL 322.78125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 322.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe6ac8c6e83\">\n   <rect x=\"43.78125\" y=\"7.2\" width=\"279\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "y.backward(torch.ones_like(x), retain_graph=True)\n",
        "d2l.plot(x.detach(), x.grad, 'x', 'grad of relu', figsize=(5, 2.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27673d35",
      "metadata": {
        "origin_pos": 16,
        "id": "27673d35"
      },
      "source": [
        "The reason for using ReLU is that\n",
        "its derivatives are particularly well behaved:\n",
        "either they vanish or they just let the argument through.\n",
        "This makes optimization better behaved\n",
        "and it mitigated the well-documented problem\n",
        "of vanishing gradients that plagued\n",
        "previous versions of neural networks (more on this later).\n",
        "\n",
        "Note that there are many variants to the ReLU function,\n",
        "including the *parametrized ReLU* (*pReLU*) function :cite:`He.Zhang.Ren.ea.2015`.\n",
        "This variation adds a linear term to ReLU,\n",
        "so some information still gets through,\n",
        "even when the argument is negative:\n",
        "\n",
        "$$\\operatorname{pReLU}(x) = \\max(0, x) + \\alpha \\min(0, x).$$\n",
        "\n",
        "### Sigmoid Function\n",
        "\n",
        "[**The *sigmoid function* transforms those inputs**]\n",
        "whose values lie in the domain $\\mathbb{R}$,\n",
        "(**to outputs that lie on the interval (0, 1).**)\n",
        "For that reason, the sigmoid is\n",
        "often called a *squashing function*:\n",
        "it squashes any input in the range (-inf, inf)\n",
        "to some value in the range (0, 1):\n",
        "\n",
        "$$\\operatorname{sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}.$$\n",
        "\n",
        "In the earliest neural networks, scientists\n",
        "were interested in modeling biological neurons\n",
        "that either *fire* or *do not fire*.\n",
        "Thus the pioneers of this field,\n",
        "going all the way back to McCulloch and Pitts,\n",
        "the inventors of the artificial neuron,\n",
        "focused on thresholding units :cite:`McCulloch.Pitts.1943`.\n",
        "A thresholding activation takes value 0\n",
        "when its input is below some threshold\n",
        "and value 1 when the input exceeds the threshold.\n",
        "\n",
        "When attention shifted to gradient-based learning,\n",
        "the sigmoid function was a natural choice\n",
        "because it is a smooth, differentiable\n",
        "approximation to a thresholding unit.\n",
        "Sigmoids are still widely used as\n",
        "activation functions on the output units\n",
        "when we want to interpret the outputs as probabilities\n",
        "for binary classification problems: you can think of the sigmoid as a special case of the softmax.\n",
        "However, the sigmoid has largely been replaced\n",
        "by the simpler and more easily trainable ReLU\n",
        "for most use in hidden layers. Much of this has to do\n",
        "with the fact that the sigmoid poses challenges for optimization\n",
        ":cite:`LeCun.Bottou.Orr.ea.1998` since its gradient vanishes for large positive *and* negative arguments.\n",
        "This can lead to plateaus that are difficult to escape from.\n",
        "Nonetheless sigmoids are important. In later chapters (e.g., :numref:`sec_lstm`) on recurrent neural networks,\n",
        "we will describe architectures that leverage sigmoid units\n",
        "to control the flow of information across time.\n",
        "\n",
        "Below, we plot the sigmoid function.\n",
        "Note that when the input is close to 0,\n",
        "the sigmoid function approaches\n",
        "a linear transformation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f75a16d6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:38:44.563423Z",
          "iopub.status.busy": "2023-08-18T19:38:44.559371Z",
          "iopub.status.idle": "2023-08-18T19:38:44.872663Z",
          "shell.execute_reply": "2023-08-18T19:38:44.870181Z"
        },
        "origin_pos": 18,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "f75a16d6",
        "outputId": "27d1621c-b699-464c-be4b-86507f461e1b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"329.98125pt\" height=\"183.35625pt\" viewBox=\"0 0 329.98125 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-08-06T00:25:01.606950</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 329.98125 183.35625 \nL 329.98125 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 145.8 \nL 322.78125 145.8 \nL 322.78125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 56.463068 145.8 \nL 56.463068 7.2 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"m8a4e791b21\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m8a4e791b21\" x=\"56.463068\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −8 -->\n      <g transform=\"translate(49.091974 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 88.367014 145.8 \nL 88.367014 7.2 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m8a4e791b21\" x=\"88.367014\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −6 -->\n      <g transform=\"translate(80.99592 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 120.27096 145.8 \nL 120.27096 7.2 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m8a4e791b21\" x=\"120.27096\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −4 -->\n      <g transform=\"translate(112.899866 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 152.174906 145.8 \nL 152.174906 7.2 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m8a4e791b21\" x=\"152.174906\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- −2 -->\n      <g transform=\"translate(144.803812 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 184.078852 145.8 \nL 184.078852 7.2 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m8a4e791b21\" x=\"184.078852\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0 -->\n      <g transform=\"translate(180.897602 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 215.982798 145.8 \nL 215.982798 7.2 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m8a4e791b21\" x=\"215.982798\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2 -->\n      <g transform=\"translate(212.801548 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path d=\"M 247.886743 145.8 \nL 247.886743 7.2 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m8a4e791b21\" x=\"247.886743\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4 -->\n      <g transform=\"translate(244.705493 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path d=\"M 279.790689 145.8 \nL 279.790689 7.2 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m8a4e791b21\" x=\"279.790689\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 6 -->\n      <g transform=\"translate(276.609439 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_17\">\n      <path d=\"M 311.694635 145.8 \nL 311.694635 7.2 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#m8a4e791b21\" x=\"311.694635\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 8 -->\n      <g transform=\"translate(308.513385 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- x -->\n     <g transform=\"translate(180.321875 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \nL 2247 1797 \nL 3578 0 \nL 2900 0 \nL 1881 1375 \nL 863 0 \nL 184 0 \nL 1544 1831 \nL 300 3500 \nL 978 3500 \nL 1906 2253 \nL 2834 3500 \nL 3513 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-78\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_19\">\n      <path d=\"M 43.78125 139.542284 \nL 322.78125 139.542284 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <defs>\n       <path id=\"m7c91facaf2\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m7c91facaf2\" x=\"43.78125\" y=\"139.542284\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 143.341503) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_21\">\n      <path d=\"M 43.78125 114.324481 \nL 322.78125 114.324481 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use xlink:href=\"#m7c91facaf2\" x=\"43.78125\" y=\"114.324481\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 118.1237) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_23\">\n      <path d=\"M 43.78125 89.106678 \nL 322.78125 89.106678 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use xlink:href=\"#m7c91facaf2\" x=\"43.78125\" y=\"89.106678\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 92.905897) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_25\">\n      <path d=\"M 43.78125 63.888875 \nL 322.78125 63.888875 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use xlink:href=\"#m7c91facaf2\" x=\"43.78125\" y=\"63.888875\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 67.688094) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_27\">\n      <path d=\"M 43.78125 38.671072 \nL 322.78125 38.671072 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use xlink:href=\"#m7c91facaf2\" x=\"43.78125\" y=\"38.671072\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 42.47029) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_29\">\n      <path d=\"M 43.78125 13.453269 \nL 322.78125 13.453269 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_30\">\n      <g>\n       <use xlink:href=\"#m7c91facaf2\" x=\"43.78125\" y=\"13.453269\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 17.252487) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- sigmoid(x) -->\n     <g transform=\"translate(14.798438 103.021875) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-73\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"52.099609\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"79.882812\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"143.359375\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"240.771484\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"301.953125\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"329.736328\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"393.212891\"/>\n      <use xlink:href=\"#DejaVuSans-78\" x=\"432.226562\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"491.40625\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 56.463068 139.5 \nL 81.986223 139.333127 \nL 96.343001 139.029084 \nL 105.914183 138.610292 \nL 113.890169 138.013022 \nL 120.27096 137.27442 \nL 125.056551 136.500132 \nL 129.842142 135.470181 \nL 133.032538 134.603917 \nL 136.222933 133.562402 \nL 139.413328 132.314335 \nL 142.60372 130.82469 \nL 145.794115 129.055121 \nL 148.98451 126.964844 \nL 152.174906 124.512105 \nL 155.365299 121.656424 \nL 158.555695 118.361648 \nL 161.74609 114.599846 \nL 164.936483 110.355802 \nL 168.126879 105.631724 \nL 171.317273 100.451472 \nL 174.507668 94.863434 \nL 179.29326 85.884159 \nL 193.650036 58.132118 \nL 196.84043 52.54408 \nL 200.030825 47.363825 \nL 203.22122 42.639745 \nL 206.411613 38.395703 \nL 209.602009 34.633906 \nL 212.792404 31.339138 \nL 215.982798 28.483454 \nL 219.173193 26.030706 \nL 222.363588 23.94043 \nL 225.553984 22.170862 \nL 228.744379 20.681217 \nL 231.934771 19.433149 \nL 235.125166 18.391638 \nL 238.315561 17.525365 \nL 243.101152 16.495419 \nL 247.886743 15.721136 \nL 254.267534 14.982536 \nL 260.648325 14.482478 \nL 268.624311 14.079535 \nL 279.790689 13.765034 \nL 295.742662 13.568135 \nL 310.099432 13.5 \nL 310.099432 13.5 \n\" clip-path=\"url(#p5194cb3cae)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 145.8 \nL 43.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 322.78125 145.8 \nL 322.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 145.8 \nL 322.78125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 322.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p5194cb3cae\">\n   <rect x=\"43.78125\" y=\"7.2\" width=\"279\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "y = torch.sigmoid(x)\n",
        "d2l.plot(x.detach(), y.detach(), 'x', 'sigmoid(x)', figsize=(5, 2.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae860f1",
      "metadata": {
        "origin_pos": 21,
        "id": "bae860f1"
      },
      "source": [
        "The derivative of the sigmoid function is given by the following equation:\n",
        "\n",
        "$$\\frac{d}{dx} \\operatorname{sigmoid}(x) = \\frac{\\exp(-x)}{(1 + \\exp(-x))^2} = \\operatorname{sigmoid}(x)\\left(1-\\operatorname{sigmoid}(x)\\right).$$\n",
        "\n",
        "\n",
        "The derivative of the sigmoid function is plotted below.\n",
        "Note that when the input is 0,\n",
        "the derivative of the sigmoid function\n",
        "reaches a maximum of 0.25.\n",
        "As the input diverges from 0 in either direction,\n",
        "the derivative approaches 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c4cc9493",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:38:44.878332Z",
          "iopub.status.busy": "2023-08-18T19:38:44.877535Z",
          "iopub.status.idle": "2023-08-18T19:38:45.347828Z",
          "shell.execute_reply": "2023-08-18T19:38:45.346820Z"
        },
        "origin_pos": 23,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "c4cc9493",
        "outputId": "99447859-3d15-44ef-9b02-253e029ab0e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"336.34375pt\" height=\"183.35625pt\" viewBox=\"0 0 336.34375 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-08-06T00:25:28.395727</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 336.34375 183.35625 \nL 336.34375 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 145.8 \nL 329.14375 145.8 \nL 329.14375 7.2 \nL 50.14375 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 62.825568 145.8 \nL 62.825568 7.2 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"m4caf11f971\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m4caf11f971\" x=\"62.825568\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −8 -->\n      <g transform=\"translate(55.454474 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 94.729514 145.8 \nL 94.729514 7.2 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m4caf11f971\" x=\"94.729514\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −6 -->\n      <g transform=\"translate(87.35842 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 126.63346 145.8 \nL 126.63346 7.2 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m4caf11f971\" x=\"126.63346\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −4 -->\n      <g transform=\"translate(119.262366 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 158.537406 145.8 \nL 158.537406 7.2 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m4caf11f971\" x=\"158.537406\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- −2 -->\n      <g transform=\"translate(151.166312 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 190.441352 145.8 \nL 190.441352 7.2 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m4caf11f971\" x=\"190.441352\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0 -->\n      <g transform=\"translate(187.260102 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 222.345298 145.8 \nL 222.345298 7.2 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m4caf11f971\" x=\"222.345298\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2 -->\n      <g transform=\"translate(219.164048 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path d=\"M 254.249243 145.8 \nL 254.249243 7.2 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m4caf11f971\" x=\"254.249243\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4 -->\n      <g transform=\"translate(251.067993 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path d=\"M 286.153189 145.8 \nL 286.153189 7.2 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m4caf11f971\" x=\"286.153189\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 6 -->\n      <g transform=\"translate(282.971939 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_17\">\n      <path d=\"M 318.057135 145.8 \nL 318.057135 7.2 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#m4caf11f971\" x=\"318.057135\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 8 -->\n      <g transform=\"translate(314.875885 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- x -->\n     <g transform=\"translate(186.684375 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \nL 2247 1797 \nL 3578 0 \nL 2900 0 \nL 1881 1375 \nL 863 0 \nL 184 0 \nL 1544 1831 \nL 300 3500 \nL 978 3500 \nL 1906 2253 \nL 2834 3500 \nL 3513 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-78\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_19\">\n      <path d=\"M 50.14375 139.669187 \nL 329.14375 139.669187 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <defs>\n       <path id=\"m46aec9148a\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m46aec9148a\" x=\"50.14375\" y=\"139.669187\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.00 -->\n      <g transform=\"translate(20.878125 143.468405) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_21\">\n      <path d=\"M 50.14375 114.435349 \nL 329.14375 114.435349 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use xlink:href=\"#m46aec9148a\" x=\"50.14375\" y=\"114.435349\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.05 -->\n      <g transform=\"translate(20.878125 118.234568) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_23\">\n      <path d=\"M 50.14375 89.201512 \nL 329.14375 89.201512 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use xlink:href=\"#m46aec9148a\" x=\"50.14375\" y=\"89.201512\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.10 -->\n      <g transform=\"translate(20.878125 93.000731) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_25\">\n      <path d=\"M 50.14375 63.967675 \nL 329.14375 63.967675 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use xlink:href=\"#m46aec9148a\" x=\"50.14375\" y=\"63.967675\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.15 -->\n      <g transform=\"translate(20.878125 67.766893) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_27\">\n      <path d=\"M 50.14375 38.733837 \nL 329.14375 38.733837 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use xlink:href=\"#m46aec9148a\" x=\"50.14375\" y=\"38.733837\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.20 -->\n      <g transform=\"translate(20.878125 42.533056) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_29\">\n      <path d=\"M 50.14375 13.5 \nL 329.14375 13.5 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_30\">\n      <g>\n       <use xlink:href=\"#m46aec9148a\" x=\"50.14375\" y=\"13.5\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.25 -->\n      <g transform=\"translate(20.878125 17.299219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- grad of sigmoid -->\n     <g transform=\"translate(14.798438 115.626563) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-67\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"104.589844\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"165.869141\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"229.345703\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"261.132812\"/>\n      <use xlink:href=\"#DejaVuSans-66\" x=\"322.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"357.519531\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"389.306641\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"441.40625\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"469.189453\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"532.666016\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"630.078125\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"691.259766\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"719.042969\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 62.825568 139.5 \nL 77.182345 139.253462 \nL 86.753528 138.912712 \nL 94.729514 138.424397 \nL 101.110305 137.816687 \nL 105.8959 137.175007 \nL 110.681487 136.314067 \nL 115.467074 135.161385 \nL 118.657473 134.185253 \nL 121.847865 133.003565 \nL 125.038257 131.575826 \nL 128.228656 129.854907 \nL 131.419051 127.786619 \nL 134.609446 125.309608 \nL 137.799842 122.355806 \nL 140.990233 118.851768 \nL 144.180629 114.721215 \nL 147.371024 109.889367 \nL 150.561419 104.289473 \nL 153.751811 97.872081 \nL 156.942206 90.617285 \nL 160.132602 82.549746 \nL 163.322997 73.755506 \nL 168.10859 59.584618 \nL 174.489379 40.443712 \nL 177.679773 31.713935 \nL 179.274971 27.775856 \nL 180.870168 24.207097 \nL 182.465365 21.068279 \nL 184.060562 18.415173 \nL 185.65576 16.296758 \nL 187.250957 14.753321 \nL 188.846154 13.814889 \nL 190.441352 13.5 \nL 192.036549 13.814896 \nL 193.631746 14.753328 \nL 195.226944 16.296758 \nL 196.822141 18.415173 \nL 198.417338 21.068279 \nL 200.012536 24.207097 \nL 201.607733 27.775848 \nL 203.20293 31.713935 \nL 206.393325 40.44372 \nL 211.178916 54.732931 \nL 215.964509 69.133646 \nL 219.154904 78.235198 \nL 222.345298 86.681345 \nL 225.535693 94.349061 \nL 228.726088 101.185068 \nL 231.916484 107.189056 \nL 235.106879 112.397409 \nL 238.297271 116.869579 \nL 241.487666 120.677302 \nL 244.678061 123.89682 \nL 247.868457 126.603296 \nL 251.058848 128.867818 \nL 254.249243 130.755216 \nL 257.439635 132.323237 \nL 260.630034 133.622466 \nL 263.820426 134.696712 \nL 267.010825 135.583359 \nL 271.79642 136.629496 \nL 276.582007 137.410223 \nL 281.367594 137.991793 \nL 287.748385 138.54229 \nL 295.724372 138.98448 \nL 306.89075 139.328718 \nL 316.461932 139.482212 \nL 316.461932 139.482212 \n\" clip-path=\"url(#p8542d389c1)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 145.8 \nL 50.14375 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 329.14375 145.8 \nL 329.14375 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 145.8 \nL 329.14375 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 7.2 \nL 329.14375 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p8542d389c1\">\n   <rect x=\"50.14375\" y=\"7.2\" width=\"279\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Clear out previous gradients\n",
        "x.grad.data.zero_()\n",
        "y.backward(torch.ones_like(x),retain_graph=True)\n",
        "d2l.plot(x.detach(), x.grad, 'x', 'grad of sigmoid', figsize=(5, 2.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22e15b1f",
      "metadata": {
        "origin_pos": 26,
        "id": "22e15b1f"
      },
      "source": [
        "### Tanh Function\n",
        ":label:`subsec_tanh`\n",
        "\n",
        "Like the sigmoid function, [**the tanh (hyperbolic tangent)\n",
        "function also squashes its inputs**],\n",
        "transforming them into elements on the interval (**between $-1$ and $1$**):\n",
        "\n",
        "$$\\operatorname{tanh}(x) = \\frac{1 - \\exp(-2x)}{1 + \\exp(-2x)}.$$\n",
        "\n",
        "We plot the tanh function below. Note that as input nears 0, the tanh function approaches a linear transformation. Although the shape of the function is similar to that of the sigmoid function, the tanh function exhibits point symmetry about the origin of the coordinate system :cite:`Kalman.Kwasny.1992`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "59cc5dc6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:38:45.353701Z",
          "iopub.status.busy": "2023-08-18T19:38:45.352955Z",
          "iopub.status.idle": "2023-08-18T19:38:45.679220Z",
          "shell.execute_reply": "2023-08-18T19:38:45.677327Z"
        },
        "origin_pos": 28,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "59cc5dc6",
        "outputId": "708adb79-b302-4d67-d706-a449c3ae1053"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"338.360937pt\" height=\"183.35625pt\" viewBox=\"0 0 338.360937 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-08-06T00:39:01.573524</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 338.360937 183.35625 \nL 338.360937 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 52.160938 145.8 \nL 331.160937 145.8 \nL 331.160937 7.2 \nL 52.160938 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 64.842756 145.8 \nL 64.842756 7.2 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"mf3c1e3af37\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mf3c1e3af37\" x=\"64.842756\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −8 -->\n      <g transform=\"translate(57.471662 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 96.746702 145.8 \nL 96.746702 7.2 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mf3c1e3af37\" x=\"96.746702\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −6 -->\n      <g transform=\"translate(89.375608 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 128.650647 145.8 \nL 128.650647 7.2 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mf3c1e3af37\" x=\"128.650647\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −4 -->\n      <g transform=\"translate(121.279554 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 160.554593 145.8 \nL 160.554593 7.2 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mf3c1e3af37\" x=\"160.554593\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- −2 -->\n      <g transform=\"translate(153.1835 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 192.458539 145.8 \nL 192.458539 7.2 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mf3c1e3af37\" x=\"192.458539\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0 -->\n      <g transform=\"translate(189.277289 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 224.362485 145.8 \nL 224.362485 7.2 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#mf3c1e3af37\" x=\"224.362485\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2 -->\n      <g transform=\"translate(221.181235 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path d=\"M 256.266431 145.8 \nL 256.266431 7.2 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#mf3c1e3af37\" x=\"256.266431\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4 -->\n      <g transform=\"translate(253.085181 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path d=\"M 288.170377 145.8 \nL 288.170377 7.2 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#mf3c1e3af37\" x=\"288.170377\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 6 -->\n      <g transform=\"translate(284.989127 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_17\">\n      <path d=\"M 320.074323 145.8 \nL 320.074323 7.2 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#mf3c1e3af37\" x=\"320.074323\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 8 -->\n      <g transform=\"translate(316.893073 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- x -->\n     <g transform=\"translate(188.701562 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \nL 2247 1797 \nL 3578 0 \nL 2900 0 \nL 1881 1375 \nL 863 0 \nL 184 0 \nL 1544 1831 \nL 300 3500 \nL 978 3500 \nL 1906 2253 \nL 2834 3500 \nL 3513 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-78\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_19\">\n      <path d=\"M 52.160938 139.500015 \nL 331.160937 139.500015 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <defs>\n       <path id=\"me6b2b65413\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#me6b2b65413\" x=\"52.160938\" y=\"139.500015\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- −1.0 -->\n      <g transform=\"translate(20.878125 143.299234) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_21\">\n      <path d=\"M 52.160938 108.000007 \nL 331.160937 108.000007 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use xlink:href=\"#me6b2b65413\" x=\"52.160938\" y=\"108.000007\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- −0.5 -->\n      <g transform=\"translate(20.878125 111.799225) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_23\">\n      <path d=\"M 52.160938 76.499998 \nL 331.160937 76.499998 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use xlink:href=\"#me6b2b65413\" x=\"52.160938\" y=\"76.499998\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.0 -->\n      <g transform=\"translate(29.257812 80.299217) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_25\">\n      <path d=\"M 52.160938 44.99999 \nL 331.160937 44.99999 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use xlink:href=\"#me6b2b65413\" x=\"52.160938\" y=\"44.99999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.5 -->\n      <g transform=\"translate(29.257812 48.799208) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_27\">\n      <path d=\"M 52.160938 13.499981 \nL 331.160937 13.499981 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use xlink:href=\"#me6b2b65413\" x=\"52.160938\" y=\"13.499981\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.0 -->\n      <g transform=\"translate(29.257812 17.2992) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- tanh(x) -->\n     <g transform=\"translate(14.798437 94.722656) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"100.488281\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"163.867188\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"227.246094\"/>\n      <use xlink:href=\"#DejaVuSans-78\" x=\"266.259766\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"325.439453\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 64.842756 139.5 \nL 135.031438 139.406014 \nL 144.60262 139.188466 \nL 150.983407 138.80874 \nL 155.768998 138.246088 \nL 158.959394 137.638487 \nL 162.149789 136.742976 \nL 163.744987 136.148793 \nL 165.340184 135.430785 \nL 166.935382 134.565131 \nL 168.53058 133.524354 \nL 170.125777 132.277168 \nL 171.720973 130.788573 \nL 173.316171 129.020255 \nL 174.911369 126.93145 \nL 176.506566 124.480444 \nL 178.101763 121.626776 \nL 179.696961 118.334325 \nL 181.292158 114.575179 \nL 182.887355 110.334131 \nL 184.482553 105.613387 \nL 186.07775 100.43679 \nL 189.268144 88.934648 \nL 197.244131 58.147297 \nL 198.839328 52.563206 \nL 200.434526 47.386609 \nL 202.029723 42.665865 \nL 203.62492 38.424817 \nL 205.220118 34.665672 \nL 206.815315 31.373221 \nL 208.410512 28.519552 \nL 210.00571 26.068546 \nL 211.600907 23.979742 \nL 213.196103 22.211427 \nL 214.791301 20.722829 \nL 216.386499 19.475642 \nL 217.981696 18.434865 \nL 219.576894 17.569211 \nL 221.172092 16.851203 \nL 224.362485 15.766244 \nL 227.55288 15.028165 \nL 230.743276 14.528464 \nL 235.528867 14.066512 \nL 241.909658 13.75517 \nL 251.48084 13.576953 \nL 272.218404 13.5057 \nL 318.479119 13.5 \nL 318.479119 13.5 \n\" clip-path=\"url(#p89b3f78b2b)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 52.160938 145.8 \nL 52.160938 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 331.160937 145.8 \nL 331.160937 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 52.160938 145.8 \nL 331.160938 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 52.160938 7.2 \nL 331.160938 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p89b3f78b2b\">\n   <rect x=\"52.160938\" y=\"7.2\" width=\"279\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "y = torch.tanh(x)\n",
        "d2l.plot(x.detach(), y.detach(), 'x', 'tanh(x)', figsize=(5, 2.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e99087ab",
      "metadata": {
        "origin_pos": 31,
        "id": "e99087ab"
      },
      "source": [
        "The derivative of the tanh function is:\n",
        "\n",
        "$$\\frac{d}{dx} \\operatorname{tanh}(x) = 1 - \\operatorname{tanh}^2(x).$$\n",
        "\n",
        "It is plotted below.\n",
        "As the input nears 0,\n",
        "the derivative of the tanh function approaches a maximum of 1.\n",
        "And as we saw with the sigmoid function,\n",
        "as input moves away from 0 in either direction,\n",
        "the derivative of the tanh function approaches 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fef45e56",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:38:45.684265Z",
          "iopub.status.busy": "2023-08-18T19:38:45.683296Z",
          "iopub.status.idle": "2023-08-18T19:38:46.004038Z",
          "shell.execute_reply": "2023-08-18T19:38:46.001327Z"
        },
        "origin_pos": 33,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "fef45e56",
        "outputId": "5a018305-79e5-45dc-8ab1-062c95fe6fa1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"329.98125pt\" height=\"183.35625pt\" viewBox=\"0 0 329.98125 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-08-06T00:39:27.281403</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 329.98125 183.35625 \nL 329.98125 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 145.8 \nL 322.78125 145.8 \nL 322.78125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 56.463068 145.8 \nL 56.463068 7.2 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"mc96e6b2b9d\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mc96e6b2b9d\" x=\"56.463068\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −8 -->\n      <g transform=\"translate(49.091974 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 88.367014 145.8 \nL 88.367014 7.2 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mc96e6b2b9d\" x=\"88.367014\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −6 -->\n      <g transform=\"translate(80.99592 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 120.27096 145.8 \nL 120.27096 7.2 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mc96e6b2b9d\" x=\"120.27096\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −4 -->\n      <g transform=\"translate(112.899866 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 152.174906 145.8 \nL 152.174906 7.2 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mc96e6b2b9d\" x=\"152.174906\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- −2 -->\n      <g transform=\"translate(144.803812 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 184.078852 145.8 \nL 184.078852 7.2 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mc96e6b2b9d\" x=\"184.078852\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0 -->\n      <g transform=\"translate(180.897602 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 215.982798 145.8 \nL 215.982798 7.2 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#mc96e6b2b9d\" x=\"215.982798\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2 -->\n      <g transform=\"translate(212.801548 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path d=\"M 247.886743 145.8 \nL 247.886743 7.2 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#mc96e6b2b9d\" x=\"247.886743\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4 -->\n      <g transform=\"translate(244.705493 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path d=\"M 279.790689 145.8 \nL 279.790689 7.2 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#mc96e6b2b9d\" x=\"279.790689\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 6 -->\n      <g transform=\"translate(276.609439 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_17\">\n      <path d=\"M 311.694635 145.8 \nL 311.694635 7.2 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#mc96e6b2b9d\" x=\"311.694635\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 8 -->\n      <g transform=\"translate(308.513385 160.398438) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- x -->\n     <g transform=\"translate(180.321875 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \nL 2247 1797 \nL 3578 0 \nL 2900 0 \nL 1881 1375 \nL 863 0 \nL 184 0 \nL 1544 1831 \nL 300 3500 \nL 978 3500 \nL 1906 2253 \nL 2834 3500 \nL 3513 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-78\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_19\">\n      <path d=\"M 43.78125 139.50006 \nL 322.78125 139.50006 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <defs>\n       <path id=\"m93c1440341\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m93c1440341\" x=\"43.78125\" y=\"139.50006\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 143.299279) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_21\">\n      <path d=\"M 43.78125 114.300048 \nL 322.78125 114.300048 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use xlink:href=\"#m93c1440341\" x=\"43.78125\" y=\"114.300048\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 118.099267) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_23\">\n      <path d=\"M 43.78125 89.100036 \nL 322.78125 89.100036 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use xlink:href=\"#m93c1440341\" x=\"43.78125\" y=\"89.100036\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 92.899255) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_25\">\n      <path d=\"M 43.78125 63.900024 \nL 322.78125 63.900024 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use xlink:href=\"#m93c1440341\" x=\"43.78125\" y=\"63.900024\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 67.699243) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_27\">\n      <path d=\"M 43.78125 38.700012 \nL 322.78125 38.700012 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use xlink:href=\"#m93c1440341\" x=\"43.78125\" y=\"38.700012\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 42.499231) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_29\">\n      <path d=\"M 43.78125 13.5 \nL 322.78125 13.5 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_30\">\n      <g>\n       <use xlink:href=\"#m93c1440341\" x=\"43.78125\" y=\"13.5\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 17.299219) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- grad of tanh -->\n     <g transform=\"translate(14.798438 107.327344) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-67\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"104.589844\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"165.869141\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"229.345703\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"261.132812\"/>\n      <use xlink:href=\"#DejaVuSans-66\" x=\"322.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"357.519531\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"389.306641\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"428.515625\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"489.794922\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"553.173828\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 56.463068 139.5 \nL 115.485365 139.407311 \nL 125.056551 139.19236 \nL 131.437342 138.816301 \nL 136.222933 138.256946 \nL 139.413328 137.650037 \nL 142.60372 136.750129 \nL 144.198919 136.149435 \nL 145.794115 135.419709 \nL 147.389311 134.534266 \nL 148.98451 133.46146 \nL 150.579706 132.163957 \nL 152.174906 130.598053 \nL 153.770102 128.713213 \nL 155.365299 126.451699 \nL 156.960497 123.748808 \nL 158.555695 120.533634 \nL 160.150892 116.731015 \nL 161.74609 112.264839 \nL 163.341286 107.063468 \nL 164.936483 101.067529 \nL 166.531681 94.240673 \nL 168.126879 86.583273 \nL 169.722075 78.148441 \nL 172.912471 59.522835 \nL 176.102865 40.407602 \nL 177.698062 31.68952 \nL 179.29326 24.192751 \nL 180.888457 18.408584 \nL 182.483654 14.751648 \nL 184.078852 13.5 \nL 185.674049 14.751648 \nL 187.269246 18.408584 \nL 188.864444 24.192751 \nL 190.459641 31.68952 \nL 192.054838 40.407602 \nL 198.435628 78.148441 \nL 200.030825 86.583273 \nL 201.626022 94.240673 \nL 203.22122 101.067529 \nL 204.816416 107.063453 \nL 206.411613 112.264839 \nL 208.006811 116.731015 \nL 209.602009 120.533634 \nL 211.197206 123.748808 \nL 212.792404 126.451699 \nL 214.3876 128.713199 \nL 215.982798 130.598053 \nL 217.577993 132.163957 \nL 219.173193 133.46146 \nL 220.768389 134.534266 \nL 222.363588 135.419709 \nL 223.958784 136.149435 \nL 227.149179 137.244125 \nL 230.339575 137.983373 \nL 233.52997 138.481373 \nL 238.315561 138.939958 \nL 244.696348 139.248084 \nL 254.267534 139.424113 \nL 275.005094 139.494412 \nL 310.099432 139.499985 \nL 310.099432 139.499985 \n\" clip-path=\"url(#p7603005084)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 145.8 \nL 43.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 322.78125 145.8 \nL 322.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 145.8 \nL 322.78125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 322.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7603005084\">\n   <rect x=\"43.78125\" y=\"7.2\" width=\"279\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Clear out previous gradients\n",
        "x.grad.data.zero_()\n",
        "y.backward(torch.ones_like(x),retain_graph=True)\n",
        "d2l.plot(x.detach(), x.grad, 'x', 'grad of tanh', figsize=(5, 2.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32968a6b",
      "metadata": {
        "origin_pos": 36,
        "id": "32968a6b"
      },
      "source": [
        "## Summary and Discussion\n",
        "\n",
        "We now know how to incorporate nonlinearities\n",
        "to build expressive multilayer neural network architectures.\n",
        "As a side note, your knowledge already\n",
        "puts you in command of a similar toolkit\n",
        "to a practitioner circa 1990.\n",
        "In some ways, you have an advantage\n",
        "over anyone working back then,\n",
        "because you can leverage powerful\n",
        "open-source deep learning frameworks\n",
        "to build models rapidly, using only a few lines of code.\n",
        "Previously, training these networks\n",
        "required researchers to code up layers and derivatives\n",
        "explicitly in C, Fortran, or even Lisp (in the case of LeNet).\n",
        "\n",
        "A secondary benefit is that ReLU is significantly more amenable to\n",
        "optimization than the sigmoid or the tanh function. One could argue\n",
        "that this was one of the key innovations that helped the resurgence\n",
        "of deep learning over the past decade. Note, though, that research in\n",
        "activation functions has not stopped.\n",
        "For instance,\n",
        "the GELU (Gaussian error linear unit)\n",
        "activation function $x \\Phi(x)$ by :citet:`Hendrycks.Gimpel.2016` ($\\Phi(x)$\n",
        "is the standard Gaussian cumulative distribution function)\n",
        "and\n",
        "the Swish activation\n",
        "function $\\sigma(x) = x \\operatorname{sigmoid}(\\beta x)$ as proposed in :citet:`Ramachandran.Zoph.Le.2017` can yield better accuracy\n",
        "in many cases.\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Show that adding layers to a *linear* deep network, i.e., a network without\n",
        "   nonlinearity $\\sigma$ can never increase the expressive power of the network.\n",
        "   Give an example where it actively reduces it.\n",
        "1. Compute the derivative of the pReLU activation function.\n",
        "1. Compute the derivative of the Swish activation function $x \\operatorname{sigmoid}(\\beta x)$.\n",
        "1. Show that an MLP using only ReLU (or pReLU) constructs a\n",
        "   continuous piecewise linear function.\n",
        "1. Sigmoid and tanh are very similar.\n",
        "    1. Show that $\\operatorname{tanh}(x) + 1 = 2 \\operatorname{sigmoid}(2x)$.\n",
        "    1. Prove that the function classes parametrized by both nonlinearities are identical. Hint: affine layers have bias terms, too.\n",
        "1. Assume that we have a nonlinearity that applies to one minibatch at a time, such as the batch normalization :cite:`Ioffe.Szegedy.2015`. What kinds of problems do you expect this to cause?\n",
        "1. Provide an example where the gradients vanish for the sigmoid activation function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce04909b",
      "metadata": {
        "origin_pos": 38,
        "tab": [
          "pytorch"
        ],
        "id": "ce04909b"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/91)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes:\n",
        "\n",
        "Hidden layers:\n",
        "\n",
        "For single layer networks, there are only affine transformations, or a linear transformation and a bias. This works fine if your features all directly relate to your outputs by a simple affine transformation, but this assumption only holds for very simple problems, and linearity is a strong assumption.\n",
        "\n",
        "\n",
        "\n",
        "Limitations of Linear Models:\n",
        "\n",
        "Linear models have the weak assumption of monotonicity, or that any increase in a feature causes an increase in output, and vice versa (and obviously this inverts if the weight is negative). This means that for something like modeling whether a person will pay back a loan, you will run into issues. Assuming all other variables are fixed, a linear increase in income doesn't mean a linear increase in whether they will pay it back. This feature probably increases likelihood logarithmically rather than linearly. Of course, we can correct this afterwards by having a logarithmic function that augments the output of the weight for that feature too. However, this requires manual augmentation of the model, and isn't applicable in all cases. For example, image recognition. Because linear models have each feature as independent (which doesn't hold in reality, as pixel values are heavily correlated with surrounding ones), you can train a model to predict images. But if you invert the pixel values, even though any person would have no issue dealing with it, a linear model would just completely break down. So, having a deep neural network allows the hidden layers to learn the representations, and linear predictors to act on these representations, avoiding this problem. Methods to deal with the inherent flaws of linear models include decision trees (binary decision making) and kernel methods. So, by stacking layers of simple transformations, models can deal with nonlinearity.\n",
        "\n",
        "\n",
        "Incorporating hidden layers:\n",
        "\n",
        "The easiest way to build a nonlinear capable model is just to stack multiple fully connected layers. So for a model with 4 input features, 1 hidden layer of 5 neurons, and an output layer of 3 neurons, we have layer_count - 1 layers that are the representations, and the final layer is the linear predictor. The input layer doesn't count, because there is no computation being done there. Because it is fully connected, each input influences every output in the next layer. However, we still have to do more to make the model represent nonlinear behaviours.\n",
        "\n",
        "\n",
        "From Linear to Nonlinear:\n",
        "\n",
        "You can't just stack multiple layers and get nonlinear capability.\n",
        "\n",
        "Lets use the same 3 layer mlp as before.\n",
        "\n",
        "X = minibatch. R^n * p  (where n is sample count, p is feature count)\n",
        "\n",
        "W_1 = weights of hidden layer 1. R^p * h (where h is amount of neurons of the hidden layer)\n",
        "\n",
        "b_1 = bias of hidden layer 1. R^1 * h\n",
        "\n",
        "H = output of hidden layer. R^n * h\n",
        "\n",
        "W_2 = weights of output layer. R^d * q (where q is amount of output neurons)\n",
        "\n",
        "O = outputs. R^n * q\n",
        "\n",
        "\n",
        "So, our current model does:\n",
        "\n",
        "H = XW_1 + b_1\n",
        "\n",
        "O = HW_2 + b_2\n",
        "\n",
        "However, this is still linear. This is because an affine transformation on top of any amount of any affine transformations is capable of being expressed as a single affine transformation.\n",
        "\n",
        "\n",
        "So, if we let W = W_1*W_2, and b = b_1W_2 + b_2:\n",
        "\n",
        "We can expand what our model does:\n",
        "\n",
        "O = XW_1W_2 + b_1W_2 + b_2\n",
        "\n",
        "Which is just:\n",
        "\n",
        "O = XW + b\n",
        "\n",
        "\n",
        "So without any introduced nonlinearity, a multiple layer neural network has zero different from a single layer linear network.\n",
        "\n",
        "This means we have to introduce nonlinearity. an example of this is ReLU:\n",
        "σ(x) = max(0, x)\n",
        "\n",
        "This is an elementwise operation on the arguments. We call the outputs of nonlinearity activations.\n",
        "\n",
        "Our model now becomes:\n",
        "\n",
        "H = σ(XW_1 + b_1)\n",
        "\n",
        "O = HW_2 + b_2\n",
        "\n",
        "Notation is used technically off here, as it is defined to apply rowwise, so an example at a time.\n",
        "\n",
        "It is obvious why adding a nonlinearity makes the model capable of expressing nonlinear functions. Because ReLU takes the max of the argument and 0, all negative arguments become zero. So, the function is no longer monotonic. This means not every feature has to contribute. Because the model can learn weights to make a feature negative, which would mean that it has certain inputs for that will not lead to an output. So it can turn certain activatioins off, increasing sparsity. Hidden layers can be stacked ontop of eachother, increasing the expressiveness of the model.\n",
        "\n",
        "\n",
        "Universal Representations:\n",
        "\n",
        "Technically speaking, you can model any function with a single hidden layer mlp (given enough nodes, of course). However, there are practical reasons for why this is a bad idea. One reason is just that kernel methods exist, and they solve problems exactly even in infinite dimensions. As such, we can increase the depth of our network to not have to have a massive single hidden layer mlp.\n",
        "\n",
        "\n",
        "Activation Functions:\n",
        "\n",
        "Activation functions further add a bias after the weighted sum of a neuron, and decide whether it should fire or not. Here are some common ones:\n",
        "\n",
        "\n",
        "ReLU:\n",
        "\n",
        "ReLU(x) = max(0, x)\n",
        "\n",
        "\n",
        "What this means is that all positive values remain the same, while negative values all become zero. This means that only neurons with a positive weighted sum can fire. ReLU is good because the derivatives are very simple, 0 for all negatives, and 1 for all positives. There isn't a derivative for 0, so it is just treated as the lhs derivative of 0. Because of how simple the derivative is, this makes computing the gradient very simple. Because the derivatives of ReLU are \"well behaved\" (they either completely disappear or let the argument through), this makes optimization with ReLU very easy, and solved the problem of vanishing gradients.\n",
        "\n",
        "There are ReLU variants like pReLU, which add a linear term to ReLU, so that negative arguments still give some information:\n",
        "\n",
        "ReLU(x) = max(0, x) + α * min(0,x)\n",
        "\n",
        "\n",
        "Sigmoid:\n",
        "\n",
        "Sigmoid turns values in domain R to lie in the interval (0, 1). This is why it is called a squashing function, because it \"sqaushes\" all reals into said interval.\n",
        "\n",
        "Sigmoid(x) = 1/(1 + exp(-x))\n",
        "\n",
        "Sigmoid became widely used when the focus turned from binary activation (where all activations are either 0 or 1), to gradient based methods, because it is smooth and differentiable approximation of a thresholding unit. Sigmoids are commonly used for binary classification problems, because it is essentially a special case of softmax (which is good for binary classification for obvious reasons). While sigmoid has these advantages over ReLU, ReLU is still more widely used for hidden layers, because sigmoid deals with the issue of vanishing gradients.\n",
        "\n",
        "The derivative of sigmoid is sigmoid(x)(1 - sigmoid(x)). (Wow its the variance of a bernoulli random variable).\n",
        "\n",
        "As such, the max value of the derivative of the sigmoid is 0.25. The minimum value of the sigmoid is 0. So, as x gets very large or small, sigmoid approaches 1 or 0 respectively. As it levels off in these regions, the gradients become increasingly flatter. And as gradients are multiplied during backprop, and these gradients are tiny (very often less than 1), this means that after just a few layers the gradients become extremely small. However, sigmoid still has uses such as controlling information flow over time in lstms.\n",
        "\n",
        "\n",
        "Tanh:\n",
        "\n",
        "Tanh, or the hyperbolic tangent, does the same thing as sigmoid, where it squashes inputs, but into the interval of (-1, 1). The difference with sigmoid is that it is symmetric about the origin, and can have both positive and negative outputs.\n",
        "\n",
        "tanh(x) = (1 - exp(-2x))/(1 + exp(-2x))\n",
        "\n",
        "Tanh also becomes approaches a linear transformation as the input approaches 0.\n",
        "\n",
        "The derivative of tanh is 1 - tanh(x)^2\n",
        "\n",
        "This is similar to the derivative of the sigmoid, but it is bounded between 1 and 0.\n",
        "\n",
        "Tanh still faces the same vanishing gradients effect that sigmoid does, but it is better. This is because tanh is symmetric about the x axis. Because sigmoid only returns positive values, that means the gradient is often all positive or negative with respect to the weights. This causes descent to oscillate more, as the weight values still span both positive and negative values. However, as tanh is centered around 0, it is far more balanced, so it is far more likely that some gradients are positive and some are negative with respect to the weights, which makes the updates more balanced and speeds up convergence.\n"
      ],
      "metadata": {
        "id": "n9fg41ymhHxB"
      },
      "id": "n9fg41ymhHxB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercises:\n",
        "\n",
        "1.\n",
        "\n",
        "Proved above.\n",
        "You can't just stack multiple layers and get nonlinear capability.\n",
        "Lets use the same 3 layer mlp as before.\n",
        "X = minibatch. R^n*p  (where n is sample count, p is feature count)\n",
        "W_1 = weights of hidden layer. R^p*h (where h is amount of neurons of the hidden layer)\n",
        "b_1 = bias of hidden layer. R^1*h\n",
        "H = output of hidden layer. R^n*h\n",
        "W_2 = weights of output layer. R^h*q (where q is amount of output neurons)\n",
        "b_1 = bias of hidden layer. R^1*q\n",
        "O = outputs. R^n*q\n",
        "\n",
        "So, our current model does:\n",
        "H = XW_1 + b_1\n",
        "O = HW_2 + b_2\n",
        "\n",
        "However, this is still linear. This is because an affine transformation ontop of any amount of any affine transformations is capable of being expressed as a single affine transformation.\n",
        "\n",
        "So, if we let W = W_1*W_2, and b = b_1W_2 + b_2:\n",
        "We can expand what our model does:\n",
        "O = XW_1W_2 + b_1W_2 + b_2\n",
        "\n",
        "Which is just:\n",
        "O = XW + b\n",
        "\n",
        "This is true for any amount of linear layers, because multiplying an affine function by an affine function is still an affine function.\n",
        "\n",
        "Since these are purely linear, the rank (dimensionality) of a single layer neural networks smallest layer determines the matrix it can realize up to. So, a single layer network with input of 10 and output of 5 can realize up to a rank 5 matrix. If we add a single hidden layer, which is rank 3, it can only realize a matrix of up to rank 3. Because you lose expressiveness from the input to the hidden layer, and you can't get it back.\n",
        "\n",
        "\n",
        "2. Compute the derivative of the pReLU activation function.\n",
        "\n",
        "\n",
        "Case 1: x is positive:\n",
        "\n",
        "pReLU(x) = max(0, x) + α * min (0, x)\n",
        "\n",
        "derivative = 1 + 0 = 1\n",
        "\n",
        "\n",
        "Case 2: x is 0:\n",
        "\n",
        "pReLU(x) = max(0, x) + α * min (0, x)\n",
        "\n",
        "We default to the lhs derivative (which is α for pReLU), as it isn't differentiable at x = 0.\n",
        "\n",
        "derivative = α\n",
        "\n",
        "\n",
        "Case 3: x is negative:\n",
        "\n",
        "pReLU(x) = max(0, x) + α * min (0, x)\n",
        "\n",
        "derivative = 0 + α * (1) = α\n",
        "\n",
        "\n",
        "\n",
        "3. Compute the derivative of the Swish activation function x * sigmoid(βx)\n",
        "\n",
        "Swish = x * sigmoid(βx)\n",
        "\n",
        "Swish =  x * 1/(1+exp(-βx))\n",
        "\n",
        "a = x, b = 1/(1+exp(-βx))\n",
        "\n",
        "derivative = a'b + ab'\n",
        "\n",
        "derivative = sigmoid(βx) + x * β * sigmoid(βx)(1 - sigmoid(βx))\n",
        "\n",
        "\n",
        "\n",
        "4. Show that an MLP using only ReLU (or pReLU) constructs a continuous piecewise linear function.\n",
        "\n",
        "\n",
        "ReLU(x) = max(0, x)\n",
        "\n",
        "H = σ(XW_1 + b_1)\n",
        "O = HW_2 + b_2\n",
        "\n",
        "As all inputs to ReLU remain the same when they are positive, and are 0 otherwise:\n",
        "\n",
        "XW_1 + b_1 -> XW_1 + b_1 while x > 0\n",
        "\n",
        "This clearly shows that the subfunction of the function that remains is all positive values of XW_1 + b_1, which is indeed piecewise and continous.\n",
        "\n",
        "\n",
        "Assume the first hidden layer has 2 ReLUs (so 2 neurons), w_1, w_2 of R^2, and biases b_1, b_2:\n",
        "\n",
        "z_i = xw_i + b_i\n",
        "\n",
        "h_i(x) = ReLU(0, z_i(x))\n",
        "\n",
        "H(x) = [h_1(x), h_2(x))]\n",
        "\n",
        "We have 4 patterns:\n",
        "\n",
        "Both on:\n",
        "\n",
        "H(x) = [z_1(x), z_2(x))]\n",
        "\n",
        "Only neuron 1 on:\n",
        "\n",
        "H(x) = [z_1(x), 0]\n",
        "\n",
        "Only neuron 2 on:\n",
        "\n",
        "H(x) = [0, z_2(x)]\n",
        "\n",
        "Both off:\n",
        "\n",
        "H(x) = [0, 0]\n",
        "\n",
        "So, clearly all of these are affine, with 4 total cases.\n",
        "\n",
        "\n",
        "Now assume the next layer also has 2 neurons, so weights w_3, w_4 of R^2, and biases b_3, b_4:\n",
        "\n",
        "d_j(x) = Hw_i + b_i\n",
        "\n",
        "o_j(x) = ReLU(0, d_j(x))\n",
        "\n",
        "O(x) = [o_1(x), o_2(x)]\n",
        "\n",
        "\n",
        "So we have the cases:\n",
        "\n",
        "Both on:\n",
        "\n",
        "O(x) = [o_1(x), o_2(x)]\n",
        "\n",
        "Only neuron 3 on:\n",
        "\n",
        "O(x) = [o_1(x), 0]\n",
        "\n",
        "Only neuron 4 on:\n",
        "\n",
        "O(x) = [0, o_2(x)]\n",
        "\n",
        "Both off:\n",
        "\n",
        "O(x) = [0, 0]\n",
        "\n",
        "\n",
        "For example:\n",
        "\n",
        "Ax + c\n",
        "\n",
        "O(x) = [o_1(x), 0]\n",
        "\n",
        "w_3Ux + w_3v + b_3\n",
        "\n",
        "w_3U = A, w_3v + b_3 = c\n",
        "\n",
        "\n",
        "Once again, the reason it is affine is obvious. Sums of affine functions are just affine functions, and since all functions are in terms of the inputs, it is affine in terms of x. However, these obviously are the higher level cases only. For each case, of O(x), we also have all cases of H(x) as possible, so there are 16 total possible cases.\n",
        "\n",
        "\n",
        "\n",
        "5. Sigmoid and tanh are very similar.\n",
        "\n",
        "5.1 Show that tanh(x) + 1 = 2sigmoid(2x)\n",
        "\n",
        "tanh = (1 - exp(-2x))/(1 + exp(-2x))\n",
        "\n",
        "tanh + 1 = (1 - exp(-2x))/(1 + exp(-2x)) + (1 + exp(-2x))/(1 + exp(-2x))\n",
        "\n",
        "tanh + 1 = (1 - exp(-2x) + 1 + exp(-2x))/(1 + exp(-2x))\n",
        "\n",
        "tanh + 1 = 2/(1 + exp(-2x)\n",
        "\n",
        "\n",
        "sigmoid(x) = 1/(1 + exp(-x))\n",
        "\n",
        "2sigmoid(2x) = 2/(1+ + exp(-2x)\n",
        "\n",
        "\n",
        "So it is clear that tanh + 1 = 2sigmoid(2x)\n",
        "\n",
        "\n",
        "5.2 Prove that the function classes parametrized by both nonlinearities are identical. Hint: affine layers have bias terms, too.\n",
        "\n",
        "\n",
        "\n",
        "In section 1 we have proved that tanh + 1 = 2sigmoid(2x)\n",
        "\n",
        "We can rearrange to get tanh = 2sigmoid(2x) - 1\n",
        "\n",
        "So, we can create tanh through multiplying sigmoid by a constant, and adding another constant. As such, these are reversible operations. We simply for one of the functions use a bias that is off by one, and scale our weights linearly (which is literally what an affine function does), and then the two functions will be exactly the same after tanh or sigmoid\n",
        "\n",
        "\n",
        "6. Assume that we have a nonlinearity that applies to one minibatch at a time, such as the batch normalization (Ioffe and Szegedy, 2015). What kinds of problems do you expect this to cause?\n",
        "\n",
        "What batch normalization does is normalize the inputs to layer(s) based off of the statistics of the minibatch, to push the inputs to have a mean of zero and standard deviation of one. What I assume this does is make it so that the observed fisher matrix is invertible (seems kinda similar to muon to me, where pushing the matrix to be invertible essentially restores fullrank of the minibatch which is obviously a good thing)? It seems to clearly be helpful and a good thing, as inputs should be relative to their feature, not absolute (which I assume is the case when inputs aren't normalized), and you want to treat them on the same scale so that features with inherently large values don't just dominate updates to gradients.\n",
        "\n",
        "Given that one of the main benefits in training is that you can use a higher learning rate (as you don't have to worry about a batch with larger updates exploding the gradient updates), I assume a problem is the potential for exploding gradients and divergence simply due to the fact that higher learning rates are used."
      ],
      "metadata": {
        "id": "XG2boNVW7U5W"
      },
      "id": "XG2boNVW7U5W"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}