{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c2ef73a8",
      "metadata": {
        "id": "c2ef73a8"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a66c1f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8a66c1f7",
        "outputId": "39ba1d7e-3809-4e6e-e5a1-c5b0b930f926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l==1.0.3\n",
            "  Downloading d2l-1.0.3-py3-none-any.whl.metadata (556 bytes)\n",
            "Collecting jupyter==1.0.0 (from d2l==1.0.3)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "Collecting numpy==1.23.5 (from d2l==1.0.3)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting matplotlib==3.7.2 (from d2l==1.0.3)\n",
            "  Downloading matplotlib-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting matplotlib-inline==0.1.6 (from d2l==1.0.3)\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting requests==2.31.0 (from d2l==1.0.3)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pandas==2.0.3 (from d2l==1.0.3)\n",
            "  Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting scipy==1.10.1 (from d2l==1.0.3)\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.7)\n",
            "Collecting qtconsole (from jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading qtconsole-5.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (11.2.1)\n",
            "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib==3.7.2->d2l==1.0.3)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (2.9.0.post0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from matplotlib-inline==0.1.6->d2l==1.0.3) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l==1.0.3) (1.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.4.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.0.15)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (2.19.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.8.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.22.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.1)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading QtPy-2.4.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.24.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l==1.0.3) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l==1.0.3) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.13.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.25.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.1)\n",
            "Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading matplotlib-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qtconsole-5.6.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.0/125.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading QtPy-2.4.3-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.0/95.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests, qtpy, pyparsing, numpy, matplotlib-inline, jedi, scipy, pandas, matplotlib, qtconsole, jupyter, d2l\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.3\n",
            "    Uninstalling pyparsing-3.2.3:\n",
            "      Successfully uninstalled pyparsing-3.2.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: matplotlib-inline\n",
            "    Found existing installation: matplotlib-inline 0.1.7\n",
            "    Uninstalling matplotlib-inline-0.1.7:\n",
            "      Successfully uninstalled matplotlib-inline-0.1.7\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "cvxpy 1.6.5 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "blosc2 3.3.4 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.0 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.0 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.3.1 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\n",
            "bigframes 2.4.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed d2l-1.0.3 jedi-0.19.2 jupyter-1.0.0 matplotlib-3.7.2 matplotlib-inline-0.1.6 numpy-1.23.5 pandas-2.0.3 pyparsing-3.0.9 qtconsole-5.6.1 qtpy-2.4.3 requests-2.31.0 scipy-1.10.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "matplotlib_inline",
                  "mpl_toolkits",
                  "numpy"
                ]
              },
              "id": "6e87fcc3485b4ea39d6ec503fcd6f9bb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install d2l==1.0.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad19fa4",
      "metadata": {
        "origin_pos": 1,
        "id": "0ad19fa4"
      },
      "source": [
        "# Probability and Statistics\n",
        ":label:`sec_prob`\n",
        "\n",
        "One way or another,\n",
        "machine learning is all about uncertainty.\n",
        "In supervised learning, we want to predict\n",
        "something unknown (the *target*)\n",
        "given something known (the *features*).\n",
        "Depending on our objective,\n",
        "we might attempt to predict\n",
        "the most likely value of the target.\n",
        "Or we might predict the value with the smallest\n",
        "expected distance from the target.\n",
        "And sometimes we wish not only\n",
        "to predict a specific value\n",
        "but to *quantify our uncertainty*.\n",
        "For example, given some features\n",
        "describing a patient,\n",
        "we might want to know *how likely* they are\n",
        "to suffer a heart attack in the next year.\n",
        "In unsupervised learning,\n",
        "we often care about uncertainty.\n",
        "To determine whether a set of measurements are anomalous,\n",
        "it helps to know how likely one is\n",
        "to observe values in a population of interest.\n",
        "Furthermore, in reinforcement learning,\n",
        "we wish to develop agents\n",
        "that act intelligently in various environments.\n",
        "This requires reasoning about\n",
        "how an environment might be expected to change\n",
        "and what rewards one might expect to encounter\n",
        "in response to each of the available actions.\n",
        "\n",
        "*Probability* is the mathematical field\n",
        "concerned with reasoning under uncertainty.\n",
        "Given a probabilistic model of some process,\n",
        "we can reason about the likelihood of various events.\n",
        "The use of probabilities to describe\n",
        "the frequencies of repeatable events\n",
        "(like coin tosses)\n",
        "is fairly uncontroversial.\n",
        "In fact, *frequentist* scholars adhere\n",
        "to an interpretation of probability\n",
        "that applies *only* to such repeatable events.\n",
        "By contrast *Bayesian* scholars\n",
        "use the language of probability more broadly\n",
        "to formalize reasoning under uncertainty.\n",
        "Bayesian probability is characterized\n",
        "by two unique features:\n",
        "(i) assigning degrees of belief\n",
        "to non-repeatable events,\n",
        "e.g., what is the *probability*\n",
        "that a dam will collapse?;\n",
        "and (ii) subjectivity. While Bayesian\n",
        "probability provides unambiguous rules\n",
        "for how one should update their beliefs\n",
        "in light of new evidence,\n",
        "it allows for different individuals\n",
        "to start off with different *prior* beliefs.\n",
        "*Statistics* helps us to reason backwards,\n",
        "starting off with collection and organization of data\n",
        "and backing out to what inferences\n",
        "we might draw about the process\n",
        "that generated the data.\n",
        "Whenever we analyze a dataset, hunting for patterns\n",
        "that we hope might characterize a broader population,\n",
        "we are employing statistical thinking.\n",
        "Many courses, majors, theses, careers, departments,\n",
        "companies, and institutions have been devoted\n",
        "to the study of probability and statistics.\n",
        "While this section only scratches the surface,\n",
        "we will provide the foundation\n",
        "that you need to begin building models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "15d26295",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:41.010215Z",
          "iopub.status.busy": "2023-08-18T19:35:41.009884Z",
          "iopub.status.idle": "2023-08-18T19:35:44.240517Z",
          "shell.execute_reply": "2023-08-18T19:35:44.239244Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "15d26295"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import random\n",
        "import torch\n",
        "from torch.distributions.multinomial import Multinomial\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "390fa88a",
      "metadata": {
        "origin_pos": 6,
        "id": "390fa88a"
      },
      "source": [
        "## A Simple Example: Tossing Coins\n",
        "\n",
        "Imagine that we plan to toss a coin\n",
        "and want to quantify how likely\n",
        "we are to see heads (vs. tails).\n",
        "If the coin is *fair*,\n",
        "then both outcomes\n",
        "(heads and tails),\n",
        "are equally likely.\n",
        "Moreover if we plan to toss the coin $n$ times\n",
        "then the fraction of heads\n",
        "that we *expect* to see\n",
        "should exactly match\n",
        "the *expected* fraction of tails.\n",
        "One intuitive way to see this\n",
        "is by symmetry:\n",
        "for every possible outcome\n",
        "with $n_\\textrm{h}$ heads and $n_\\textrm{t} = (n - n_\\textrm{h})$ tails,\n",
        "there is an equally likely outcome\n",
        "with $n_\\textrm{t}$ heads and $n_\\textrm{h}$ tails.\n",
        "Note that this is only possible\n",
        "if on average we expect to see\n",
        "$1/2$ of tosses come up heads\n",
        "and $1/2$ come up tails.\n",
        "Of course, if you conduct this experiment\n",
        "many times with $n=1000000$ tosses each,\n",
        "you might never see a trial\n",
        "where $n_\\textrm{h} = n_\\textrm{t}$ exactly.\n",
        "\n",
        "\n",
        "Formally, the quantity $1/2$ is called a *probability*\n",
        "and here it captures the certainty with which\n",
        "any given toss will come up heads.\n",
        "Probabilities assign scores between $0$ and $1$\n",
        "to outcomes of interest, called *events*.\n",
        "Here the event of interest is $\\textrm{heads}$\n",
        "and we denote the corresponding probability $P(\\textrm{heads})$.\n",
        "A probability of $1$ indicates absolute certainty\n",
        "(imagine a trick coin where both sides were heads)\n",
        "and a probability of $0$ indicates impossibility\n",
        "(e.g., if both sides were tails).\n",
        "The frequencies $n_\\textrm{h}/n$ and $n_\\textrm{t}/n$ are not probabilities\n",
        "but rather *statistics*.\n",
        "Probabilities are *theoretical* quantities\n",
        "that underly the data generating process.\n",
        "Here, the probability $1/2$\n",
        "is a property of the coin itself.\n",
        "By contrast, statistics are *empirical* quantities\n",
        "that are computed as functions of the observed data.\n",
        "Our interests in probabilistic and statistical quantities\n",
        "are inextricably intertwined.\n",
        "We often design special statistics called *estimators*\n",
        "that, given a dataset, produce *estimates*\n",
        "of model parameters such as probabilities.\n",
        "Moreover, when those estimators satisfy\n",
        "a nice property called *consistency*,\n",
        "our estimates will converge\n",
        "to the corresponding probability.\n",
        "In turn, these inferred probabilities\n",
        "tell about the likely statistical properties\n",
        "of data from the same population\n",
        "that we might encounter in the future.\n",
        "\n",
        "Suppose that we stumbled upon a real coin\n",
        "for which we did not know\n",
        "the true $P(\\textrm{heads})$.\n",
        "To investigate this quantity\n",
        "with statistical methods,\n",
        "we need to (i) collect some data;\n",
        "and (ii) design an estimator.\n",
        "Data acquisition here is easy;\n",
        "we can toss the coin many times\n",
        "and record all the outcomes.\n",
        "Formally, drawing realizations\n",
        "from some underlying random process\n",
        "is called *sampling*.\n",
        "As you might have guessed,\n",
        "one natural estimator\n",
        "is the ratio of\n",
        "the number of observed *heads*\n",
        "to the total number of tosses.\n",
        "\n",
        "Now, suppose that the coin was in fact fair,\n",
        "i.e., $P(\\textrm{heads}) = 0.5$.\n",
        "To simulate tosses of a fair coin,\n",
        "we can invoke any random number generator.\n",
        "There are some easy ways to draw samples\n",
        "of an event with probability $0.5$.\n",
        "For example Python's `random.random`\n",
        "yields numbers in the interval $[0,1]$\n",
        "where the probability of lying\n",
        "in any sub-interval $[a, b] \\subset [0,1]$\n",
        "is equal to $b-a$.\n",
        "Thus we can get out `0` and `1` with probability `0.5` each\n",
        "by testing whether the returned float number is greater than `0.5`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3a500e66",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.245216Z",
          "iopub.status.busy": "2023-08-18T19:35:44.244448Z",
          "iopub.status.idle": "2023-08-18T19:35:44.250559Z",
          "shell.execute_reply": "2023-08-18T19:35:44.249469Z"
        },
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a500e66",
        "outputId": "94229d73-2765-4da9-bd0e-05e8b0a0e4e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heads, tails:  [55, 45]\n"
          ]
        }
      ],
      "source": [
        "num_tosses = 100\n",
        "heads = sum([random.random() > 0.5 for _ in range(num_tosses)])\n",
        "tails = num_tosses - heads\n",
        "print(\"heads, tails: \", [heads, tails])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "096c1837",
      "metadata": {
        "origin_pos": 8,
        "id": "096c1837"
      },
      "source": [
        "More generally, we can simulate multiple draws\n",
        "from any variable with a finite number\n",
        "of possible outcomes\n",
        "(like the toss of a coin or roll of a die)\n",
        "by calling the multinomial function,\n",
        "setting the first argument\n",
        "to the number of draws\n",
        "and the second as a list of probabilities\n",
        "associated with each of the possible outcomes.\n",
        "To simulate ten tosses of a fair coin,\n",
        "we assign probability vector `[0.5, 0.5]`,\n",
        "interpreting index 0 as heads\n",
        "and index 1 as tails.\n",
        "The function returns a vector\n",
        "with length equal to the number\n",
        "of possible outcomes (here, 2),\n",
        "where the first component tells us\n",
        "the number of occurrences of heads\n",
        "and the second component tells us\n",
        "the number of occurrences of tails.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b70ba754",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.256289Z",
          "iopub.status.busy": "2023-08-18T19:35:44.255841Z",
          "iopub.status.idle": "2023-08-18T19:35:44.292323Z",
          "shell.execute_reply": "2023-08-18T19:35:44.291255Z"
        },
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b70ba754",
        "outputId": "a6aee97c-1b98-47ba-a7e7-2a11c6212229"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([53., 47.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "fair_probs = torch.tensor([0.5, 0.5])\n",
        "Multinomial(100, fair_probs).sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca81b0bc",
      "metadata": {
        "origin_pos": 13,
        "id": "ca81b0bc"
      },
      "source": [
        "Each time you run this sampling process,\n",
        "you will receive a new random value\n",
        "that may differ from the previous outcome.\n",
        "Dividing by the number of tosses\n",
        "gives us the *frequency*\n",
        "of each outcome in our data.\n",
        "Note that these frequencies,\n",
        "just like the probabilities\n",
        "that they are intended\n",
        "to estimate, sum to $1$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d4157453",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.297194Z",
          "iopub.status.busy": "2023-08-18T19:35:44.296806Z",
          "iopub.status.idle": "2023-08-18T19:35:44.309679Z",
          "shell.execute_reply": "2023-08-18T19:35:44.308709Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4157453",
        "outputId": "23851751-3440-4513-d0fa-b61c2a895db2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5300, 0.4700])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "Multinomial(100, fair_probs).sample() / 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5135ef92",
      "metadata": {
        "origin_pos": 18,
        "id": "5135ef92"
      },
      "source": [
        "Here, even though our simulated coin is fair\n",
        "(we ourselves set the probabilities `[0.5, 0.5]`),\n",
        "the counts of heads and tails may not be identical.\n",
        "That is because we only drew a relatively small number of samples.\n",
        "If we did not implement the simulation ourselves,\n",
        "and only saw the outcome,\n",
        "how would we know if the coin were slightly unfair\n",
        "or if the possible deviation from $1/2$ was\n",
        "just an artifact of the small sample size?\n",
        "Let's see what happens when we simulate 10,000 tosses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "3b639145",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.313908Z",
          "iopub.status.busy": "2023-08-18T19:35:44.313549Z",
          "iopub.status.idle": "2023-08-18T19:35:44.325094Z",
          "shell.execute_reply": "2023-08-18T19:35:44.324133Z"
        },
        "origin_pos": 20,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b639145",
        "outputId": "a555f77d-ad1e-42c5-ce6c-6226d7c08808"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4988, 0.5012])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "counts = Multinomial(10000, fair_probs).sample()\n",
        "counts / 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8725b688",
      "metadata": {
        "origin_pos": 23,
        "id": "8725b688"
      },
      "source": [
        "In general, for averages of repeated events (like coin tosses),\n",
        "as the number of repetitions grows,\n",
        "our estimates are guaranteed to converge\n",
        "to the true underlying probabilities.\n",
        "The mathematical formulation of this phenomenon\n",
        "is called the *law of large numbers*\n",
        "and the *central limit theorem*\n",
        "tells us that in many situations,\n",
        "as the sample size $n$ grows,\n",
        "these errors should go down\n",
        "at a rate of $(1/\\sqrt{n})$.\n",
        "Let's get some more intuition by studying\n",
        "how our estimate evolves as we grow\n",
        "the number of tosses from 1 to 10,000.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "fda7f94d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.329246Z",
          "iopub.status.busy": "2023-08-18T19:35:44.328647Z",
          "iopub.status.idle": "2023-08-18T19:35:44.675913Z",
          "shell.execute_reply": "2023-08-18T19:35:44.674711Z"
        },
        "origin_pos": 24,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "fda7f94d",
        "outputId": "003e42af-f136-4dcc-b4a7-fa392142926f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 450x350 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"306.596693pt\" height=\"238.79625pt\" viewBox=\"0 0 306.596693 238.79625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-06-04T04:25:17.623775</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 238.79625 \nL 306.596693 238.79625 \nL 306.596693 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 201.24 \nL 294.88125 201.24 \nL 294.88125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m3933e90a26\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m3933e90a26\" x=\"55.194886\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(52.013636 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m3933e90a26\" x=\"100.853998\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2000 -->\n      <g transform=\"translate(88.128998 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m3933e90a26\" x=\"146.513109\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4000 -->\n      <g transform=\"translate(133.788109 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m3933e90a26\" x=\"192.17222\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6000 -->\n      <g transform=\"translate(179.44722 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m3933e90a26\" x=\"237.831332\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8000 -->\n      <g transform=\"translate(225.106332 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m3933e90a26\" x=\"283.490443\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10000 -->\n      <g transform=\"translate(267.584193 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Samples -->\n     <g transform=\"translate(147.978125 229.516562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"124.755859\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"222.167969\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"285.644531\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"313.427734\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"374.951172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m027397eedd\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m027397eedd\" x=\"43.78125\" y=\"192.42\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 196.219219) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m027397eedd\" x=\"43.78125\" y=\"157.14\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 160.939219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m027397eedd\" x=\"43.78125\" y=\"121.86\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 125.659219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m027397eedd\" x=\"43.78125\" y=\"86.58\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 90.379219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m027397eedd\" x=\"43.78125\" y=\"51.3\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 55.099219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m027397eedd\" x=\"43.78125\" y=\"16.02\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 19.819219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- Estimated probability -->\n     <g transform=\"translate(14.798438 157.743437) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"115.283203\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"154.492188\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"182.275391\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"279.6875\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"340.966797\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"380.175781\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"441.699219\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"505.175781\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"536.962891\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"600.439453\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"639.302734\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"700.484375\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"763.960938\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"825.240234\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"888.716797\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"916.5\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"944.283203\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"972.066406\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"1011.275391\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 55.194886 192.42 \nL 55.217716 192.42 \nL 55.286205 86.579996 \nL 55.354693 104.22 \nL 55.468841 138.143075 \nL 55.5145 133.619998 \nL 55.605818 118.146315 \nL 55.651477 125.219999 \nL 55.674307 128.274544 \nL 55.697137 123.393914 \nL 55.719966 126.27 \nL 55.902603 109.7325 \nL 55.993921 109.120002 \nL 56.03958 113.504212 \nL 56.176557 108.229092 \nL 56.199387 110.1 \nL 56.245046 106.096596 \nL 56.267875 104.22 \nL 56.313535 107.748002 \nL 56.336364 105.949412 \nL 56.382023 109.212454 \nL 56.427682 105.823635 \nL 56.655978 97.43538 \nL 56.678807 96.201815 \nL 56.747296 97.828697 \nL 56.770126 96.659995 \nL 56.975592 107.569365 \nL 57.021251 105.308888 \nL 57.226717 98.339995 \nL 57.272376 98.467827 \nL 57.340865 99.577891 \nL 57.363694 98.7075 \nL 57.386524 97.855056 \nL 57.432183 99.765455 \nL 57.455012 98.928005 \nL 57.59199 102.555845 \nL 57.614819 101.747099 \nL 57.637649 100.953335 \nL 57.683308 102.616365 \nL 57.706137 103.425406 \nL 57.751797 101.878411 \nL 57.843115 100.450764 \nL 57.797456 101.919133 \nL 57.888774 100.514113 \nL 58.09424 104.22 \nL 58.162729 104.893281 \nL 58.276876 101.62588 \nL 58.459513 104.22 \nL 58.482342 103.611729 \nL 58.528001 104.820001 \nL 58.550831 104.22 \nL 58.573661 104.811948 \nL 58.61932 103.635891 \nL 58.710638 102.512905 \nL 58.664979 103.643524 \nL 58.756297 102.534648 \nL 58.824786 103.117496 \nL 58.847615 102.576527 \nL 58.870445 102.042224 \nL 58.916104 103.144391 \nL 58.938933 102.616365 \nL 58.984593 103.691858 \nL 59.030252 102.654322 \nL 59.12157 101.67087 \nL 59.075911 102.672627 \nL 59.144399 102.192409 \nL 59.304206 103.732706 \nL 59.327036 103.250764 \nL 59.372695 104.22 \nL 59.669479 108.249443 \nL 59.829286 106.81412 \nL 60.057582 109.990094 \nL 60.080411 109.553022 \nL 60.240218 108.192971 \nL 60.263048 108.570674 \nL 60.308707 107.748002 \nL 60.400025 106.145765 \nL 60.445684 106.892725 \nL 60.628321 109.755563 \nL 60.67398 108.977676 \nL 60.719639 108.21259 \nL 60.788128 108.52244 \nL 60.925105 109.82 \nL 60.947934 109.449251 \nL 61.084912 107.965947 \nL 61.107741 108.290769 \nL 61.244719 109.525264 \nL 61.290378 109.485673 \nL 61.473014 108.054782 \nL 61.495844 108.359348 \nL 61.541503 107.697418 \nL 61.564332 108.000002 \nL 61.67848 107.005264 \nL 61.70131 107.303916 \nL 61.746969 107.895002 \nL 61.838287 107.844659 \nL 61.906776 107.508813 \nL 61.929605 107.795674 \nL 61.952435 108.080605 \nL 61.998094 107.464816 \nL 62.043753 108.0293 \nL 62.22639 106.218056 \nL 62.249219 106.496127 \nL 62.294878 107.046922 \nL 62.340537 106.467134 \nL 62.386196 105.894685 \nL 62.431856 106.438866 \nL 62.591662 107.20523 \nL 62.660151 107.446831 \nL 62.70581 106.892725 \nL 62.751469 107.40795 \nL 62.797128 106.860719 \nL 62.819958 107.116121 \nL 62.842788 106.845001 \nL 62.888447 107.351362 \nL 62.911276 107.602301 \nL 62.956935 107.065164 \nL 63.002594 107.562856 \nL 63.071083 107.788787 \nL 63.185231 106.481538 \nL 63.299379 107.688538 \nL 63.390697 107.649998 \nL 63.413526 107.396179 \nL 63.459186 107.864626 \nL 63.504845 107.844659 \nL 63.641822 108.736984 \nL 63.710311 108.936576 \nL 63.75597 108.442343 \nL 63.801629 108.886665 \nL 63.847288 108.397894 \nL 63.870118 108.618425 \nL 64.007095 108.09442 \nL 64.029924 108.31175 \nL 64.075584 107.838461 \nL 64.144072 107.13756 \nL 64.212561 107.338182 \nL 64.303879 107.307002 \nL 64.349538 107.730448 \nL 64.555004 106.151385 \nL 64.577834 106.360777 \nL 64.851788 108.380377 \nL 64.897448 108.360847 \nL 64.965936 108.126294 \nL 64.988766 108.322328 \nL 65.080084 108.690968 \nL 65.034425 108.303334 \nL 65.102914 108.477933 \nL 65.331209 107.193033 \nL 65.468186 107.935745 \nL 65.513846 107.919337 \nL 65.650823 107.102353 \nL 65.673652 107.287824 \nL 65.719312 107.656365 \nL 65.7878 107.444518 \nL 65.856289 107.235384 \nL 65.879118 107.417013 \nL 65.970437 107.389981 \nL 66.038925 107.925882 \nL 66.175903 107.513776 \nL 66.267221 107.849627 \nL 66.221562 107.500165 \nL 66.31288 107.834755 \nL 66.33571 107.646991 \nL 66.381369 107.992301 \nL 66.404198 107.805368 \nL 66.449857 108.147933 \nL 66.518346 107.946758 \nL 66.564005 107.578318 \nL 66.609664 107.917008 \nL 66.632494 108.085336 \nL 66.700982 107.887721 \nL 66.769471 107.345195 \nL 66.81513 107.678823 \nL 66.974937 108.826192 \nL 67.043426 108.630001 \nL 67.226062 107.895002 \nL 67.248892 108.054782 \nL 67.294551 107.708137 \nL 67.500017 106.833335 \nL 67.705483 107.593768 \nL 67.910949 106.749032 \nL 67.933778 106.902287 \nL 67.979438 106.578291 \nL 68.002267 106.731031 \nL 68.047926 106.409363 \nL 68.116415 106.553335 \nL 68.321881 107.282499 \nL 68.458858 106.947835 \nL 68.504517 107.240547 \nL 68.550176 106.929214 \nL 68.595836 106.620001 \nL 68.664324 106.757054 \nL 68.755642 107.03647 \nL 68.709983 106.748501 \nL 68.801302 107.027034 \nL 69.006768 106.257621 \nL 69.098086 106.533442 \nL 69.143745 106.525882 \nL 69.303552 105.787366 \nL 69.326381 105.927095 \nL 69.440529 106.05456 \nL 69.463359 105.910735 \nL 69.509018 106.18624 \nL 69.531847 106.042894 \nL 69.691654 106.716227 \nL 69.737313 106.708399 \nL 69.942779 105.719538 \nL 69.965609 105.853332 \nL 70.034098 105.710323 \nL 70.079757 105.975897 \nL 70.148245 105.564511 \nL 70.193904 105.828508 \nL 70.330882 106.3453 \nL 70.353711 106.209471 \nL 70.467859 105.536417 \nL 70.536348 105.661605 \nL 70.696155 106.035881 \nL 70.718984 105.903701 \nL 70.764643 106.157042 \nL 70.833132 106.534283 \nL 70.878791 106.271164 \nL 70.901621 106.140172 \nL 70.94728 106.389901 \nL 70.970109 106.259309 \nL 70.992939 106.383635 \nL 71.038598 106.123596 \nL 71.107087 105.989056 \nL 71.129916 106.112703 \nL 71.47236 107.431765 \nL 71.518019 107.176426 \nL 71.563678 107.413869 \nL 71.700655 108.11834 \nL 71.769144 107.980935 \nL 71.95178 107.460001 \nL 71.997439 107.690557 \nL 72.043098 107.442463 \nL 72.202905 107.057536 \nL 72.317053 107.390974 \nL 72.339883 107.269466 \nL 72.522519 106.773157 \nL 72.636667 107.102353 \nL 72.659496 106.983447 \nL 72.956281 105.918332 \nL 72.97911 106.029231 \nL 73.024769 105.799026 \nL 73.047599 105.684368 \nL 73.093258 105.905352 \nL 73.161747 105.787003 \nL 73.207406 106.006331 \nL 73.321554 105.662262 \nL 73.344383 105.771258 \nL 73.48136 106.199551 \nL 73.50419 106.087248 \nL 73.595508 105.640818 \nL 73.641167 105.855351 \nL 73.755315 105.953659 \nL 73.869463 105.835385 \nL 73.892292 105.940974 \nL 73.937952 105.722188 \nL 73.960781 105.613197 \nL 74.00644 105.823635 \nL 74.02927 105.714917 \nL 74.257565 106.330049 \nL 74.50869 105.573721 \nL 74.668497 105.872458 \nL 74.736986 105.969594 \nL 74.805475 105.655811 \nL 74.828304 105.756585 \nL 74.873963 105.548619 \nL 75.03377 105.233795 \nL 75.0566 105.333891 \nL 75.102259 105.129278 \nL 75.125088 105.229153 \nL 75.216407 104.822735 \nL 75.262066 105.021817 \nL 75.444702 105.411891 \nL 75.53602 105.208787 \nL 75.55885 105.306449 \nL 75.672998 105.398617 \nL 75.718657 105.200003 \nL 75.764316 105.393391 \nL 75.787146 105.489765 \nL 75.832805 105.292044 \nL 75.855634 105.388213 \nL 75.901293 105.191365 \nL 75.946952 105.383077 \nL 76.106759 105.855115 \nL 76.129589 105.757253 \nL 76.198078 105.656484 \nL 76.220907 105.750587 \nL 76.289396 105.840973 \nL 76.312225 105.743974 \nL 76.472032 105.448938 \nL 76.540521 105.727692 \nL 76.58618 105.536417 \nL 76.677498 105.343564 \nL 76.700328 105.435906 \nL 76.791646 105.617045 \nL 76.814476 105.522533 \nL 76.951453 105.329433 \nL 77.225408 106.046085 \nL 77.362385 105.853332 \nL 77.522192 106.111931 \nL 77.750487 105.557713 \nL 77.978783 106.074053 \nL 78.047272 106.156527 \nL 78.184249 105.62 \nL 78.412544 106.126088 \nL 78.526692 106.030555 \nL 78.709329 106.3587 \nL 78.891965 105.832898 \nL 78.914795 105.916155 \nL 78.983283 105.995837 \nL 79.006113 105.909657 \nL 79.074602 105.820575 \nL 79.097431 105.903207 \nL 79.120261 105.985681 \nL 79.16592 105.814482 \nL 79.188749 105.896804 \nL 79.348556 105.635866 \nL 79.554022 106.036853 \nL 79.827977 105.363331 \nL 79.896466 105.604486 \nL 79.964954 105.519447 \nL 80.033443 105.434875 \nL 80.056273 105.514679 \nL 80.216079 106.069227 \nL 80.284568 105.983998 \nL 80.444375 105.733822 \nL 80.581352 105.88415 \nL 80.672671 105.720269 \nL 80.6955 105.797817 \nL 80.741159 105.952498 \nL 80.786818 105.792192 \nL 80.855307 105.866402 \nL 80.923796 105.627449 \nL 80.969455 105.781063 \nL 81.015114 105.622476 \nL 81.174921 105.226672 \nL 81.19775 105.303158 \nL 81.22058 105.379507 \nL 81.266239 105.22315 \nL 81.380387 105.141953 \nL 81.448875 105.216179 \nL 81.471705 105.138752 \nL 81.540194 105.212725 \nL 81.608682 104.981658 \nL 81.677171 104.903721 \nL 81.791319 105.279007 \nL 81.905467 105.048524 \nL 81.928296 105.12307 \nL 82.042444 105.194172 \nL 82.133762 104.89214 \nL 82.179421 105.040117 \nL 82.24791 105.261148 \nL 82.316399 105.184342 \nL 82.453376 105.031885 \nL 82.658842 105.392093 \nL 82.795819 104.948927 \nL 82.841478 105.093267 \nL 83.024115 105.521313 \nL 83.046944 105.448008 \nL 83.206751 105.225536 \nL 83.298069 105.365455 \nL 83.320899 105.292991 \nL 83.389388 105.219028 \nL 83.412217 105.289521 \nL 83.435047 105.359903 \nL 83.480706 105.215806 \nL 83.663342 104.926732 \nL 83.686172 104.996783 \nL 83.731831 104.85453 \nL 83.754661 104.924471 \nL 83.77749 104.853521 \nL 83.823149 104.993066 \nL 83.891638 104.921112 \nL 83.937297 105.06 \nL 84.142763 104.706526 \nL 84.256911 104.773844 \nL 84.27974 104.704234 \nL 84.325399 104.841614 \nL 84.348229 104.91014 \nL 84.393888 104.771252 \nL 84.416718 104.839674 \nL 84.508036 104.700465 \nL 84.530865 104.768676 \nL 84.576525 104.904783 \nL 84.622184 104.766978 \nL 84.850479 104.355692 \nL 84.873309 104.423383 \nL 84.918968 104.287691 \nL 85.055945 104.017863 \nL 85.078775 104.085344 \nL 85.3299 104.553838 \nL 85.489707 104.352832 \nL 85.581025 104.484865 \nL 85.603855 104.418499 \nL 85.626684 104.352233 \nL 85.672343 104.484071 \nL 85.695173 104.417905 \nL 85.763661 104.483282 \nL 85.786491 104.417316 \nL 85.85498 104.22 \nL 85.923468 104.285478 \nL 85.969127 104.416144 \nL 86.014787 104.285283 \nL 86.083275 104.350282 \nL 86.128934 104.22 \nL 86.197423 104.414703 \nL 86.243082 104.284805 \nL 86.288741 104.155285 \nL 86.3344 104.284615 \nL 86.448548 104.348758 \nL 86.562696 104.284147 \nL 86.676844 104.475654 \nL 86.699673 104.411601 \nL 86.745332 104.283774 \nL 86.790991 104.411049 \nL 86.973628 104.663218 \nL 86.996457 104.599628 \nL 87.042117 104.725447 \nL 87.064946 104.661946 \nL 87.316071 105.096989 \nL 87.338901 105.033767 \nL 87.38456 105.157635 \nL 87.407389 105.094502 \nL 87.430219 105.156305 \nL 87.475878 105.030318 \nL 87.612855 104.902759 \nL 87.635685 104.964304 \nL 87.681344 104.839385 \nL 87.704174 104.90084 \nL 87.772662 104.714118 \nL 87.818321 104.836782 \nL 88.000958 105.201364 \nL 88.023787 105.139388 \nL 88.183594 104.95195 \nL 88.343401 105.13053 \nL 88.434719 105.006961 \nL 88.457549 105.066913 \nL 88.480379 105.126787 \nL 88.526038 105.004805 \nL 88.548867 105.064595 \nL 88.571697 105.003733 \nL 88.617356 105.12307 \nL 88.640185 105.062292 \nL 88.685845 105.181308 \nL 88.731504 105.06 \nL 88.777163 104.939023 \nL 88.822822 105.057718 \nL 88.891311 105.115736 \nL 88.91414 105.055453 \nL 88.982629 105.113318 \nL 89.028288 104.993161 \nL 89.165265 105.226982 \nL 89.188095 105.167114 \nL 89.370731 104.926542 \nL 89.393561 104.984912 \nL 89.43922 104.866369 \nL 89.462049 104.92466 \nL 89.621856 104.629147 \nL 89.644686 104.687285 \nL 89.758834 104.860397 \nL 89.781663 104.801796 \nL 89.804493 104.743268 \nL 89.850152 104.85871 \nL 89.872981 104.916317 \nL 89.918641 104.799499 \nL 90.055618 104.450888 \nL 90.101277 104.565882 \nL 90.124107 104.623264 \nL 90.169766 104.50767 \nL 90.420891 104.105752 \nL 90.46655 104.22 \nL 90.512209 104.106046 \nL 90.580698 104.049396 \nL 90.603527 104.106341 \nL 90.626357 104.163202 \nL 90.672016 104.049837 \nL 90.717675 103.936767 \nL 90.763334 104.050279 \nL 90.900311 104.276356 \nL 90.923141 104.22 \nL 91.105777 103.995857 \nL 91.219925 104.164138 \nL 91.242755 104.10836 \nL 91.379732 103.77511 \nL 91.425391 103.886751 \nL 91.562369 103.998675 \nL 91.608028 103.888422 \nL 91.653687 103.999222 \nL 91.881982 104.329701 \nL 92.064619 104.110841 \nL 92.315744 104.491052 \nL 92.384233 104.328223 \nL 92.429892 104.436178 \nL 92.52121 104.651295 \nL 92.589699 104.596694 \nL 92.795165 104.32704 \nL 92.840824 104.433818 \nL 92.886483 104.326778 \nL 92.932142 104.22 \nL 93.000631 104.273228 \nL 93.206097 104.64353 \nL 93.228926 104.590365 \nL 93.297415 104.642516 \nL 93.343074 104.536505 \nL 93.480051 104.640502 \nL 93.54854 104.482341 \nL 93.617029 104.53425 \nL 93.639858 104.586411 \nL 93.685517 104.481411 \nL 93.776835 104.376473 \nL 93.799665 104.428508 \nL 93.845324 104.532394 \nL 93.890983 104.428019 \nL 94.119279 104.116603 \nL 94.393233 104.528031 \nL 94.416063 104.476543 \nL 94.461722 104.578747 \nL 94.484552 104.629756 \nL 94.530211 104.526959 \nL 94.735677 104.270894 \nL 94.895484 104.625519 \nL 94.941143 104.523788 \nL 94.986802 104.422294 \nL 95.055291 104.472432 \nL 95.123779 104.522401 \nL 95.146609 104.471859 \nL 95.169438 104.421369 \nL 95.215097 104.521712 \nL 95.237927 104.47128 \nL 95.511882 104.868898 \nL 95.6032 104.767824 \nL 95.626029 104.817289 \nL 95.648859 104.866701 \nL 95.694518 104.766589 \nL 95.717348 104.71662 \nL 95.763007 104.815275 \nL 95.831495 104.863793 \nL 95.854325 104.81394 \nL 96.014132 104.663712 \nL 96.288087 105.150486 \nL 96.310916 105.101021 \nL 96.425064 104.952155 \nL 96.447893 105.000531 \nL 96.584871 105.192438 \nL 96.6077 105.143304 \nL 96.63053 105.094229 \nL 96.676189 105.190298 \nL 96.904485 105.570982 \nL 96.927314 105.522023 \nL 97.064291 105.421633 \nL 97.087121 105.46902 \nL 97.13278 105.371685 \nL 97.201269 105.417716 \nL 97.246928 105.320706 \nL 97.315417 105.366696 \nL 97.338246 105.31832 \nL 97.361076 105.270001 \nL 97.406735 105.364214 \nL 97.498053 105.552041 \nL 97.543712 105.455562 \nL 97.63503 105.358063 \nL 97.65786 105.404847 \nL 97.863326 105.634972 \nL 97.886155 105.587075 \nL 97.931815 105.679795 \nL 97.954644 105.631955 \nL 98.068792 105.769013 \nL 98.091621 105.721279 \nL 98.137281 105.625951 \nL 98.18294 105.718087 \nL 98.297087 105.8542 \nL 98.319917 105.806665 \nL 98.456894 105.522533 \nL 98.525383 105.566919 \nL 98.593872 105.518422 \nL 98.639531 105.609706 \nL 98.66236 105.562676 \nL 98.708019 105.653772 \nL 98.730849 105.606794 \nL 98.867826 105.694609 \nL 98.936315 105.646291 \nL 98.959145 105.691534 \nL 98.981974 105.736729 \nL 99.027633 105.643321 \nL 99.118951 105.457092 \nL 99.164611 105.547346 \nL 99.18744 105.592405 \nL 99.233099 105.499585 \nL 99.255929 105.544597 \nL 99.461395 105.311133 \nL 99.575543 105.44437 \nL 99.598372 105.398417 \nL 99.621202 105.352512 \nL 99.666861 105.441857 \nL 99.781009 105.483867 \nL 99.917986 105.39 \nL 100.009304 105.477432 \nL 100.032134 105.43191 \nL 100.100622 105.385243 \nL 100.123452 105.429445 \nL 100.146282 105.473605 \nL 100.191941 105.382882 \nL 100.260429 105.42577 \nL 100.306088 105.335326 \nL 100.511554 105.552325 \nL 100.602873 105.461003 \nL 100.625702 105.50468 \nL 100.76268 105.589156 \nL 101.013805 105.274181 \nL 101.082293 105.228754 \nL 101.127952 105.315381 \nL 101.424737 104.916543 \nL 101.607373 105.087258 \nL 101.675862 105.129278 \nL 101.721521 105.041873 \nL 101.926987 105.253594 \nL 102.063964 105.164696 \nL 102.246601 105.332125 \nL 102.360748 105.201422 \nL 102.383578 105.2436 \nL 102.406408 105.285731 \nL 102.452067 105.199524 \nL 102.543385 105.112629 \nL 102.566214 105.154681 \nL 102.703192 105.236713 \nL 102.840169 105.149308 \nL 102.977146 105.230888 \nL 103.045635 105.18738 \nL 103.068465 105.228959 \nL 103.205442 105.309924 \nL 103.29676 105.224175 \nL 103.31959 105.265517 \nL 103.456567 105.345956 \nL 103.593544 105.259603 \nL 103.639204 105.341714 \nL 103.707692 105.298647 \nL 103.82184 105.171945 \nL 103.84467 105.212872 \nL 103.935988 105.376179 \nL 104.004476 105.333323 \nL 104.027306 105.291587 \nL 104.072965 105.372941 \nL 104.095795 105.331247 \nL 104.164283 105.370791 \nL 104.187113 105.329176 \nL 104.34692 105.120835 \nL 104.369749 105.161347 \nL 104.415408 105.242254 \nL 104.483897 105.200003 \nL 104.598045 104.994044 \nL 104.666534 105.033651 \nL 104.780681 105.07237 \nL 104.940488 104.948254 \nL 105.054636 105.067691 \nL 105.077466 105.026954 \nL 105.100295 104.986253 \nL 105.145954 105.06614 \nL 105.37425 105.302948 \nL 105.511227 105.220001 \nL 105.648204 105.376852 \nL 105.671034 105.336457 \nL 105.762352 105.25484 \nL 105.785182 105.294153 \nL 105.89933 105.410819 \nL 105.922159 105.370607 \nL 106.036307 105.32844 \nL 106.104796 105.445547 \nL 106.150455 105.365455 \nL 106.173284 105.325459 \nL 106.218943 105.403364 \nL 106.40158 105.556362 \nL 106.515728 105.514174 \nL 106.675534 105.783828 \nL 106.721194 105.704324 \nL 106.881 105.582916 \nL 106.995148 105.618764 \nL 107.086466 105.538735 \nL 107.109296 105.576923 \nL 107.200614 105.574542 \nL 107.246273 105.496021 \nL 107.291932 105.572171 \nL 107.337592 105.648183 \nL 107.383251 105.569805 \nL 107.520228 105.412412 \nL 107.543058 105.450342 \nL 107.680035 105.523826 \nL 107.794183 105.482731 \nL 108.045308 105.743316 \nL 108.068137 105.704592 \nL 108.113796 105.77938 \nL 108.296433 105.925628 \nL 108.479069 105.768693 \nL 108.616047 105.840079 \nL 108.798683 105.684368 \nL 108.98132 105.829081 \nL 109.095467 105.788333 \nL 109.278104 105.9319 \nL 109.574888 105.589451 \nL 109.666206 105.661058 \nL 109.689036 105.623517 \nL 110.031479 105.211011 \nL 110.122797 105.355934 \nL 110.168456 105.281767 \nL 110.373922 105.02248 \nL 110.396752 105.058612 \nL 110.419582 105.094713 \nL 110.465241 105.021155 \nL 110.556559 105.019835 \nL 110.625048 105.055158 \nL 110.647877 105.018516 \nL 110.762025 104.980659 \nL 110.967491 105.158298 \nL 111.081639 105.120368 \nL 111.218616 105.190019 \nL 111.378423 105.079788 \nL 111.5154 105.149171 \nL 111.675207 105.039634 \nL 111.720866 105.11019 \nL 111.766525 105.038314 \nL 111.789355 105.002419 \nL 111.835014 105.072859 \nL 111.857844 105.10804 \nL 111.903503 105.036338 \nL 111.971991 104.999906 \nL 111.994821 105.035029 \nL 112.154628 105.138752 \nL 112.291605 105.066046 \nL 112.314435 105.100942 \nL 112.360094 105.029819 \nL 112.54273 104.886851 \nL 112.588389 104.956461 \nL 112.634048 104.885794 \nL 112.656878 104.850498 \nL 112.702537 104.920003 \nL 112.793855 104.918888 \nL 112.930833 104.777787 \nL 112.953662 104.812415 \nL 113.06781 104.846024 \nL 113.227617 104.740251 \nL 113.341765 104.843075 \nL 113.364594 104.808231 \nL 113.455912 104.738216 \nL 113.478742 104.772545 \nL 113.684208 104.942671 \nL 113.798356 104.906918 \nL 113.958163 105.007807 \nL 114.049481 104.938187 \nL 114.07231 104.972095 \nL 114.232117 105.072338 \nL 114.483242 104.831083 \nL 114.665879 104.964588 \nL 114.780027 104.929381 \nL 114.802856 104.96288 \nL 114.848515 104.894826 \nL 115.031152 104.758214 \nL 115.09964 104.8584 \nL 115.1453 104.790767 \nL 115.168129 104.756984 \nL 115.213788 104.82365 \nL 115.305106 104.822735 \nL 115.419254 104.78817 \nL 115.510572 104.854052 \nL 115.533402 104.820454 \nL 115.670379 104.752526 \nL 115.693209 104.785599 \nL 115.738868 104.718681 \nL 115.853016 104.684562 \nL 116.012823 104.782629 \nL 116.286777 104.516528 \nL 116.423755 104.581612 \nL 116.446584 104.548613 \nL 116.492243 104.614043 \nL 116.65205 104.711274 \nL 116.789028 104.579467 \nL 116.811857 104.611998 \nL 116.834687 104.644508 \nL 116.880346 104.578936 \nL 116.994494 104.5457 \nL 117.222789 104.739205 \nL 117.245619 104.706574 \nL 117.291278 104.771047 \nL 117.314107 104.803247 \nL 117.359766 104.738064 \nL 117.451085 104.737302 \nL 117.725039 104.992556 \nL 118.067483 104.508133 \nL 118.113142 104.571902 \nL 118.318608 104.730194 \nL 118.524074 104.633189 \nL 118.683881 104.72726 \nL 118.912176 104.599081 \nL 119.026324 104.693005 \nL 119.049154 104.661315 \nL 119.391597 104.314066 \nL 119.574233 104.376326 \nL 119.711211 104.375995 \nL 119.848188 104.437929 \nL 119.871018 104.406733 \nL 120.190631 104.15806 \nL 120.350438 104.127317 \nL 120.441757 104.189151 \nL 120.487416 104.127517 \nL 120.647223 104.096983 \nL 120.7842 104.22 \nL 120.829859 104.15866 \nL 121.149473 103.914813 \nL 121.332109 104.037388 \nL 121.354939 104.007034 \nL 121.491916 104.007465 \nL 121.720212 104.12923 \nL 121.994166 103.948806 \nL 122.222462 104.069846 \nL 122.382269 103.920407 \nL 122.427928 103.980485 \nL 122.564905 103.980979 \nL 122.793201 103.862673 \nL 122.884519 103.863157 \nL 122.907349 103.833548 \nL 123.067155 103.804802 \nL 123.226962 103.835367 \nL 123.36394 103.836135 \nL 123.592235 103.955135 \nL 123.752042 103.867667 \nL 123.774872 103.897139 \nL 123.934679 103.985742 \nL 123.957508 103.956544 \nL 124.140145 103.898852 \nL 124.231463 103.957585 \nL 124.277122 103.899483 \nL 124.39127 103.870927 \nL 124.414099 103.900114 \nL 124.505417 103.958626 \nL 124.551077 103.900745 \nL 124.688054 103.901376 \nL 124.916349 104.017905 \nL 125.076156 103.931951 \nL 125.098986 103.960845 \nL 125.372941 104.133951 \nL 125.578407 104.048407 \nL 125.875191 104.248478 \nL 126.057827 104.19159 \nL 126.103486 104.248389 \nL 126.171975 104.163276 \nL 126.44593 103.993996 \nL 126.765543 104.22 \nL 126.92535 104.191937 \nL 127.062328 104.304025 \nL 127.107987 104.247989 \nL 127.199305 104.247957 \nL 127.222135 104.275894 \nL 127.496089 104.442729 \nL 127.541748 104.38694 \nL 127.610237 104.470171 \nL 127.815703 104.552619 \nL 128.043999 104.441052 \nL 128.295124 104.633053 \nL 128.317953 104.605395 \nL 128.340783 104.577753 \nL 128.409271 104.659901 \nL 128.569078 104.686376 \nL 128.637567 104.658534 \nL 128.683226 104.713045 \nL 128.820203 104.766805 \nL 128.843033 104.739305 \nL 128.957181 104.71121 \nL 128.98001 104.738342 \nL 129.094158 104.81926 \nL 129.139817 104.764444 \nL 129.322454 104.708792 \nL 129.390942 104.735472 \nL 129.436601 104.680929 \nL 129.52792 104.572044 \nL 129.596408 104.652883 \nL 129.756215 104.678953 \nL 129.938852 104.623968 \nL 130.121488 104.676718 \nL 130.349784 104.568195 \nL 130.53242 104.620788 \nL 130.715057 104.566508 \nL 130.852034 104.619095 \nL 130.874863 104.592378 \nL 131.0575 104.538414 \nL 131.354284 104.722187 \nL 131.422773 104.695329 \nL 131.468432 104.747826 \nL 131.536921 104.773723 \nL 131.58258 104.720689 \nL 131.765216 104.666914 \nL 131.947853 104.718308 \nL 132.130489 104.664795 \nL 132.267466 104.664001 \nL 132.518591 104.532394 \nL 132.792546 104.686944 \nL 133.043671 104.556146 \nL 133.249137 104.735788 \nL 133.294796 104.683942 \nL 133.591581 104.502445 \nL 133.751387 104.527495 \nL 133.956853 104.45002 \nL 134.162319 104.525897 \nL 134.207979 104.474766 \nL 134.276467 104.55091 \nL 134.344956 104.576055 \nL 134.390615 104.525013 \nL 134.459104 104.448564 \nL 134.527592 104.524488 \nL 134.66457 104.523962 \nL 134.710229 104.473157 \nL 134.778717 104.548823 \nL 134.961354 104.59854 \nL 135.235309 104.446346 \nL 135.372286 104.445962 \nL 135.463604 104.395546 \nL 135.509263 104.445573 \nL 135.897366 104.768755 \nL 135.920195 104.743663 \nL 136.102832 104.692721 \nL 136.216979 104.766589 \nL 136.262639 104.71662 \nL 136.468105 104.641059 \nL 136.71923 104.81261 \nL 136.742059 104.787759 \nL 137.016014 104.638241 \nL 137.175821 104.71109 \nL 137.19865 104.686407 \nL 137.426946 104.587195 \nL 137.632412 104.659533 \nL 137.74656 104.683311 \nL 137.837878 104.780231 \nL 137.906367 104.706752 \nL 138.089003 104.608544 \nL 138.111833 104.632716 \nL 138.340128 104.728428 \nL 138.499935 104.654959 \nL 138.522765 104.679 \nL 138.75106 104.774112 \nL 138.888037 104.773202 \nL 139.093503 104.843832 \nL 139.27614 104.746712 \nL 139.298969 104.7705 \nL 139.458776 104.793348 \nL 139.550095 104.744998 \nL 139.595754 104.792417 \nL 139.755561 104.815144 \nL 139.915368 104.790257 \nL 140.006686 104.789647 \nL 140.029515 104.765764 \nL 140.143663 104.646542 \nL 140.212152 104.717235 \nL 140.3263 104.692921 \nL 140.577425 104.526496 \nL 140.600254 104.549985 \nL 140.691572 104.596721 \nL 140.737232 104.549454 \nL 140.988357 104.384243 \nL 141.011186 104.407659 \nL 141.125334 104.430837 \nL 141.148164 104.407359 \nL 141.262311 104.290167 \nL 141.3308 104.360223 \nL 141.513436 104.40657 \nL 141.696073 104.359629 \nL 141.83305 104.452349 \nL 141.878709 104.405782 \nL 142.129834 104.243158 \nL 142.152664 104.2663 \nL 142.243982 104.266252 \nL 142.266812 104.243121 \nL 142.426619 104.22 \nL 142.540766 104.289142 \nL 142.586426 104.243037 \nL 142.723403 104.243 \nL 142.837551 104.22 \nL 142.974528 104.174137 \nL 142.997358 104.197068 \nL 143.157164 104.22 \nL 143.225653 104.197131 \nL 143.271312 104.242858 \nL 143.431119 104.311259 \nL 143.453949 104.288427 \nL 143.636585 104.242763 \nL 143.727903 104.197258 \nL 143.91054 104.151931 \nL 144.138835 104.242632 \nL 144.252983 104.265206 \nL 144.43562 104.310228 \nL 144.663915 104.22 \nL 144.778063 104.197531 \nL 144.91504 104.197563 \nL 145.097677 104.24239 \nL 145.234654 104.242359 \nL 145.41729 104.286939 \nL 145.668416 104.175504 \nL 145.9652 104.330889 \nL 146.125007 104.308556 \nL 146.284814 104.3305 \nL 146.376132 104.374544 \nL 146.49028 104.352301 \nL 146.581598 104.396224 \nL 146.695746 104.374002 \nL 146.809893 104.395783 \nL 146.901212 104.351707 \nL 147.083848 104.307631 \nL 147.243655 104.329348 \nL 147.403462 104.307326 \nL 147.631757 104.394221 \nL 147.768735 104.393964 \nL 147.882882 104.372031 \nL 148.134008 104.263319 \nL 148.339474 104.32806 \nL 148.476451 104.327903 \nL 148.613428 104.327745 \nL 148.750406 104.327587 \nL 148.887383 104.327429 \nL 149.04719 104.305796 \nL 149.275485 104.391177 \nL 149.503781 104.305381 \nL 149.709247 104.369092 \nL 149.869054 104.34758 \nL 150.028861 104.368593 \nL 150.257156 104.283527 \nL 150.462622 104.346786 \nL 150.645259 104.304361 \nL 150.919213 104.430301 \nL 151.147509 104.345882 \nL 151.307316 104.366616 \nL 151.398634 104.408326 \nL 151.512782 104.387203 \nL 151.786736 104.261684 \nL 152.037862 104.365512 \nL 152.152009 104.386104 \nL 152.266157 104.36517 \nL 152.448794 104.323497 \nL 152.6086 104.343995 \nL 152.699919 104.385168 \nL 152.973873 104.508238 \nL 153.065192 104.549107 \nL 153.293487 104.630424 \nL 153.453294 104.609269 \nL 153.63593 104.649444 \nL 153.772908 104.64885 \nL 153.909885 104.648256 \nL 154.024033 104.668128 \nL 154.275158 104.768581 \nL 154.526283 104.665862 \nL 154.800238 104.785904 \nL 154.914386 104.805444 \nL 155.051363 104.80464 \nL 155.18834 104.803841 \nL 155.439465 104.902785 \nL 155.69059 104.800923 \nL 155.850397 104.820001 \nL 156.101522 104.718754 \nL 156.306988 104.777471 \nL 156.489625 104.736718 \nL 156.626602 104.736024 \nL 156.71792 104.775216 \nL 156.877727 104.794142 \nL 157.106023 104.713839 \nL 157.243 104.713177 \nL 157.471296 104.633347 \nL 157.631103 104.652352 \nL 157.74525 104.671503 \nL 158.042035 104.807216 \nL 158.247501 104.747443 \nL 158.407308 104.766132 \nL 158.589944 104.726225 \nL 158.749751 104.744882 \nL 158.863899 104.763724 \nL 159.046535 104.801538 \nL 159.160683 104.820264 \nL 159.366149 104.877057 \nL 159.548785 104.837324 \nL 159.662933 104.817378 \nL 159.777081 104.835978 \nL 159.936888 104.854257 \nL 160.188013 104.756869 \nL 160.279331 104.718087 \nL 160.393479 104.736686 \nL 160.644604 104.83091 \nL 160.827241 104.791739 \nL 161.055536 104.866574 \nL 161.283832 104.789279 \nL 161.466468 104.826184 \nL 161.649105 104.787323 \nL 161.740423 104.749051 \nL 161.8774 104.748368 \nL 162.037207 104.766421 \nL 162.242673 104.708955 \nL 162.425309 104.745671 \nL 162.722094 104.613165 \nL 162.973219 104.705643 \nL 163.155855 104.667529 \nL 163.247173 104.629888 \nL 163.384151 104.629367 \nL 163.658105 104.739699 \nL 163.977719 104.590123 \nL 164.160356 104.62645 \nL 164.251674 104.663029 \nL 164.388651 104.662477 \nL 164.616947 104.587962 \nL 164.708265 104.550889 \nL 164.868072 104.532047 \nL 165.073538 104.586432 \nL 165.164856 104.622738 \nL 165.256174 104.585823 \nL 165.438811 104.548697 \nL 165.644277 104.602766 \nL 165.826913 104.56574 \nL 166.00955 104.601505 \nL 166.306334 104.473657 \nL 166.443311 104.473346 \nL 166.625948 104.436799 \nL 166.762925 104.436531 \nL 166.968391 104.382098 \nL 167.173857 104.435737 \nL 167.265175 104.471485 \nL 167.447812 104.506945 \nL 167.630448 104.47067 \nL 167.790255 104.488192 \nL 167.881573 104.523704 \nL 168.018551 104.523336 \nL 168.178357 104.505089 \nL 168.360994 104.540212 \nL 168.475142 104.55766 \nL 168.56646 104.521875 \nL 168.749096 104.485932 \nL 168.977392 104.556167 \nL 169.114369 104.555762 \nL 169.297006 104.590512 \nL 169.433983 104.59007 \nL 169.548131 104.572096 \nL 169.753597 104.518747 \nL 169.913404 104.53588 \nL 170.027551 104.553097 \nL 170.164529 104.552697 \nL 170.301506 104.587279 \nL 170.484143 104.621624 \nL 170.826586 104.498565 \nL 170.963563 104.463452 \nL 171.1462 104.463069 \nL 171.351666 104.47997 \nL 171.64845 104.392875 \nL 171.785427 104.358136 \nL 171.899575 104.409751 \nL 172.059382 104.392266 \nL 172.333337 104.323119 \nL 172.515973 104.322956 \nL 172.65295 104.357116 \nL 172.972564 104.459305 \nL 173.132371 104.476049 \nL 173.315007 104.475654 \nL 173.520473 104.458195 \nL 173.931405 104.626923 \nL 174.114042 104.626297 \nL 174.273849 104.608844 \nL 174.410826 104.642169 \nL 174.547803 104.60795 \nL 174.70761 104.624279 \nL 174.913076 104.640402 \nL 175.141372 104.606031 \nL 175.25552 104.555363 \nL 175.529474 104.487677 \nL 175.689281 104.470618 \nL 175.917577 104.436788 \nL 176.214361 104.519436 \nL 176.465486 104.469014 \nL 176.693782 104.501682 \nL 177.036225 104.385232 \nL 177.218861 104.384985 \nL 177.355839 104.417757 \nL 177.515646 104.40104 \nL 177.766771 104.351397 \nL 178.017896 104.400299 \nL 178.33751 104.301743 \nL 178.520146 104.301622 \nL 178.657123 104.334143 \nL 178.81693 104.317709 \nL 178.931078 104.366432 \nL 179.090885 104.349993 \nL 179.433328 104.236202 \nL 179.821431 104.381541 \nL 180.118215 104.300576 \nL 180.460658 104.412858 \nL 180.734613 104.34829 \nL 180.87159 104.316111 \nL 181.099886 104.283958 \nL 181.351011 104.331709 \nL 181.602136 104.283706 \nL 181.853261 104.331262 \nL 182.150046 104.251716 \nL 182.332682 104.251669 \nL 182.583807 104.204197 \nL 182.743614 104.188436 \nL 182.94908 104.172728 \nL 183.177376 104.204271 \nL 183.519819 104.094491 \nL 183.702455 104.09467 \nL 183.885092 104.094849 \nL 184.022069 104.063727 \nL 184.318853 103.986131 \nL 184.455831 103.95523 \nL 184.615638 103.971106 \nL 184.958081 104.080371 \nL 185.186376 104.049637 \nL 185.369013 104.049879 \nL 185.642968 103.988508 \nL 185.802774 103.973378 \nL 186.0539 103.927693 \nL 186.305025 103.974313 \nL 186.601809 103.898274 \nL 187.126889 104.128442 \nL 187.355184 104.09814 \nL 187.58348 104.128757 \nL 187.697628 104.174421 \nL 187.925923 104.204828 \nL 188.10856 104.204849 \nL 188.359685 104.250239 \nL 188.542321 104.250197 \nL 188.702128 104.235077 \nL 189.181549 104.039691 \nL 189.341356 104.024897 \nL 189.523992 104.025171 \nL 189.683799 104.01043 \nL 189.912094 103.980895 \nL 190.071901 103.966249 \nL 190.277367 103.951729 \nL 190.596981 104.041573 \nL 190.893765 103.967784 \nL 191.099231 103.982988 \nL 191.373186 103.924329 \nL 191.487334 103.880253 \nL 191.852607 103.763313 \nL 192.080902 103.793489 \nL 192.354857 103.735629 \nL 192.72013 103.85402 \nL 192.902766 103.854514 \nL 193.039744 103.825663 \nL 193.268039 103.797148 \nL 193.450676 103.797716 \nL 193.587653 103.827229 \nL 193.770289 103.827745 \nL 194.044244 103.770515 \nL 194.24971 103.785656 \nL 194.455176 103.77184 \nL 194.706301 103.815948 \nL 194.866108 103.830815 \nL 195.29987 103.990085 \nL 195.505336 103.97608 \nL 195.665142 103.962022 \nL 195.893438 103.933823 \nL 196.190222 104.005814 \nL 196.3272 104.03456 \nL 196.532666 104.04907 \nL 196.669643 104.0777 \nL 196.943598 104.134782 \nL 197.080575 104.163244 \nL 197.286041 104.177491 \nL 197.468677 104.177543 \nL 197.674143 104.191738 \nL 197.902439 104.16357 \nL 198.130734 104.191832 \nL 198.3362 104.177806 \nL 198.518837 104.177859 \nL 198.929769 104.037914 \nL 199.135235 104.052161 \nL 199.363531 104.024498 \nL 199.568997 104.038724 \nL 199.842951 103.983387 \nL 200.094076 104.025486 \nL 200.390861 103.956555 \nL 200.596327 103.97077 \nL 201.098577 103.778443 \nL 201.281213 103.779 \nL 201.509509 103.752168 \nL 201.646486 103.725115 \nL 201.806293 103.739383 \nL 202.011759 103.753766 \nL 202.217225 103.740729 \nL 202.49118 103.796286 \nL 202.650987 103.810407 \nL 202.833623 103.810911 \nL 203.016259 103.811416 \nL 203.130407 103.770904 \nL 203.472851 103.676896 \nL 203.678317 103.691206 \nL 203.838123 103.705316 \nL 204.089249 103.746753 \nL 204.271885 103.747331 \nL 204.568669 103.815664 \nL 204.705647 103.842959 \nL 204.933942 103.870422 \nL 205.139408 103.857479 \nL 205.367704 103.884847 \nL 205.618829 103.845251 \nL 205.892783 103.899368 \nL 206.07542 103.899757 \nL 206.258056 103.900146 \nL 206.463522 103.887266 \nL 206.783136 103.967658 \nL 207.011432 103.941519 \nL 207.353875 104.03476 \nL 207.536511 104.034981 \nL 207.901784 104.140901 \nL 208.10725 104.127832 \nL 208.63233 104.324969 \nL 208.814967 104.324843 \nL 209.13458 104.403095 \nL 209.317217 104.40288 \nL 209.568342 104.441709 \nL 209.956444 104.32407 \nL 210.116251 104.310969 \nL 210.276058 104.323855 \nL 210.572842 104.388444 \nL 210.778308 104.37528 \nL 210.983774 104.388002 \nL 211.234899 104.34902 \nL 211.394706 104.336004 \nL 211.668661 104.284331 \nL 211.965445 104.348421 \nL 212.2394 104.296917 \nL 212.422036 104.296828 \nL 213.038434 104.05419 \nL 213.221071 104.054379 \nL 213.495025 104.003795 \nL 213.837469 104.067711 \nL 214.157083 104.118674 \nL 214.385378 104.118821 \nL 214.613674 104.118968 \nL 214.79631 104.144318 \nL 215.001776 104.131817 \nL 215.275731 104.106814 \nL 215.458367 104.081811 \nL 215.686663 104.082011 \nL 216.029106 104.144897 \nL 216.32589 104.10755 \nL 216.645504 104.15765 \nL 216.805311 104.195081 \nL 217.124925 104.244866 \nL 217.330391 104.257252 \nL 217.672834 104.319128 \nL 217.855471 104.343774 \nL 218.152255 104.380611 \nL 218.426209 104.355671 \nL 218.677335 104.367778 \nL 219.088267 104.269138 \nL 219.362221 104.293584 \nL 219.544858 104.317998 \nL 219.795983 104.330084 \nL 220.047108 104.317704 \nL 220.298233 104.329748 \nL 220.640676 104.268676 \nL 220.891802 104.280751 \nL 221.371222 104.147304 \nL 221.576688 104.135297 \nL 221.827813 104.123342 \nL 222.033279 104.111398 \nL 222.330064 104.07545 \nL 222.695336 104.147883 \nL 222.992121 104.112019 \nL 223.174757 104.088162 \nL 223.471541 104.052497 \nL 223.677007 104.040753 \nL 223.973792 104.005288 \nL 224.179258 103.993628 \nL 224.339064 104.029555 \nL 224.56736 104.029808 \nL 224.727167 104.065619 \nL 224.932633 104.053938 \nL 225.138099 104.065987 \nL 225.320735 104.042488 \nL 225.57186 104.030933 \nL 225.845815 104.054832 \nL 226.09694 104.043297 \nL 226.370895 104.067102 \nL 226.64485 104.043855 \nL 226.895975 104.055841 \nL 227.421054 103.904372 \nL 227.64935 103.904793 \nL 227.991793 103.847164 \nL 228.311407 103.894363 \nL 228.539703 103.894794 \nL 228.767998 103.895225 \nL 228.950635 103.918735 \nL 229.315908 103.988749 \nL 229.612692 103.954515 \nL 229.818158 103.943296 \nL 230.092112 103.920701 \nL 230.320408 103.92109 \nL 230.571533 103.91004 \nL 230.913976 103.967931 \nL 231.073783 104.002502 \nL 231.416227 104.060047 \nL 231.73584 104.01472 \nL 231.986966 104.026401 \nL 232.375068 103.947292 \nL 232.626193 103.959015 \nL 232.991466 103.891619 \nL 233.242591 103.903384 \nL 233.539375 103.870043 \nL 233.7905 103.881809 \nL 234.155773 103.815001 \nL 234.292751 103.770347 \nL 234.498217 103.782092 \nL 234.726512 103.782649 \nL 235.023296 103.749781 \nL 235.36574 103.806548 \nL 235.86799 103.673973 \nL 236.073456 103.663459 \nL 236.438729 103.597934 \nL 236.712684 103.621055 \nL 236.963809 103.610804 \nL 237.123616 103.578147 \nL 237.488888 103.513158 \nL 237.717184 103.514052 \nL 237.991139 103.493076 \nL 238.196605 103.482887 \nL 238.493389 103.451134 \nL 238.904321 103.540527 \nL 239.109787 103.552229 \nL 239.338083 103.55306 \nL 239.589208 103.54305 \nL 239.954481 103.609773 \nL 240.205606 103.599711 \nL 240.433901 103.600479 \nL 240.639367 103.612023 \nL 240.936151 103.645511 \nL 241.164447 103.646216 \nL 241.50689 103.7013 \nL 241.712356 103.712666 \nL 241.940652 103.713286 \nL 242.191777 103.703203 \nL 242.442902 103.714653 \nL 242.739686 103.683247 \nL 243.104959 103.748572 \nL 243.264766 103.781093 \nL 243.58438 103.82458 \nL 243.881164 103.793195 \nL 244.246437 103.85791 \nL 244.497562 103.847753 \nL 244.748687 103.858877 \nL 244.999812 103.848742 \nL 245.273767 103.870464 \nL 245.433574 103.902501 \nL 245.684699 103.913488 \nL 245.935824 103.903342 \nL 246.16412 103.903721 \nL 246.460904 103.87263 \nL 246.826177 103.936336 \nL 247.054472 103.936672 \nL 247.328427 103.958027 \nL 247.556723 103.958342 \nL 247.716529 103.927188 \nL 248.036143 103.885909 \nL 248.447075 103.96996 \nL 248.652541 103.980632 \nL 248.903666 103.991336 \nL 249.109132 104.001966 \nL 249.314598 103.99183 \nL 249.474405 104.023099 \nL 249.862508 104.09589 \nL 250.045144 104.116676 \nL 250.319099 104.137453 \nL 250.707201 104.065535 \nL 251.026815 104.106909 \nL 251.323599 104.076281 \nL 251.620383 104.107256 \nL 251.962827 104.056282 \nL 252.099804 104.015498 \nL 252.30527 104.025928 \nL 252.602054 104.056819 \nL 252.944498 104.006193 \nL 253.3326 104.077742 \nL 253.538066 104.088036 \nL 253.880509 104.138935 \nL 254.085975 104.149144 \nL 254.565396 104.260396 \nL 254.839351 104.260338 \nL 255.204624 104.300529 \nL 255.41009 104.330615 \nL 255.638385 104.310402 \nL 256.003658 104.270132 \nL 256.505908 104.370017 \nL 256.779863 104.369812 \nL 257.099477 104.389521 \nL 257.350602 104.399268 \nL 257.670216 104.418872 \nL 258.012659 104.388754 \nL 258.218125 104.358836 \nL 258.537739 104.338816 \nL 258.811693 104.338653 \nL 259.176966 104.298962 \nL 259.49658 104.318545 \nL 259.816194 104.298715 \nL 260.272785 104.377078 \nL 260.52391 104.386693 \nL 260.843524 104.406013 \nL 261.277286 104.337234 \nL 261.619729 104.366301 \nL 261.916513 104.356354 \nL 262.213297 104.36588 \nL 262.441593 104.385153 \nL 262.669888 104.365559 \nL 262.943843 104.36537 \nL 263.309116 104.40381 \nL 263.62873 104.384212 \nL 263.925514 104.393622 \nL 264.199469 104.393396 \nL 264.450594 104.383565 \nL 264.724548 104.38335 \nL 265.18114 104.459699 \nL 265.432265 104.468988 \nL 265.614901 104.430501 \nL 266.025833 104.372793 \nL 266.482424 104.448696 \nL 266.802038 104.429318 \nL 267.075993 104.42905 \nL 267.464095 104.381241 \nL 267.989175 104.484923 \nL 268.194641 104.513022 \nL 268.400107 104.484413 \nL 268.76538 104.446251 \nL 269.130653 104.483508 \nL 269.358948 104.502029 \nL 269.701392 104.52974 \nL 269.998176 104.519935 \nL 270.363449 104.556856 \nL 270.82004 104.481442 \nL 271.162483 104.508995 \nL 271.367949 104.536663 \nL 271.664733 104.545532 \nL 271.938688 104.545117 \nL 272.121324 104.507717 \nL 272.34962 104.52596 \nL 272.760552 104.580907 \nL 273.194314 104.51554 \nL 273.39978 104.487583 \nL 273.90203 104.39491 \nL 274.175984 104.394689 \nL 274.632576 104.320926 \nL 274.90653 104.3208 \nL 275.226144 104.302353 \nL 275.545758 104.320506 \nL 275.865372 104.302116 \nL 276.321963 104.374786 \nL 276.824213 104.28359 \nL 277.166656 104.310701 \nL 277.48627 104.292459 \nL 277.760225 104.29237 \nL 278.057009 104.283238 \nL 278.582089 104.38223 \nL 278.901702 104.363998 \nL 279.244146 104.390741 \nL 279.632248 104.345588 \nL 279.814885 104.309634 \nL 280.271476 104.23789 \nL 280.454112 104.202126 \nL 280.796556 104.175377 \nL 281.184658 104.22 \nL 281.390124 104.246701 \nL 281.823886 104.30884 \nL 282.09784 104.30873 \nL 282.348965 104.299772 \nL 282.691409 104.273102 \nL 283.056682 104.308357 \nL 283.307807 104.317089 \nL 283.467614 104.308199 \nL 283.467614 104.308199 \n\" clip-path=\"url(#p6315a5b485)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 55.194886 16.02 \nL 55.217716 16.02 \nL 55.286205 121.859999 \nL 55.354693 104.22 \nL 55.468841 70.29692 \nL 55.5145 74.819996 \nL 55.605818 90.293685 \nL 55.651477 83.219996 \nL 55.674307 80.165456 \nL 55.697137 85.046092 \nL 55.719966 82.17 \nL 55.902603 98.7075 \nL 55.993921 99.319998 \nL 56.03958 94.935793 \nL 56.176557 100.210913 \nL 56.199387 98.339995 \nL 56.245046 102.343404 \nL 56.267875 104.22 \nL 56.313535 100.692003 \nL 56.336364 102.490583 \nL 56.382023 99.227546 \nL 56.427682 102.616365 \nL 56.655978 111.004615 \nL 56.678807 112.238179 \nL 56.747296 110.611303 \nL 56.770126 111.78 \nL 56.975592 100.87063 \nL 57.021251 103.131112 \nL 57.226717 110.1 \nL 57.272376 109.972173 \nL 57.340865 108.862103 \nL 57.363694 109.7325 \nL 57.386524 110.584949 \nL 57.432183 108.674545 \nL 57.455012 109.512 \nL 57.59199 105.88415 \nL 57.614819 106.692896 \nL 57.637649 107.486665 \nL 57.683308 105.823635 \nL 57.706137 105.014594 \nL 57.751797 106.561594 \nL 57.843115 107.989231 \nL 57.797456 106.520872 \nL 57.888774 107.925882 \nL 58.09424 104.22 \nL 58.162729 103.546719 \nL 58.276876 106.81412 \nL 58.459513 104.22 \nL 58.482342 104.828276 \nL 58.528001 103.620004 \nL 58.550831 104.22 \nL 58.573661 103.628058 \nL 58.61932 104.804104 \nL 58.710638 105.927095 \nL 58.664979 104.796471 \nL 58.756297 105.905352 \nL 58.824786 105.322499 \nL 58.847615 105.863479 \nL 58.870445 106.397776 \nL 58.916104 105.295609 \nL 58.938933 105.823635 \nL 58.984593 104.748142 \nL 59.030252 105.785678 \nL 59.12157 106.769135 \nL 59.075911 105.767368 \nL 59.144399 106.247586 \nL 59.304206 104.707294 \nL 59.327036 105.189231 \nL 59.372695 104.22 \nL 59.669479 100.190557 \nL 59.829286 101.62588 \nL 60.057582 98.449911 \nL 60.080411 98.886978 \nL 60.240218 100.247029 \nL 60.263048 99.869326 \nL 60.308707 100.692003 \nL 60.400025 102.29424 \nL 60.445684 101.547275 \nL 60.628321 98.684432 \nL 60.67398 99.462319 \nL 60.719639 100.22741 \nL 60.788128 99.917565 \nL 60.925105 98.62 \nL 60.947934 98.990754 \nL 61.084912 100.474053 \nL 61.107741 100.149226 \nL 61.244719 98.914736 \nL 61.290378 98.954333 \nL 61.473014 100.385218 \nL 61.495844 100.080652 \nL 61.541503 100.742577 \nL 61.564332 100.439998 \nL 61.67848 101.434741 \nL 61.70131 101.136084 \nL 61.746969 100.545004 \nL 61.838287 100.595346 \nL 61.906776 100.931182 \nL 61.929605 100.644321 \nL 61.952435 100.359395 \nL 61.998094 100.975184 \nL 62.043753 100.410694 \nL 62.22639 102.221944 \nL 62.249219 101.943873 \nL 62.294878 101.393073 \nL 62.340537 101.972871 \nL 62.386196 102.54532 \nL 62.431856 102.001134 \nL 62.591662 101.23477 \nL 62.660151 100.993174 \nL 62.70581 101.547275 \nL 62.751469 101.032045 \nL 62.797128 101.579281 \nL 62.819958 101.323879 \nL 62.842788 101.594999 \nL 62.888447 101.088643 \nL 62.911276 100.837699 \nL 62.956935 101.374841 \nL 63.002594 100.877138 \nL 63.071083 100.651219 \nL 63.185231 101.958456 \nL 63.299379 100.751462 \nL 63.390697 100.789996 \nL 63.413526 101.043821 \nL 63.459186 100.575369 \nL 63.504845 100.595346 \nL 63.641822 99.703022 \nL 63.710311 99.503419 \nL 63.75597 99.997663 \nL 63.801629 99.55333 \nL 63.847288 100.042106 \nL 63.870118 99.82157 \nL 64.007095 100.34558 \nL 64.029924 100.12825 \nL 64.075584 100.601539 \nL 64.144072 101.30244 \nL 64.212561 101.101818 \nL 64.303879 101.133003 \nL 64.349538 100.709552 \nL 64.555004 102.288615 \nL 64.577834 102.079223 \nL 64.851788 100.059623 \nL 64.897448 100.079159 \nL 64.965936 100.313711 \nL 64.988766 100.117672 \nL 65.080084 99.749032 \nL 65.034425 100.136672 \nL 65.102914 99.962072 \nL 65.331209 101.246967 \nL 65.468186 100.504261 \nL 65.513846 100.520663 \nL 65.650823 101.337642 \nL 65.673652 101.15217 \nL 65.719312 100.783635 \nL 65.7878 100.995487 \nL 65.856289 101.204616 \nL 65.879118 101.022982 \nL 65.970437 101.050024 \nL 66.038925 100.514113 \nL 66.175903 100.926219 \nL 66.267221 100.590373 \nL 66.221562 100.939835 \nL 66.31288 100.60525 \nL 66.33571 100.793003 \nL 66.381369 100.447694 \nL 66.404198 100.634638 \nL 66.449857 100.292062 \nL 66.518346 100.493242 \nL 66.564005 100.861682 \nL 66.609664 100.522997 \nL 66.632494 100.354664 \nL 66.700982 100.552279 \nL 66.769471 101.094805 \nL 66.81513 100.761177 \nL 66.974937 99.613808 \nL 67.043426 99.810004 \nL 67.226062 100.545004 \nL 67.248892 100.385218 \nL 67.294551 100.731863 \nL 67.500017 101.60667 \nL 67.705483 100.846227 \nL 67.910949 101.690963 \nL 67.933778 101.537707 \nL 67.979438 101.861715 \nL 68.002267 101.708964 \nL 68.047926 102.030637 \nL 68.116415 101.886665 \nL 68.321881 101.157501 \nL 68.458858 101.49217 \nL 68.504517 101.199453 \nL 68.550176 101.51078 \nL 68.595836 101.820005 \nL 68.664324 101.682941 \nL 68.755642 101.403524 \nL 68.709983 101.691499 \nL 68.801302 101.412966 \nL 69.006768 102.182379 \nL 69.098086 101.906558 \nL 69.143745 101.914118 \nL 69.303552 102.652629 \nL 69.326381 102.512905 \nL 69.440529 102.38544 \nL 69.463359 102.529265 \nL 69.509018 102.25376 \nL 69.531847 102.397111 \nL 69.691654 101.723778 \nL 69.737313 101.731601 \nL 69.942779 102.720467 \nL 69.965609 102.586662 \nL 70.034098 102.729677 \nL 70.079757 102.464108 \nL 70.148245 102.875489 \nL 70.193904 102.611487 \nL 70.330882 102.0947 \nL 70.353711 102.230523 \nL 70.467859 102.903583 \nL 70.536348 102.7784 \nL 70.696155 102.404114 \nL 70.718984 102.536299 \nL 70.764643 102.282958 \nL 70.833132 101.905717 \nL 70.878791 102.168836 \nL 70.901621 102.299823 \nL 70.94728 102.050099 \nL 70.970109 102.180696 \nL 70.992939 102.056365 \nL 71.038598 102.316404 \nL 71.107087 102.450944 \nL 71.129916 102.327297 \nL 71.47236 101.00823 \nL 71.518019 101.26358 \nL 71.563678 101.026125 \nL 71.700655 100.32166 \nL 71.769144 100.45906 \nL 71.95178 100.979999 \nL 71.997439 100.749443 \nL 72.043098 100.997537 \nL 72.202905 101.382464 \nL 72.317053 101.049026 \nL 72.339883 101.170528 \nL 72.522519 101.666843 \nL 72.636667 101.337642 \nL 72.659496 101.456558 \nL 72.956281 102.521674 \nL 72.97911 102.410769 \nL 73.024769 102.640969 \nL 73.047599 102.755637 \nL 73.093258 102.534648 \nL 73.161747 102.652997 \nL 73.207406 102.433669 \nL 73.321554 102.777738 \nL 73.344383 102.668747 \nL 73.48136 102.240449 \nL 73.50419 102.352752 \nL 73.595508 102.799187 \nL 73.641167 102.584644 \nL 73.755315 102.486335 \nL 73.869463 102.60461 \nL 73.892292 102.499026 \nL 73.937952 102.717807 \nL 73.960781 102.826808 \nL 74.00644 102.616365 \nL 74.02927 102.725083 \nL 74.257565 102.109956 \nL 74.50869 102.866279 \nL 74.668497 102.567537 \nL 74.736986 102.470406 \nL 74.805475 102.784183 \nL 74.828304 102.683415 \nL 74.873963 102.891376 \nL 75.03377 103.206205 \nL 75.0566 103.106109 \nL 75.102259 103.310727 \nL 75.125088 103.210852 \nL 75.216407 103.61727 \nL 75.262066 103.418183 \nL 75.444702 103.028104 \nL 75.53602 103.231208 \nL 75.55885 103.133551 \nL 75.672998 103.041383 \nL 75.718657 103.239997 \nL 75.764316 103.046609 \nL 75.787146 102.950235 \nL 75.832805 103.147956 \nL 75.855634 103.051792 \nL 75.901293 103.24863 \nL 75.946952 103.056923 \nL 76.106759 102.584885 \nL 76.129589 102.682742 \nL 76.198078 102.783521 \nL 76.220907 102.689418 \nL 76.289396 102.599027 \nL 76.312225 102.696021 \nL 76.472032 102.991062 \nL 76.540521 102.712308 \nL 76.58618 102.903583 \nL 76.677498 103.096436 \nL 76.700328 103.004089 \nL 76.791646 102.82296 \nL 76.814476 102.917473 \nL 76.951453 103.110567 \nL 77.225408 102.393915 \nL 77.362385 102.586662 \nL 77.522192 102.328075 \nL 77.750487 102.882281 \nL 77.978783 102.365947 \nL 78.047272 102.283473 \nL 78.184249 102.819995 \nL 78.412544 102.313912 \nL 78.526692 102.409445 \nL 78.709329 102.081295 \nL 78.891965 102.607102 \nL 78.914795 102.52385 \nL 78.983283 102.444163 \nL 79.006113 102.530348 \nL 79.074602 102.619425 \nL 79.097431 102.536793 \nL 79.120261 102.454319 \nL 79.16592 102.625523 \nL 79.188749 102.543196 \nL 79.348556 102.804139 \nL 79.554022 102.403147 \nL 79.827977 103.076669 \nL 79.896466 102.835514 \nL 79.964954 102.920553 \nL 80.033443 103.005119 \nL 80.056273 102.925316 \nL 80.216079 102.370773 \nL 80.284568 102.456002 \nL 80.444375 102.706178 \nL 80.581352 102.555845 \nL 80.672671 102.719731 \nL 80.6955 102.642178 \nL 80.741159 102.487502 \nL 80.786818 102.647803 \nL 80.855307 102.573604 \nL 80.923796 102.812551 \nL 80.969455 102.658937 \nL 81.015114 102.817524 \nL 81.174921 103.213323 \nL 81.19775 103.136842 \nL 81.22058 103.060487 \nL 81.266239 103.216856 \nL 81.380387 103.298047 \nL 81.448875 103.223826 \nL 81.471705 103.301254 \nL 81.540194 103.227275 \nL 81.608682 103.458347 \nL 81.677171 103.536279 \nL 81.791319 103.160993 \nL 81.905467 103.391476 \nL 81.928296 103.31693 \nL 82.042444 103.245833 \nL 82.133762 103.547855 \nL 82.179421 103.399877 \nL 82.24791 103.178857 \nL 82.316399 103.255664 \nL 82.453376 103.40812 \nL 82.658842 103.047902 \nL 82.795819 103.491078 \nL 82.841478 103.346728 \nL 83.024115 102.918692 \nL 83.046944 102.991987 \nL 83.206751 103.214458 \nL 83.298069 103.074545 \nL 83.320899 103.147009 \nL 83.389388 103.220967 \nL 83.412217 103.150479 \nL 83.435047 103.080097 \nL 83.480706 103.224194 \nL 83.663342 103.513274 \nL 83.686172 103.443217 \nL 83.731831 103.585464 \nL 83.754661 103.515524 \nL 83.77749 103.586484 \nL 83.823149 103.446929 \nL 83.891638 103.518888 \nL 83.937297 103.379995 \nL 84.142763 103.733474 \nL 84.256911 103.666151 \nL 84.27974 103.735766 \nL 84.325399 103.598386 \nL 84.348229 103.529855 \nL 84.393888 103.668748 \nL 84.416718 103.600332 \nL 84.508036 103.73953 \nL 84.530865 103.671324 \nL 84.576525 103.535217 \nL 84.622184 103.673027 \nL 84.850479 104.084303 \nL 84.873309 104.016623 \nL 84.918968 104.152309 \nL 85.055945 104.422137 \nL 85.078775 104.354656 \nL 85.3299 103.886162 \nL 85.489707 104.087173 \nL 85.581025 103.955135 \nL 85.603855 104.021501 \nL 85.626684 104.087762 \nL 85.672343 103.955924 \nL 85.695173 104.02209 \nL 85.763661 103.956712 \nL 85.786491 104.022689 \nL 85.85498 104.22 \nL 85.923468 104.154517 \nL 85.969127 104.023856 \nL 86.014787 104.154717 \nL 86.083275 104.089718 \nL 86.128934 104.22 \nL 86.197423 104.025297 \nL 86.243082 104.15519 \nL 86.288741 104.28471 \nL 86.3344 104.155379 \nL 86.448548 104.091242 \nL 86.562696 104.155853 \nL 86.676844 103.964346 \nL 86.699673 104.028399 \nL 86.745332 104.156221 \nL 86.790991 104.028956 \nL 86.973628 103.776782 \nL 86.996457 103.840372 \nL 87.042117 103.714559 \nL 87.064946 103.778054 \nL 87.316071 103.343016 \nL 87.338901 103.406228 \nL 87.38456 103.28237 \nL 87.407389 103.345498 \nL 87.430219 103.283695 \nL 87.475878 103.409687 \nL 87.612855 103.537246 \nL 87.635685 103.475696 \nL 87.681344 103.600615 \nL 87.704174 103.53916 \nL 87.772662 103.725882 \nL 87.818321 103.603213 \nL 88.000958 103.238641 \nL 88.023787 103.300612 \nL 88.183594 103.48805 \nL 88.343401 103.309465 \nL 88.434719 103.433039 \nL 88.457549 103.373087 \nL 88.480379 103.313219 \nL 88.526038 103.435195 \nL 88.548867 103.3754 \nL 88.571697 103.436267 \nL 88.617356 103.31693 \nL 88.640185 103.377713 \nL 88.685845 103.258692 \nL 88.731504 103.379995 \nL 88.777163 103.500982 \nL 88.822822 103.382276 \nL 88.891311 103.324269 \nL 88.91414 103.384547 \nL 88.982629 103.326687 \nL 89.028288 103.446834 \nL 89.165265 103.213018 \nL 89.188095 103.272886 \nL 89.370731 103.513463 \nL 89.393561 103.455088 \nL 89.43922 103.573636 \nL 89.462049 103.515334 \nL 89.621856 103.810859 \nL 89.644686 103.752715 \nL 89.758834 103.579608 \nL 89.781663 103.638204 \nL 89.804493 103.696726 \nL 89.850152 103.58129 \nL 89.872981 103.523683 \nL 89.918641 103.640496 \nL 90.055618 103.989107 \nL 90.101277 103.874112 \nL 90.124107 103.816736 \nL 90.169766 103.93233 \nL 90.420891 104.334248 \nL 90.46655 104.22 \nL 90.512209 104.333954 \nL 90.580698 104.390599 \nL 90.603527 104.333659 \nL 90.626357 104.276793 \nL 90.672016 104.390163 \nL 90.717675 104.503238 \nL 90.763334 104.389726 \nL 90.900311 104.163644 \nL 90.923141 104.22 \nL 91.105777 104.444143 \nL 91.219925 104.275857 \nL 91.242755 104.331646 \nL 91.379732 104.664895 \nL 91.425391 104.553249 \nL 91.562369 104.44133 \nL 91.608028 104.551578 \nL 91.653687 104.440778 \nL 91.881982 104.110294 \nL 92.064619 104.329159 \nL 92.315744 103.948953 \nL 92.384233 104.111777 \nL 92.429892 104.003827 \nL 92.52121 103.788705 \nL 92.589699 103.843306 \nL 92.795165 104.112965 \nL 92.840824 104.006182 \nL 92.886483 104.113217 \nL 92.932142 104.22 \nL 93.000631 104.166766 \nL 93.206097 103.796475 \nL 93.228926 103.849635 \nL 93.297415 103.797484 \nL 93.343074 103.903489 \nL 93.480051 103.799503 \nL 93.54854 103.957659 \nL 93.617029 103.90575 \nL 93.639858 103.853589 \nL 93.685517 103.958584 \nL 93.776835 104.063527 \nL 93.799665 104.011492 \nL 93.845324 103.9076 \nL 93.890983 104.011986 \nL 94.119279 104.323397 \nL 94.393233 103.911964 \nL 94.416063 103.963452 \nL 94.461722 103.861253 \nL 94.484552 103.810249 \nL 94.530211 103.913036 \nL 94.735677 104.1691 \nL 94.895484 103.814486 \nL 94.941143 103.916212 \nL 94.986802 104.017706 \nL 95.055291 103.967563 \nL 95.123779 103.917599 \nL 95.146609 103.968141 \nL 95.169438 104.018631 \nL 95.215097 103.918293 \nL 95.237927 103.96872 \nL 95.511882 103.571102 \nL 95.6032 103.672176 \nL 95.626029 103.622706 \nL 95.648859 103.573299 \nL 95.694518 103.673406 \nL 95.717348 103.72338 \nL 95.763007 103.624725 \nL 95.831495 103.576201 \nL 95.854325 103.62606 \nL 96.014132 103.776288 \nL 96.288087 103.28952 \nL 96.310916 103.338979 \nL 96.425064 103.48785 \nL 96.447893 103.439474 \nL 96.584871 103.247568 \nL 96.6077 103.29669 \nL 96.63053 103.345771 \nL 96.676189 103.249702 \nL 96.904485 102.869012 \nL 96.927314 102.917977 \nL 97.064291 103.018367 \nL 97.087121 102.97098 \nL 97.13278 103.06831 \nL 97.201269 103.022279 \nL 97.246928 103.119294 \nL 97.315417 103.073304 \nL 97.338246 103.12168 \nL 97.361076 103.170004 \nL 97.406735 103.075786 \nL 97.498053 102.887959 \nL 97.543712 102.984438 \nL 97.63503 103.081937 \nL 97.65786 103.035148 \nL 97.863326 102.805023 \nL 97.886155 102.852925 \nL 97.931815 102.7602 \nL 97.954644 102.808051 \nL 98.068792 102.670987 \nL 98.091621 102.718721 \nL 98.137281 102.814044 \nL 98.18294 102.721907 \nL 98.297087 102.5858 \nL 98.319917 102.633335 \nL 98.456894 102.917473 \nL 98.525383 102.873081 \nL 98.593872 102.921573 \nL 98.639531 102.830299 \nL 98.66236 102.877319 \nL 98.708019 102.786234 \nL 98.730849 102.833211 \nL 98.867826 102.745396 \nL 98.936315 102.793709 \nL 98.959145 102.748466 \nL 98.981974 102.703276 \nL 99.027633 102.796674 \nL 99.118951 102.982913 \nL 99.164611 102.892648 \nL 99.18744 102.847595 \nL 99.233099 102.940415 \nL 99.255929 102.895403 \nL 99.461395 103.128862 \nL 99.575543 102.995625 \nL 99.598372 103.041583 \nL 99.621202 103.087488 \nL 99.666861 102.998138 \nL 99.781009 102.956133 \nL 99.917986 103.050005 \nL 100.009304 102.962568 \nL 100.032134 103.008095 \nL 100.100622 103.054757 \nL 100.123452 103.010555 \nL 100.146282 102.966395 \nL 100.191941 103.057123 \nL 100.260429 103.014225 \nL 100.306088 103.104679 \nL 100.511554 102.887675 \nL 100.602873 102.978991 \nL 100.625702 102.935315 \nL 100.76268 102.850844 \nL 101.013805 103.165819 \nL 101.082293 103.211251 \nL 101.127952 103.124624 \nL 101.424737 103.523451 \nL 101.607373 103.352742 \nL 101.675862 103.310727 \nL 101.721521 103.398121 \nL 101.926987 103.186406 \nL 102.063964 103.275304 \nL 102.246601 103.107875 \nL 102.360748 103.238578 \nL 102.383578 103.196405 \nL 102.406408 103.154264 \nL 102.452067 103.240471 \nL 102.543385 103.327371 \nL 102.566214 103.285314 \nL 102.703192 103.203282 \nL 102.840169 103.290687 \nL 102.977146 103.209107 \nL 103.045635 103.252615 \nL 103.068465 103.211041 \nL 103.205442 103.130071 \nL 103.29676 103.215825 \nL 103.31959 103.174483 \nL 103.456567 103.094038 \nL 103.593544 103.180392 \nL 103.639204 103.098286 \nL 103.707692 103.141353 \nL 103.82184 103.268049 \nL 103.84467 103.227128 \nL 103.935988 103.063821 \nL 104.004476 103.106677 \nL 104.027306 103.148408 \nL 104.072965 103.067059 \nL 104.095795 103.108758 \nL 104.164283 103.069204 \nL 104.187113 103.110819 \nL 104.34692 103.319159 \nL 104.369749 103.278658 \nL 104.415408 103.197751 \nL 104.483897 103.239997 \nL 104.598045 103.445961 \nL 104.666534 103.406344 \nL 104.780681 103.36763 \nL 104.940488 103.49174 \nL 105.054636 103.372309 \nL 105.077466 103.413052 \nL 105.100295 103.453742 \nL 105.145954 103.373865 \nL 105.37425 103.137052 \nL 105.511227 103.219999 \nL 105.648204 103.063148 \nL 105.671034 103.103543 \nL 105.762352 103.185166 \nL 105.785182 103.145842 \nL 105.89933 103.029176 \nL 105.922159 103.069393 \nL 106.036307 103.111566 \nL 106.104796 102.994447 \nL 106.150455 103.074545 \nL 106.173284 103.114541 \nL 106.218943 103.036641 \nL 106.40158 102.883638 \nL 106.515728 102.925821 \nL 106.675534 102.656172 \nL 106.721194 102.735681 \nL 106.881 102.857089 \nL 106.995148 102.821236 \nL 107.086466 102.90127 \nL 107.109296 102.863072 \nL 107.200614 102.865458 \nL 107.246273 102.943979 \nL 107.291932 102.867835 \nL 107.337592 102.791817 \nL 107.383251 102.8702 \nL 107.520228 103.027588 \nL 107.543058 102.989663 \nL 107.680035 102.916169 \nL 107.794183 102.957269 \nL 108.045308 102.696684 \nL 108.068137 102.735408 \nL 108.113796 102.66062 \nL 108.296433 102.514366 \nL 108.479069 102.671302 \nL 108.616047 102.599921 \nL 108.798683 102.755637 \nL 108.98132 102.610919 \nL 109.095467 102.651672 \nL 109.278104 102.5081 \nL 109.574888 102.850549 \nL 109.666206 102.778947 \nL 109.689036 102.816483 \nL 110.031479 103.228989 \nL 110.122797 103.08406 \nL 110.168456 103.158228 \nL 110.373922 103.41752 \nL 110.396752 103.381393 \nL 110.419582 103.345287 \nL 110.465241 103.418845 \nL 110.556559 103.42017 \nL 110.625048 103.384842 \nL 110.647877 103.421484 \nL 110.762025 103.459346 \nL 110.967491 103.281697 \nL 111.081639 103.319632 \nL 111.218616 103.249975 \nL 111.378423 103.360207 \nL 111.5154 103.290823 \nL 111.675207 103.400361 \nL 111.720866 103.32981 \nL 111.766525 103.401686 \nL 111.789355 103.437581 \nL 111.835014 103.367136 \nL 111.857844 103.331966 \nL 111.903503 103.403662 \nL 111.971991 103.440094 \nL 111.994821 103.404977 \nL 112.154628 103.301254 \nL 112.291605 103.37396 \nL 112.314435 103.339052 \nL 112.360094 103.410181 \nL 112.54273 103.553144 \nL 112.588389 103.483539 \nL 112.634048 103.554206 \nL 112.656878 103.589502 \nL 112.702537 103.520003 \nL 112.793855 103.521107 \nL 112.930833 103.662219 \nL 112.953662 103.627585 \nL 113.06781 103.59397 \nL 113.227617 103.699744 \nL 113.341765 103.596925 \nL 113.364594 103.631769 \nL 113.455912 103.701784 \nL 113.478742 103.667455 \nL 113.684208 103.497334 \nL 113.798356 103.533082 \nL 113.958163 103.432198 \nL 114.049481 103.501813 \nL 114.07231 103.467905 \nL 114.232117 103.367662 \nL 114.483242 103.608911 \nL 114.665879 103.475412 \nL 114.780027 103.510613 \nL 114.802856 103.477126 \nL 114.848515 103.545174 \nL 115.031152 103.681786 \nL 115.09964 103.581595 \nL 115.1453 103.649233 \nL 115.168129 103.683016 \nL 115.213788 103.616345 \nL 115.305106 103.61727 \nL 115.419254 103.65183 \nL 115.510572 103.585948 \nL 115.533402 103.619541 \nL 115.670379 103.687474 \nL 115.693209 103.654406 \nL 115.738868 103.721319 \nL 115.853016 103.755438 \nL 116.012823 103.657371 \nL 116.286777 103.923477 \nL 116.423755 103.858394 \nL 116.446584 103.891387 \nL 116.492243 103.825957 \nL 116.65205 103.728721 \nL 116.789028 103.860539 \nL 116.811857 103.827997 \nL 116.834687 103.795487 \nL 116.880346 103.861064 \nL 116.994494 103.8943 \nL 117.222789 103.700795 \nL 117.245619 103.733421 \nL 117.291278 103.668948 \nL 117.314107 103.636753 \nL 117.359766 103.701941 \nL 117.451085 103.702698 \nL 117.725039 103.447444 \nL 118.067483 103.931867 \nL 118.113142 103.868098 \nL 118.318608 103.709806 \nL 118.524074 103.806811 \nL 118.683881 103.71274 \nL 118.912176 103.840919 \nL 119.026324 103.746995 \nL 119.049154 103.778685 \nL 119.391597 104.125939 \nL 119.574233 104.063674 \nL 119.711211 104.064 \nL 119.848188 104.002071 \nL 119.871018 104.033267 \nL 120.213461 104.312872 \nL 120.350438 104.312678 \nL 120.441757 104.250849 \nL 120.487416 104.312483 \nL 120.647223 104.343012 \nL 120.7842 104.22 \nL 120.829859 104.281335 \nL 121.149473 104.525192 \nL 121.332109 104.402606 \nL 121.354939 104.432972 \nL 121.491916 104.43253 \nL 121.720212 104.31077 \nL 121.994166 104.4912 \nL 122.222462 104.370154 \nL 122.382269 104.519593 \nL 122.427928 104.45951 \nL 122.564905 104.459026 \nL 122.793201 104.577327 \nL 122.884519 104.576843 \nL 122.907349 104.606452 \nL 123.067155 104.635198 \nL 123.226962 104.604638 \nL 123.36394 104.603865 \nL 123.592235 104.484865 \nL 123.752042 104.572333 \nL 123.774872 104.542861 \nL 123.934679 104.454263 \nL 123.957508 104.483456 \nL 124.140145 104.541153 \nL 124.231463 104.482415 \nL 124.277122 104.540517 \nL 124.39127 104.569079 \nL 124.414099 104.539881 \nL 124.505417 104.481374 \nL 124.551077 104.53925 \nL 124.688054 104.538619 \nL 124.916349 104.422095 \nL 125.076156 104.508049 \nL 125.098986 104.479155 \nL 125.372941 104.306049 \nL 125.578407 104.391593 \nL 125.875191 104.191517 \nL 126.057827 104.248404 \nL 126.103486 104.191611 \nL 126.171975 104.276719 \nL 126.44593 104.446009 \nL 126.765543 104.22 \nL 126.92535 104.248063 \nL 127.062328 104.13597 \nL 127.107987 104.192011 \nL 127.199305 104.192043 \nL 127.222135 104.164106 \nL 127.496089 103.997276 \nL 127.541748 104.053065 \nL 127.610237 103.969824 \nL 127.815703 103.887381 \nL 128.043999 103.998948 \nL 128.295124 103.806947 \nL 128.317953 103.83461 \nL 128.340783 103.862242 \nL 128.409271 103.780104 \nL 128.569078 103.753619 \nL 128.637567 103.781471 \nL 128.683226 103.726955 \nL 128.820203 103.673195 \nL 128.843033 103.70069 \nL 128.957181 103.728784 \nL 128.98001 103.701658 \nL 129.094158 103.62074 \nL 129.139817 103.675551 \nL 129.322454 103.731203 \nL 129.390942 103.704528 \nL 129.436601 103.759076 \nL 129.52792 103.867962 \nL 129.596408 103.787117 \nL 129.756215 103.761042 \nL 129.938852 103.816032 \nL 130.121488 103.763282 \nL 130.349784 103.87181 \nL 130.53242 103.819217 \nL 130.715057 103.873492 \nL 130.852034 103.8209 \nL 130.874863 103.847627 \nL 131.0575 103.901586 \nL 131.354284 103.717807 \nL 131.422773 103.744671 \nL 131.468432 103.692174 \nL 131.536921 103.666277 \nL 131.58258 103.719311 \nL 131.765216 103.773081 \nL 131.947853 103.721698 \nL 132.130489 103.775205 \nL 132.267466 103.775993 \nL 132.518591 103.9076 \nL 132.792546 103.753062 \nL 133.043671 103.883849 \nL 133.249137 103.704212 \nL 133.294796 103.756058 \nL 133.591581 103.937555 \nL 133.751387 103.9125 \nL 133.956853 103.98998 \nL 134.162319 103.914109 \nL 134.207979 103.965229 \nL 134.276467 103.889095 \nL 134.344956 103.863945 \nL 134.390615 103.914981 \nL 134.459104 103.991441 \nL 134.527592 103.915507 \nL 134.66457 103.916033 \nL 134.710229 103.966838 \nL 134.778717 103.891177 \nL 134.961354 103.841455 \nL 135.235309 103.993649 \nL 135.372286 103.994038 \nL 135.463604 104.044454 \nL 135.509263 103.994427 \nL 135.897366 103.67124 \nL 135.920195 103.696337 \nL 136.102832 103.747279 \nL 136.216979 103.673406 \nL 136.262639 103.72338 \nL 136.468105 103.798935 \nL 136.71923 103.627395 \nL 136.742059 103.652241 \nL 137.016014 103.801753 \nL 137.175821 103.72891 \nL 137.19865 103.753598 \nL 137.426946 103.852811 \nL 137.632412 103.780462 \nL 137.74656 103.756689 \nL 137.837878 103.659769 \nL 137.906367 103.733242 \nL 138.089003 103.831456 \nL 138.111833 103.807284 \nL 138.340128 103.711572 \nL 138.499935 103.785046 \nL 138.522765 103.761 \nL 138.75106 103.665888 \nL 138.888037 103.666792 \nL 139.093503 103.596168 \nL 139.27614 103.693288 \nL 139.298969 103.669494 \nL 139.458776 103.646657 \nL 139.550095 103.695002 \nL 139.595754 103.647583 \nL 139.755561 103.624861 \nL 139.915368 103.649738 \nL 140.006686 103.650358 \nL 140.029515 103.674236 \nL 140.143663 103.793458 \nL 140.212152 103.72277 \nL 140.3263 103.747079 \nL 140.577425 103.913509 \nL 140.600254 103.89002 \nL 140.691572 103.843274 \nL 140.737232 103.890546 \nL 140.988357 104.055757 \nL 141.011186 104.032341 \nL 141.125334 104.009168 \nL 141.148164 104.032636 \nL 141.262311 104.149828 \nL 141.3308 104.079782 \nL 141.513436 104.033435 \nL 141.696073 104.080371 \nL 141.83305 103.987645 \nL 141.878709 104.034213 \nL 142.129834 104.196848 \nL 142.152664 104.173706 \nL 142.243982 104.173748 \nL 142.266812 104.196879 \nL 142.426619 104.22 \nL 142.540766 104.150858 \nL 142.586426 104.196963 \nL 142.723403 104.197005 \nL 142.837551 104.22 \nL 142.974528 104.265868 \nL 142.997358 104.242926 \nL 143.157164 104.22 \nL 143.225653 104.242869 \nL 143.271312 104.197142 \nL 143.431119 104.128747 \nL 143.453949 104.151573 \nL 143.636585 104.197237 \nL 143.727903 104.242737 \nL 143.91054 104.288075 \nL 144.138835 104.197363 \nL 144.252983 104.174789 \nL 144.43562 104.129767 \nL 144.663915 104.22 \nL 144.778063 104.242469 \nL 144.91504 104.242437 \nL 145.097677 104.197605 \nL 145.234654 104.197647 \nL 145.41729 104.153066 \nL 145.668416 104.264502 \nL 145.9652 104.109117 \nL 146.125007 104.131449 \nL 146.284814 104.109506 \nL 146.376132 104.065461 \nL 146.49028 104.087699 \nL 146.581598 104.043781 \nL 146.695746 104.065998 \nL 146.809893 104.044212 \nL 146.901212 104.088288 \nL 147.083848 104.132374 \nL 147.243655 104.110652 \nL 147.403462 104.132669 \nL 147.631757 104.045779 \nL 147.768735 104.046031 \nL 147.882882 104.067964 \nL 148.134008 104.176681 \nL 148.339474 104.111934 \nL 148.476451 104.112092 \nL 148.613428 104.11225 \nL 148.750406 104.112408 \nL 148.887383 104.112565 \nL 149.04719 104.134204 \nL 149.275485 104.048817 \nL 149.503781 104.134614 \nL 149.709247 104.070908 \nL 149.869054 104.09242 \nL 150.028861 104.071412 \nL 150.257156 104.156473 \nL 150.462622 104.093219 \nL 150.645259 104.135634 \nL 150.919213 104.009704 \nL 151.147509 104.094123 \nL 151.307316 104.073389 \nL 151.398634 104.031669 \nL 151.512782 104.052792 \nL 151.786736 104.178321 \nL 152.037862 104.074493 \nL 152.152009 104.053896 \nL 152.266157 104.07483 \nL 152.448794 104.116508 \nL 152.6086 104.096005 \nL 152.699919 104.054832 \nL 152.973873 103.931762 \nL 153.065192 103.890893 \nL 153.293487 103.809576 \nL 153.453294 103.830731 \nL 153.63593 103.790556 \nL 153.772908 103.791155 \nL 153.909885 103.791744 \nL 154.024033 103.771872 \nL 154.275158 103.671419 \nL 154.526283 103.774132 \nL 154.800238 103.654102 \nL 154.914386 103.634556 \nL 155.051363 103.635365 \nL 155.18834 103.636164 \nL 155.439465 103.537215 \nL 155.69059 103.639077 \nL 155.850397 103.620004 \nL 156.101522 103.721246 \nL 156.306988 103.662523 \nL 156.489625 103.703277 \nL 156.626602 103.703981 \nL 156.71792 103.664784 \nL 156.877727 103.645858 \nL 157.106023 103.726156 \nL 157.243 103.726818 \nL 157.471296 103.806653 \nL 157.631103 103.787643 \nL 157.74525 103.768497 \nL 158.042035 103.632779 \nL 158.247501 103.692563 \nL 158.407308 103.673868 \nL 158.589944 103.71377 \nL 158.749751 103.695118 \nL 158.863899 103.676276 \nL 159.046535 103.638456 \nL 159.160683 103.619741 \nL 159.366149 103.562943 \nL 159.548785 103.602676 \nL 159.662933 103.622622 \nL 159.777081 103.604022 \nL 159.936888 103.585748 \nL 160.188013 103.683131 \nL 160.279331 103.721908 \nL 160.393479 103.703319 \nL 160.644604 103.60909 \nL 160.827241 103.648266 \nL 161.055536 103.573426 \nL 161.283832 103.650726 \nL 161.466468 103.613811 \nL 161.649105 103.652672 \nL 161.740423 103.690954 \nL 161.8774 103.691627 \nL 162.037207 103.673574 \nL 162.242673 103.731045 \nL 162.425309 103.694329 \nL 162.722094 103.82684 \nL 162.973219 103.734357 \nL 163.155855 103.772471 \nL 163.247173 103.810112 \nL 163.384151 103.810638 \nL 163.658105 103.700301 \nL 163.977719 103.849877 \nL 164.160356 103.81355 \nL 164.251674 103.776971 \nL 164.388651 103.777528 \nL 164.616947 103.852043 \nL 164.708265 103.889116 \nL 164.868072 103.907947 \nL 165.073538 103.853568 \nL 165.164856 103.817262 \nL 165.256174 103.854177 \nL 165.438811 103.891303 \nL 165.644277 103.837239 \nL 165.826913 103.87426 \nL 166.00955 103.838501 \nL 166.306334 103.966343 \nL 166.443311 103.966659 \nL 166.625948 104.003206 \nL 166.762925 104.003469 \nL 166.968391 104.057902 \nL 167.173857 104.004268 \nL 167.265175 103.968509 \nL 167.447812 103.933055 \nL 167.630448 103.96933 \nL 167.790255 103.951802 \nL 167.881573 103.916296 \nL 168.018551 103.916664 \nL 168.178357 103.934906 \nL 168.360994 103.899788 \nL 168.475142 103.882345 \nL 168.56646 103.918125 \nL 168.749096 103.954073 \nL 168.977392 103.883828 \nL 169.114369 103.884238 \nL 169.297006 103.849488 \nL 169.433983 103.84993 \nL 169.548131 103.867909 \nL 169.753597 103.921258 \nL 169.913404 103.90412 \nL 170.027551 103.886908 \nL 170.164529 103.887297 \nL 170.301506 103.852716 \nL 170.484143 103.818376 \nL 170.826586 103.941435 \nL 170.963563 103.976542 \nL 171.1462 103.976931 \nL 171.351666 103.960024 \nL 171.64845 104.047125 \nL 171.785427 104.081864 \nL 171.899575 104.030249 \nL 172.059382 104.047734 \nL 172.333337 104.116887 \nL 172.515973 104.117044 \nL 172.65295 104.082884 \nL 172.972564 103.980695 \nL 173.132371 103.963957 \nL 173.315007 103.964346 \nL 173.520473 103.98181 \nL 173.931405 103.813077 \nL 174.114042 103.813708 \nL 174.273849 103.831151 \nL 174.410826 103.797831 \nL 174.547803 103.832045 \nL 174.70761 103.815727 \nL 174.913076 103.799598 \nL 175.141372 103.833969 \nL 175.25552 103.884637 \nL 175.529474 103.952317 \nL 175.689281 103.969382 \nL 175.917577 104.003206 \nL 176.214361 103.920564 \nL 176.465486 103.970991 \nL 176.693782 103.938312 \nL 177.036225 104.054768 \nL 177.218861 104.055021 \nL 177.355839 104.022237 \nL 177.515646 104.038955 \nL 177.766771 104.088603 \nL 178.017896 104.039701 \nL 178.33751 104.138262 \nL 178.520146 104.138378 \nL 178.657123 104.105857 \nL 178.81693 104.122291 \nL 178.931078 104.073568 \nL 179.090885 104.090012 \nL 179.433328 104.203798 \nL 179.821431 104.058459 \nL 180.118215 104.139419 \nL 180.460658 104.027147 \nL 180.734613 104.091705 \nL 180.87159 104.123889 \nL 181.099886 104.156042 \nL 181.351011 104.108297 \nL 181.602136 104.156294 \nL 181.853261 104.108738 \nL 182.150046 104.188289 \nL 182.332682 104.188331 \nL 182.583807 104.235803 \nL 182.743614 104.251569 \nL 182.94908 104.267277 \nL 183.177376 104.235729 \nL 183.519819 104.345509 \nL 183.702455 104.34533 \nL 183.885092 104.345151 \nL 184.022069 104.376273 \nL 184.318853 104.453869 \nL 184.455831 104.48477 \nL 184.615638 104.468888 \nL 184.958081 104.359629 \nL 185.186376 104.390363 \nL 185.369013 104.390121 \nL 185.642968 104.451498 \nL 185.802774 104.466628 \nL 186.0539 104.512307 \nL 186.305025 104.465681 \nL 186.601809 104.541731 \nL 187.126889 104.311558 \nL 187.355184 104.341866 \nL 187.58348 104.311243 \nL 187.697628 104.265579 \nL 187.925923 104.235167 \nL 188.10856 104.235146 \nL 188.359685 104.189761 \nL 188.542321 104.189803 \nL 188.702128 104.204923 \nL 189.181549 104.400309 \nL 189.341356 104.415097 \nL 189.523992 104.414834 \nL 189.683799 104.42957 \nL 189.912094 104.459105 \nL 190.071901 104.473751 \nL 190.277367 104.488266 \nL 190.596981 104.398422 \nL 190.893765 104.472211 \nL 191.099231 104.457018 \nL 191.373186 104.515677 \nL 191.487334 104.559742 \nL 191.852607 104.676692 \nL 192.080902 104.646511 \nL 192.354857 104.704371 \nL 192.72013 104.585975 \nL 192.902766 104.585491 \nL 193.039744 104.614337 \nL 193.268039 104.642847 \nL 193.450676 104.642289 \nL 193.587653 104.612776 \nL 193.770289 104.612261 \nL 194.044244 104.669485 \nL 194.24971 104.654339 \nL 194.455176 104.668155 \nL 194.706301 104.624058 \nL 194.866108 104.60918 \nL 195.29987 104.44991 \nL 195.505336 104.463926 \nL 195.665142 104.477978 \nL 195.893438 104.506177 \nL 196.190222 104.434181 \nL 196.3272 104.405445 \nL 196.532666 104.39093 \nL 196.669643 104.362305 \nL 196.943598 104.305218 \nL 197.080575 104.276756 \nL 197.286041 104.262504 \nL 197.468677 104.262451 \nL 197.674143 104.248262 \nL 197.902439 104.27643 \nL 198.130734 104.248168 \nL 198.3362 104.262194 \nL 198.518837 104.262141 \nL 198.929769 104.402086 \nL 199.135235 104.387839 \nL 199.363531 104.415502 \nL 199.568997 104.401282 \nL 199.842951 104.456613 \nL 200.094076 104.414519 \nL 200.390861 104.483451 \nL 200.596327 104.46923 \nL 201.098577 104.661552 \nL 201.281213 104.661 \nL 201.509509 104.687832 \nL 201.646486 104.714885 \nL 201.806293 104.700617 \nL 202.011759 104.686234 \nL 202.217225 104.699271 \nL 202.49118 104.643709 \nL 202.650987 104.629599 \nL 202.833623 104.629089 \nL 203.016259 104.628584 \nL 203.130407 104.669096 \nL 203.472851 104.763104 \nL 203.678317 104.748794 \nL 203.838123 104.734678 \nL 204.089249 104.693247 \nL 204.271885 104.692669 \nL 204.568669 104.624342 \nL 204.705647 104.597036 \nL 204.933942 104.569573 \nL 205.139408 104.582521 \nL 205.367704 104.555158 \nL 205.618829 104.594749 \nL 205.892783 104.540632 \nL 206.07542 104.540243 \nL 206.258056 104.539854 \nL 206.463522 104.552729 \nL 206.783136 104.472342 \nL 207.011432 104.498486 \nL 207.353875 104.40524 \nL 207.536511 104.405014 \nL 207.901784 104.299104 \nL 208.10725 104.312163 \nL 208.63233 104.115036 \nL 208.814967 104.115152 \nL 209.13458 104.036905 \nL 209.317217 104.037125 \nL 209.568342 103.998296 \nL 209.956444 104.11593 \nL 210.116251 104.129031 \nL 210.276058 104.11614 \nL 210.572842 104.051551 \nL 210.778308 104.064715 \nL 210.983774 104.052003 \nL 211.234899 104.09098 \nL 211.394706 104.103996 \nL 211.668661 104.155663 \nL 211.965445 104.091579 \nL 212.2394 104.143078 \nL 212.422036 104.143172 \nL 213.038434 104.385815 \nL 213.221071 104.385621 \nL 213.495025 104.43621 \nL 213.79181 104.397723 \nL 214.157083 104.321321 \nL 214.385378 104.321173 \nL 214.613674 104.321032 \nL 214.79631 104.295687 \nL 215.001776 104.308188 \nL 215.275731 104.333191 \nL 215.458367 104.358184 \nL 215.686663 104.357989 \nL 216.029106 104.295109 \nL 216.32589 104.33245 \nL 216.645504 104.28235 \nL 216.805311 104.244914 \nL 217.124925 104.195134 \nL 217.330391 104.182748 \nL 217.672834 104.120872 \nL 217.855471 104.096226 \nL 218.152255 104.059384 \nL 218.426209 104.084324 \nL 218.677335 104.072222 \nL 219.088267 104.170867 \nL 219.362221 104.146421 \nL 219.544858 104.121997 \nL 219.795983 104.109916 \nL 220.047108 104.122302 \nL 220.298233 104.110252 \nL 220.640676 104.171329 \nL 220.891802 104.159249 \nL 221.371222 104.29269 \nL 221.576688 104.304703 \nL 221.827813 104.316658 \nL 222.033279 104.328607 \nL 222.330064 104.36455 \nL 222.695336 104.292117 \nL 222.992121 104.327987 \nL 223.174757 104.351838 \nL 223.471541 104.387497 \nL 223.677007 104.399242 \nL 223.973792 104.434717 \nL 224.179258 104.446367 \nL 224.339064 104.410445 \nL 224.56736 104.410187 \nL 224.727167 104.374381 \nL 224.932633 104.386057 \nL 225.138099 104.374008 \nL 225.320735 104.397512 \nL 225.57186 104.409067 \nL 225.845815 104.385168 \nL 226.09694 104.396708 \nL 226.370895 104.372898 \nL 226.64485 104.39614 \nL 226.895975 104.384159 \nL 227.421054 104.535628 \nL 227.64935 104.535207 \nL 227.991793 104.592841 \nL 228.311407 104.545632 \nL 228.539703 104.545206 \nL 228.767998 104.544775 \nL 228.950635 104.52126 \nL 229.315908 104.451256 \nL 229.612692 104.48549 \nL 229.818158 104.496704 \nL 230.092112 104.519294 \nL 230.320408 104.518905 \nL 230.571533 104.529955 \nL 230.913976 104.472064 \nL 231.073783 104.437493 \nL 231.416227 104.379948 \nL 231.73584 104.425275 \nL 231.986966 104.413594 \nL 232.375068 104.492714 \nL 232.626193 104.48098 \nL 232.991466 104.548387 \nL 233.242591 104.536616 \nL 233.539375 104.569957 \nL 233.7905 104.558191 \nL 234.155773 104.624999 \nL 234.292751 104.669658 \nL 234.498217 104.657914 \nL 234.726512 104.657356 \nL 235.023296 104.690219 \nL 235.36574 104.633457 \nL 235.86799 104.766027 \nL 236.073456 104.776536 \nL 236.438729 104.842066 \nL 236.712684 104.818945 \nL 236.963809 104.829191 \nL 237.123616 104.861859 \nL 237.488888 104.926837 \nL 237.717184 104.925954 \nL 237.991139 104.946924 \nL 238.196605 104.957107 \nL 238.493389 104.988866 \nL 238.904321 104.899473 \nL 239.109787 104.887766 \nL 239.338083 104.88694 \nL 239.589208 104.89695 \nL 239.954481 104.830232 \nL 240.205606 104.840283 \nL 240.433901 104.839521 \nL 240.639367 104.827977 \nL 240.936151 104.794489 \nL 241.164447 104.793784 \nL 241.50689 104.738695 \nL 241.712356 104.727329 \nL 241.940652 104.726708 \nL 242.191777 104.736797 \nL 242.442902 104.725352 \nL 242.739686 104.756758 \nL 243.104959 104.691428 \nL 243.264766 104.658912 \nL 243.58438 104.61542 \nL 243.881164 104.646811 \nL 244.246437 104.582085 \nL 244.497562 104.592242 \nL 244.748687 104.581128 \nL 244.999812 104.591258 \nL 245.273767 104.569536 \nL 245.433574 104.537494 \nL 245.684699 104.526506 \nL 245.935824 104.536658 \nL 246.16412 104.536279 \nL 246.460904 104.56737 \nL 246.826177 104.503669 \nL 247.054472 104.503333 \nL 247.328427 104.481968 \nL 247.556723 104.481658 \nL 247.716529 104.512817 \nL 248.036143 104.554091 \nL 248.447075 104.470034 \nL 248.652541 104.459362 \nL 248.903666 104.448659 \nL 249.109132 104.438034 \nL 249.314598 104.448175 \nL 249.474405 104.416901 \nL 249.862508 104.34411 \nL 250.045144 104.323329 \nL 250.319099 104.302547 \nL 250.707201 104.374465 \nL 251.026815 104.333091 \nL 251.323599 104.363714 \nL 251.620383 104.33275 \nL 251.962827 104.383712 \nL 252.099804 104.424497 \nL 252.30527 104.414072 \nL 252.602054 104.383181 \nL 252.944498 104.433807 \nL 253.3326 104.362258 \nL 253.538066 104.351959 \nL 253.880509 104.301065 \nL 254.085975 104.290861 \nL 254.565396 104.179604 \nL 254.839351 104.179657 \nL 255.204624 104.139471 \nL 255.41009 104.10939 \nL 255.638385 104.129598 \nL 256.003658 104.169868 \nL 256.505908 104.069983 \nL 256.779863 104.070182 \nL 257.099477 104.050479 \nL 257.350602 104.040732 \nL 257.670216 104.021123 \nL 258.012659 104.051246 \nL 258.218125 104.08117 \nL 258.537739 104.101189 \nL 258.811693 104.101347 \nL 259.176966 104.141038 \nL 259.49658 104.12145 \nL 259.816194 104.14129 \nL 260.272785 104.062917 \nL 260.52391 104.053307 \nL 260.843524 104.033982 \nL 261.277286 104.102766 \nL 261.619729 104.073694 \nL 261.916513 104.083651 \nL 262.213297 104.074115 \nL 262.441593 104.054853 \nL 262.669888 104.074441 \nL 262.943843 104.07463 \nL 263.309116 104.03619 \nL 263.62873 104.055788 \nL 263.925514 104.046378 \nL 264.199469 104.046609 \nL 264.450594 104.05644 \nL 264.724548 104.05665 \nL 265.18114 103.980296 \nL 265.432265 103.971012 \nL 265.614901 104.009494 \nL 266.025833 104.067207 \nL 266.482424 103.991304 \nL 266.802038 104.010682 \nL 267.075993 104.010945 \nL 267.464095 104.058753 \nL 267.989175 103.955083 \nL 268.194641 103.926978 \nL 268.400107 103.955587 \nL 268.76538 103.993754 \nL 269.130653 103.956492 \nL 269.358948 103.937966 \nL 269.701392 103.91026 \nL 269.998176 103.92006 \nL 270.363449 103.883144 \nL 270.82004 103.958552 \nL 271.162483 103.931005 \nL 271.367949 103.903342 \nL 271.664733 103.894468 \nL 271.938688 103.894878 \nL 272.121324 103.932277 \nL 272.34962 103.914035 \nL 272.760552 103.859098 \nL 273.194314 103.924465 \nL 273.39978 103.952423 \nL 273.90203 104.045095 \nL 274.175984 104.045306 \nL 274.632576 104.119074 \nL 274.90653 104.1192 \nL 275.226144 104.137642 \nL 275.545758 104.119494 \nL 275.865372 104.137884 \nL 276.321963 104.06522 \nL 276.824213 104.15641 \nL 277.166656 104.129293 \nL 277.48627 104.147546 \nL 277.760225 104.14763 \nL 278.057009 104.156757 \nL 278.582089 104.057765 \nL 278.901702 104.075997 \nL 279.244146 104.049259 \nL 279.632248 104.094407 \nL 279.814885 104.130366 \nL 280.271476 104.202105 \nL 280.454112 104.237874 \nL 280.796556 104.264623 \nL 281.184658 104.22 \nL 281.390124 104.193294 \nL 281.823886 104.131165 \nL 282.09784 104.13127 \nL 282.348965 104.140228 \nL 282.691409 104.166903 \nL 283.056682 104.131638 \nL 283.307807 104.122911 \nL 283.467614 104.131796 \nL 283.467614 104.131796 \n\" clip-path=\"url(#p6315a5b485)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 43.78125 104.22 \nL 294.88125 104.22 \n\" clip-path=\"url(#p6315a5b485)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 201.24 \nL 43.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 294.88125 201.24 \nL 294.88125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 201.24 \nL 294.88125 201.24 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 294.88125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 182.759375 44.55625 \nL 287.88125 44.55625 \nQ 289.88125 44.55625 289.88125 42.55625 \nL 289.88125 14.2 \nQ 289.88125 12.2 287.88125 12.2 \nL 182.759375 12.2 \nQ 180.759375 12.2 180.759375 14.2 \nL 180.759375 42.55625 \nQ 180.759375 44.55625 182.759375 44.55625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 184.759375 20.298438 \nL 194.759375 20.298438 \nL 204.759375 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_15\">\n     <!-- P(coin=heads) -->\n     <g transform=\"translate(212.759375 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \nL 1259 2394 \nL 2053 2394 \nQ 2494 2394 2734 2622 \nQ 2975 2850 2975 3272 \nQ 2975 3691 2734 3919 \nQ 2494 4147 2053 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2053 4666 \nQ 2838 4666 3239 4311 \nQ 3641 3956 3641 3272 \nQ 3641 2581 3239 2228 \nQ 2838 1875 2053 1875 \nL 1259 1875 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \nL 4684 2906 \nL 4684 2381 \nL 678 2381 \nL 678 2906 \nz\nM 678 1631 \nL 4684 1631 \nL 4684 1100 \nL 678 1100 \nL 678 1631 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"390.429688\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"453.808594\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"515.332031\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"576.611328\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"640.087891\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"692.1875\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 184.759375 34.976562 \nL 194.759375 34.976562 \nL 204.759375 34.976562 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_16\">\n     <!-- P(coin=tails) -->\n     <g transform=\"translate(212.759375 38.476562) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"390.429688\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"429.638672\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"490.917969\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"518.701172\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"546.484375\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"598.583984\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p6315a5b485\">\n   <rect x=\"43.78125\" y=\"7.2\" width=\"251.1\" height=\"194.04\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "counts = Multinomial(1, fair_probs).sample((10000,))\n",
        "cum_counts = counts.cumsum(dim=0)\n",
        "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
        "estimates = estimates.numpy()\n",
        "\n",
        "d2l.set_figsize((4.5, 3.5))\n",
        "d2l.plt.plot(estimates[:, 0], label=(\"P(coin=heads)\"))\n",
        "d2l.plt.plot(estimates[:, 1], label=(\"P(coin=tails)\"))\n",
        "d2l.plt.axhline(y=0.5, color='black', linestyle='dashed')\n",
        "d2l.plt.gca().set_xlabel('Samples')\n",
        "d2l.plt.gca().set_ylabel('Estimated probability')\n",
        "d2l.plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec40585d",
      "metadata": {
        "origin_pos": 29,
        "id": "ec40585d"
      },
      "source": [
        "Each solid curve corresponds to one of the two values of the coin\n",
        "and gives our estimated probability that the coin turns up that value\n",
        "after each group of experiments.\n",
        "The dashed black line gives the true underlying probability.\n",
        "As we get more data by conducting more experiments,\n",
        "the curves converge towards the true probability.\n",
        "You might already begin to see the shape\n",
        "of some of the more advanced questions\n",
        "that preoccupy statisticians:\n",
        "How quickly does this convergence happen?\n",
        "If we had already tested many coins\n",
        "manufactured at the same plant,\n",
        "how might we incorporate this information?\n",
        "\n",
        "##  A More Formal Treatment\n",
        "\n",
        "We have already gotten pretty far: posing\n",
        "a probabilistic model,\n",
        "generating synthetic data,\n",
        "running a statistical estimator,\n",
        "empirically assessing convergence,\n",
        "and reporting error metrics (checking the deviation).\n",
        "However, to go much further,\n",
        "we will need to be more precise.\n",
        "\n",
        "\n",
        "When dealing with randomness,\n",
        "we denote the set of possible outcomes $\\mathcal{S}$\n",
        "and call it the *sample space* or *outcome space*.\n",
        "Here, each element is a distinct possible *outcome*.\n",
        "In the case of rolling a single coin,\n",
        "$\\mathcal{S} = \\{\\textrm{heads}, \\textrm{tails}\\}$.\n",
        "For a single die, $\\mathcal{S} = \\{1, 2, 3, 4, 5, 6\\}$.\n",
        "When flipping two coins, possible outcomes are\n",
        "$\\{(\\textrm{heads}, \\textrm{heads}), (\\textrm{heads}, \\textrm{tails}), (\\textrm{tails}, \\textrm{heads}),  (\\textrm{tails}, \\textrm{tails})\\}$.\n",
        "*Events* are subsets of the sample space.\n",
        "For instance, the event \"the first coin toss comes up heads\"\n",
        "corresponds to the set $\\{(\\textrm{heads}, \\textrm{heads}), (\\textrm{heads}, \\textrm{tails})\\}$.\n",
        "Whenever the outcome $z$ of a random experiment satisfies\n",
        "$z \\in \\mathcal{A}$, then event $\\mathcal{A}$ has occurred.\n",
        "For a single roll of a die, we could define the events\n",
        "\"seeing a $5$\" ($\\mathcal{A} = \\{5\\}$)\n",
        "and \"seeing an odd number\"  ($\\mathcal{B} = \\{1, 3, 5\\}$).\n",
        "In this case, if the die came up $5$,\n",
        "we would say that both $\\mathcal{A}$ and $\\mathcal{B}$ occurred.\n",
        "On the other hand, if $z = 3$,\n",
        "then $\\mathcal{A}$ did not occur\n",
        "but $\\mathcal{B}$ did.\n",
        "\n",
        "\n",
        "A *probability* function maps events\n",
        "onto real values ${P: \\mathcal{A} \\subseteq \\mathcal{S} \\rightarrow [0,1]}$.\n",
        "The probability, denoted $P(\\mathcal{A})$, of an event $\\mathcal{A}$\n",
        "in the given sample space $\\mathcal{S}$,\n",
        "has the following properties:\n",
        "\n",
        "* The probability of any event $\\mathcal{A}$ is a nonnegative real number, i.e., $P(\\mathcal{A}) \\geq 0$;\n",
        "* The probability of the entire sample space is $1$, i.e., $P(\\mathcal{S}) = 1$;\n",
        "* For any countable sequence of events $\\mathcal{A}_1, \\mathcal{A}_2, \\ldots$ that are *mutually exclusive* (i.e., $\\mathcal{A}_i \\cap \\mathcal{A}_j = \\emptyset$ for all $i \\neq j$), the probability that any of them happens is equal to the sum of their individual probabilities, i.e., $P(\\bigcup_{i=1}^{\\infty} \\mathcal{A}_i) = \\sum_{i=1}^{\\infty} P(\\mathcal{A}_i)$.\n",
        "\n",
        "These axioms of probability theory,\n",
        "proposed by :citet:`Kolmogorov.1933`,\n",
        "can be applied to rapidly derive a number of important consequences.\n",
        "For instance, it follows immediately\n",
        "that the probability of any event $\\mathcal{A}$\n",
        "*or* its complement $\\mathcal{A}'$ occurring is 1\n",
        "(because $\\mathcal{A} \\cup \\mathcal{A}' = \\mathcal{S}$).\n",
        "We can also prove that $P(\\emptyset) = 0$\n",
        "because $1 = P(\\mathcal{S} \\cup \\mathcal{S}') = P(\\mathcal{S} \\cup \\emptyset) = P(\\mathcal{S}) + P(\\emptyset) = 1 + P(\\emptyset)$.\n",
        "Consequently, the probability of any event $\\mathcal{A}$\n",
        "*and* its complement $\\mathcal{A}'$ occurring simultaneously\n",
        "is $P(\\mathcal{A} \\cap \\mathcal{A}') = 0$.\n",
        "Informally, this tells us that impossible events\n",
        "have zero probability of occurring.\n",
        "\n",
        "\n",
        "\n",
        "## Random Variables\n",
        "\n",
        "When we spoke about events like the roll of a die\n",
        "coming up odds or the first coin toss coming up heads,\n",
        "we were invoking the idea of a *random variable*.\n",
        "Formally, random variables are mappings\n",
        "from an underlying sample space\n",
        "to a set of (possibly many) values.\n",
        "You might wonder how a random variable\n",
        "is different from the sample space,\n",
        "since both are collections of outcomes.\n",
        "Importantly, random variables can be much coarser\n",
        "than the raw sample space.\n",
        "We can define a binary random variable like \"greater than 0.5\"\n",
        "even when the underlying sample space is infinite,\n",
        "e.g., points on the line segment between $0$ and $1$.\n",
        "Additionally, multiple random variables\n",
        "can share the same underlying sample space.\n",
        "For example \"whether my home alarm goes off\"\n",
        "and \"whether my house was burgled\"\n",
        "are both binary random variables\n",
        "that share an underlying sample space.\n",
        "Consequently, knowing the value taken by one random variable\n",
        "can tell us something about the likely value of another random variable.\n",
        "Knowing that the alarm went off,\n",
        "we might suspect that the house was likely burgled.\n",
        "\n",
        "\n",
        "Every value taken by a random variable corresponds\n",
        "to a subset of the underlying sample space.\n",
        "Thus the occurrence where the random variable $X$\n",
        "takes value $v$, denoted by $X=v$, is an *event*\n",
        "and $P(X=v)$ denotes its probability.\n",
        "Sometimes this notation can get clunky,\n",
        "and we can abuse notation when the context is clear.\n",
        "For example, we might use $P(X)$ to refer broadly\n",
        "to the *distribution* of $X$, i.e.,\n",
        "the function that tells us the probability\n",
        "that $X$ takes any given value.\n",
        "Other times we write expressions\n",
        "like $P(X,Y) = P(X) P(Y)$,\n",
        "as a shorthand to express a statement\n",
        "that is true for all of the values\n",
        "that the random variables $X$ and $Y$ can take, i.e.,\n",
        "for all $i,j$ it holds that $P(X=i \\textrm{ and } Y=j) = P(X=i)P(Y=j)$.\n",
        "Other times, we abuse notation by writing\n",
        "$P(v)$ when the random variable is clear from the context.\n",
        "Since an event in probability theory is a set of outcomes from the sample space,\n",
        "we can specify a range of values for a random variable to take.\n",
        "For example, $P(1 \\leq X \\leq 3)$ denotes the probability of the event $\\{1 \\leq X \\leq 3\\}$.\n",
        "\n",
        "\n",
        "Note that there is a subtle difference\n",
        "between *discrete* random variables,\n",
        "like flips of a coin or tosses of a die,\n",
        "and *continuous* ones,\n",
        "like the weight and the height of a person\n",
        "sampled at random from the population.\n",
        "In this case we seldom really care about\n",
        "someone's exact height.\n",
        "Moreover, if we took precise enough measurements,\n",
        "we would find that no two people on the planet\n",
        "have the exact same height.\n",
        "In fact, with fine enough measurements,\n",
        "you would never have the same height\n",
        "when you wake up and when you go to sleep.\n",
        "There is little point in asking about\n",
        "the exact probability that someone\n",
        "is 1.801392782910287192 meters tall.\n",
        "Instead, we typically care more about being able to say\n",
        "whether someone's height falls into a given interval,\n",
        "say between 1.79 and 1.81 meters.\n",
        "In these cases we work with probability *densities*.\n",
        "The height of exactly 1.80 meters\n",
        "has no probability, but nonzero density.\n",
        "To work out the probability assigned to an interval,\n",
        "we must take an *integral* of the density\n",
        "over that interval.\n",
        "\n",
        "## Multiple Random Variables\n",
        "\n",
        "You might have noticed that we could not even\n",
        "make it through the previous section without\n",
        "making statements involving interactions\n",
        "among multiple random variables\n",
        "(recall $P(X,Y) = P(X) P(Y)$).\n",
        "Most of machine learning\n",
        "is concerned with such relationships.\n",
        "Here, the sample space would be\n",
        "the population of interest,\n",
        "say customers who transact with a business,\n",
        "photographs on the Internet,\n",
        "or proteins known to biologists.\n",
        "Each random variable would represent\n",
        "the (unknown) value of a different attribute.\n",
        "Whenever we sample an individual from the population,\n",
        "we observe a realization of each of the random variables.\n",
        "Because the values taken by random variables\n",
        "correspond to subsets of the sample space\n",
        "that could be overlapping, partially overlapping,\n",
        "or entirely disjoint,\n",
        "knowing the value taken by one random variable\n",
        "can cause us to update our beliefs\n",
        "about which values of another random variable are likely.\n",
        "If a patient walks into a hospital\n",
        "and we observe that they\n",
        "are having trouble breathing\n",
        "and have lost their sense of smell,\n",
        "then we believe that they are more likely\n",
        "to have COVID-19 than we might\n",
        "if they had no trouble breathing\n",
        "and a perfectly ordinary sense of smell.\n",
        "\n",
        "\n",
        "When working with multiple random variables,\n",
        "we can construct events corresponding\n",
        "to every combination of values\n",
        "that the variables can jointly take.\n",
        "The probability function that assigns\n",
        "probabilities to each of these combinations\n",
        "(e.g. $A=a$ and $B=b$)\n",
        "is called the *joint probability* function\n",
        "and simply returns the probability assigned\n",
        "to the intersection of the corresponding subsets\n",
        "of the sample space.\n",
        "The *joint probability* assigned to the event\n",
        "where random variables $A$ and $B$\n",
        "take values $a$ and $b$, respectively,\n",
        "is denoted $P(A = a, B = b)$,\n",
        "where the comma indicates \"and\".\n",
        "Note that for any values $a$ and $b$,\n",
        "it follows that\n",
        "\n",
        "$$P(A=a, B=b) \\leq P(A=a) \\textrm{ and } P(A=a, B=b) \\leq P(B = b),$$\n",
        "\n",
        "since for $A=a$ and $B=b$ to happen,\n",
        "$A=a$ has to happen *and* $B=b$ also has to happen.\n",
        "Interestingly, the joint probability\n",
        "tells us all that we can know about these\n",
        "random variables in a probabilistic sense,\n",
        "and can be used to derive many other\n",
        "useful quantities, including recovering the\n",
        "individual distributions $P(A)$ and $P(B)$.\n",
        "To recover $P(A=a)$ we simply sum up\n",
        "$P(A=a, B=v)$ over all values $v$\n",
        "that the random variable $B$ can take:\n",
        "$P(A=a) = \\sum_v P(A=a, B=v)$.\n",
        "\n",
        "\n",
        "The ratio $\\frac{P(A=a, B=b)}{P(A=a)} \\leq 1$\n",
        "turns out to be extremely important.\n",
        "It is called the *conditional probability*,\n",
        "and is denoted via the \"$\\mid$\" symbol:\n",
        "\n",
        "$$P(B=b \\mid A=a) = P(A=a,B=b)/P(A=a).$$\n",
        "\n",
        "It tells us the new probability\n",
        "associated with the event $B=b$,\n",
        "once we condition on the fact $A=a$ took place.\n",
        "We can think of this conditional probability\n",
        "as restricting attention only to the subset\n",
        "of the sample space associated with $A=a$\n",
        "and then renormalizing so that\n",
        "all probabilities sum to 1.\n",
        "Conditional probabilities\n",
        "are in fact just ordinary probabilities\n",
        "and thus respect all of the axioms,\n",
        "as long as we condition all terms\n",
        "on the same event and thus\n",
        "restrict attention to the same sample space.\n",
        "For instance, for disjoint events\n",
        "$\\mathcal{B}$ and $\\mathcal{B}'$, we have that\n",
        "$P(\\mathcal{B} \\cup \\mathcal{B}' \\mid A = a) = P(\\mathcal{B} \\mid A = a) + P(\\mathcal{B}' \\mid A = a)$.\n",
        "\n",
        "\n",
        "Using the definition of conditional probabilities,\n",
        "we can derive the famous result called *Bayes' theorem*.\n",
        "By construction, we have that $P(A, B) = P(B\\mid A) P(A)$\n",
        "and $P(A, B) = P(A\\mid B) P(B)$.\n",
        "Combining both equations yields\n",
        "$P(B\\mid A) P(A) = P(A\\mid B) P(B)$ and hence\n",
        "\n",
        "$$P(A \\mid B) = \\frac{P(B\\mid A) P(A)}{P(B)}.$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This simple equation has profound implications because\n",
        "it allows us to reverse the order of conditioning.\n",
        "If we know how to estimate $P(B\\mid A)$, $P(A)$, and $P(B)$,\n",
        "then we can estimate $P(A\\mid B)$.\n",
        "We often find it easier to estimate one term directly\n",
        "but not the other and Bayes' theorem can come to the rescue here.\n",
        "For instance, if we know the prevalence of symptoms for a given disease,\n",
        "and the overall prevalences of the disease and symptoms, respectively,\n",
        "we can determine how likely someone is\n",
        "to have the disease based on their symptoms.\n",
        "In some cases we might not have direct access to $P(B)$,\n",
        "such as the prevalence of symptoms.\n",
        "In this case a simplified version of Bayes' theorem comes in handy:\n",
        "\n",
        "$$P(A \\mid B) \\propto P(B \\mid A) P(A).$$\n",
        "\n",
        "Since we know that $P(A \\mid B)$ must be normalized to $1$, i.e., $\\sum_a P(A=a \\mid B) = 1$,\n",
        "we can use it to compute\n",
        "\n",
        "$$P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{\\sum_a P(B \\mid A=a) P(A = a)}.$$\n",
        "\n",
        "In Bayesian statistics, we think of an observer\n",
        "as possessing some (subjective) prior beliefs\n",
        "about the plausibility of the available hypotheses\n",
        "encoded in the *prior* $P(H)$,\n",
        "and a *likelihood function* that says how likely\n",
        "one is to observe any value of the collected evidence\n",
        "for each of the hypotheses in the class $P(E \\mid H)$.\n",
        "Bayes' theorem is then interpreted as telling us\n",
        "how to update the initial *prior* $P(H)$\n",
        "in light of the available evidence $E$\n",
        "to produce *posterior* beliefs\n",
        "$P(H \\mid E) = \\frac{P(E \\mid H) P(H)}{P(E)}$.\n",
        "Informally, this can be stated as\n",
        "\"posterior equals prior times likelihood, divided by the evidence\".\n",
        "Now, because the evidence $P(E)$ is the same for all hypotheses,\n",
        "we can get away with simply normalizing over the hypotheses.\n",
        "\n",
        "Note that $\\sum_a P(A=a \\mid B) = 1$ also allows us to *marginalize* over random variables. That is, we can drop variables from a joint distribution such as $P(A, B)$. After all, we have that\n",
        "\n",
        "$$\\sum_a P(B \\mid A=a) P(A=a) = \\sum_a P(B, A=a) = P(B).$$\n",
        "\n",
        "Independence is another fundamentally important concept\n",
        "that forms the backbone of\n",
        "many important ideas in statistics.\n",
        "In short, two variables are *independent*\n",
        "if conditioning on the value of $A$ does not\n",
        "cause any change to the probability distribution\n",
        "associated with $B$ and vice versa.\n",
        "More formally, independence, denoted $A \\perp B$,\n",
        "requires that $P(A \\mid B) = P(A)$ and, consequently,\n",
        "that $P(A,B) = P(A \\mid B) P(B) = P(A) P(B)$.\n",
        "Independence is often an appropriate assumption.\n",
        "For example, if the random variable $A$\n",
        "represents the outcome from tossing one fair coin\n",
        "and the random variable $B$\n",
        "represents the outcome from tossing another,\n",
        "then knowing whether $A$ came up heads\n",
        "should not influence the probability\n",
        "of $B$ coming up heads.\n",
        "\n",
        "\n",
        "Independence is especially useful when it holds among the successive\n",
        "draws of our data from some underlying distribution\n",
        "(allowing us to make strong statistical conclusions)\n",
        "or when it holds among various variables in our data,\n",
        "allowing us to work with simpler models\n",
        "that encode this independence structure.\n",
        "On the other hand, estimating the dependencies\n",
        "among random variables is often the very aim of learning.\n",
        "We care to estimate the probability of disease given symptoms\n",
        "specifically because we believe\n",
        "that diseases and symptoms are *not* independent.\n",
        "\n",
        "\n",
        "Note that because conditional probabilities are proper probabilities,\n",
        "the concepts of independence and dependence also apply to them.\n",
        "Two random variables $A$ and $B$ are *conditionally independent*\n",
        "given a third variable $C$ if and only if $P(A, B \\mid C) = P(A \\mid C)P(B \\mid C)$.\n",
        "Interestingly, two variables can be independent in general\n",
        "but become dependent when conditioning on a third.\n",
        "This often occurs when the two random variables $A$ and $B$\n",
        "correspond to causes of some third variable $C$.\n",
        "For example, broken bones and lung cancer might be independent\n",
        "in the general population but if we condition on being in the hospital\n",
        "then we might find that broken bones are negatively correlated with lung cancer.\n",
        "That is because the broken bone *explains away* why some person is in the hospital\n",
        "and thus lowers the probability that they are hospitalized because of having lung cancer.\n",
        "\n",
        "\n",
        "And conversely, two dependent random variables\n",
        "can become independent upon conditioning on a third.\n",
        "This often happens when two otherwise unrelated events\n",
        "have a common cause.\n",
        "Shoe size and reading level are highly correlated\n",
        "among elementary school students,\n",
        "but this correlation disappears if we condition on age.\n",
        "\n",
        "\n",
        "\n",
        "## An Example\n",
        ":label:`subsec_probability_hiv_app`\n",
        "\n",
        "Let's put our skills to the test.\n",
        "Assume that a doctor administers an HIV test to a patient.\n",
        "This test is fairly accurate and fails only with 1% probability\n",
        "if the patient is healthy but reported as diseased,\n",
        "i.e., healthy patients test positive in 1% of cases.\n",
        "Moreover, it never fails to detect HIV if the patient actually has it.\n",
        "We use $D_1 \\in \\{0, 1\\}$ to indicate the diagnosis\n",
        "($0$ if negative and $1$ if positive)\n",
        "and $H \\in \\{0, 1\\}$ to denote the HIV status.\n",
        "\n",
        "| Conditional probability | $H=1$ | $H=0$ |\n",
        "|:------------------------|------:|------:|\n",
        "| $P(D_1 = 1 \\mid H)$        |     1 |  0.01 |\n",
        "| $P(D_1 = 0 \\mid H)$        |     0 |  0.99 |\n",
        "\n",
        "Note that the column sums are all 1 (but the row sums do not),\n",
        "since they are conditional probabilities.\n",
        "Let's compute the probability of the patient having HIV\n",
        "if the test comes back positive, i.e., $P(H = 1 \\mid D_1 = 1)$.\n",
        "Intuitively this is going to depend on how common the disease is,\n",
        "since it affects the number of false alarms.\n",
        "Assume that the population is fairly free of the disease, e.g., $P(H=1) = 0.0015$.\n",
        "To apply Bayes' theorem, we need to apply marginalization\n",
        "to determine\n",
        "\n",
        "$$\\begin{aligned}\n",
        "P(D_1 = 1)\n",
        "=& P(D_1=1, H=0) + P(D_1=1, H=1)  \\\\\n",
        "=& P(D_1=1 \\mid H=0) P(H=0) + P(D_1=1 \\mid H=1) P(H=1) \\\\\n",
        "=& 0.011485.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This leads us to\n",
        "\n",
        "$$P(H = 1 \\mid D_1 = 1) = \\frac{P(D_1=1 \\mid H=1) P(H=1)}{P(D_1=1)} = 0.1306.$$\n",
        "\n",
        "In other words, there is only a 13.06% chance\n",
        "that the patient actually has HIV,\n",
        "despite the test being pretty accurate.\n",
        "As we can see, probability can be counterintuitive.\n",
        "What should a patient do upon receiving such terrifying news?\n",
        "Likely, the patient would ask the physician\n",
        "to administer another test to get clarity.\n",
        "The second test has different characteristics\n",
        "and it is not as good as the first one.\n",
        "\n",
        "| Conditional probability | $H=1$ | $H=0$ |\n",
        "|:------------------------|------:|------:|\n",
        "| $P(D_2 = 1 \\mid H)$          |  0.98 |  0.03 |\n",
        "| $P(D_2 = 0 \\mid H)$          |  0.02 |  0.97 |\n",
        "\n",
        "Unfortunately, the second test comes back positive, too.\n",
        "Let's calculate the requisite probabilities to invoke Bayes' theorem\n",
        "by assuming conditional independence:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "P(D_1 = 1, D_2 = 1 \\mid H = 0)\n",
        "& = P(D_1 = 1 \\mid H = 0) P(D_2 = 1 \\mid H = 0)\n",
        "=& 0.0003, \\\\\n",
        "P(D_1 = 1, D_2 = 1 \\mid H = 1)\n",
        "& = P(D_1 = 1 \\mid H = 1) P(D_2 = 1 \\mid H = 1)\n",
        "=& 0.98.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Now we can apply marginalization to obtain the probability\n",
        "that both tests come back positive:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "&P(D_1 = 1, D_2 = 1)\\\\\n",
        "&= P(D_1 = 1, D_2 = 1, H = 0) + P(D_1 = 1, D_2 = 1, H = 1)  \\\\\n",
        "&= P(D_1 = 1, D_2 = 1 \\mid H = 0)P(H=0) + P(D_1 = 1, D_2 = 1 \\mid H = 1)P(H=1)\\\\\n",
        "&= 0.00176955.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Finally, the probability of the patient having HIV given that both tests are positive is\n",
        "\n",
        "$$P(H = 1 \\mid D_1 = 1, D_2 = 1)\n",
        "= \\frac{P(D_1 = 1, D_2 = 1 \\mid H=1) P(H=1)}{P(D_1 = 1, D_2 = 1)}\n",
        "= 0.8307.$$\n",
        "\n",
        "That is, the second test allowed us to gain much higher confidence that not all is well.\n",
        "Despite the second test being considerably less accurate than the first one,\n",
        "it still significantly improved our estimate.\n",
        "The assumption of both tests being conditionally independent of each other\n",
        "was crucial for our ability to generate a more accurate estimate.\n",
        "Take the extreme case where we run the same test twice.\n",
        "In this situation we would expect the same outcome both times,\n",
        "hence no additional insight is gained from running the same test again.\n",
        "The astute reader might have noticed that the diagnosis behaved\n",
        "like a classifier hiding in plain sight\n",
        "where our ability to decide whether a patient is healthy\n",
        "increases as we obtain more features (test outcomes).\n",
        "\n",
        "\n",
        "## Expectations\n",
        "\n",
        "Often, making decisions requires not just looking\n",
        "at the probabilities assigned to individual events\n",
        "but composing them together into useful aggregates\n",
        "that can provide us with guidance.\n",
        "For example, when random variables take continuous scalar values,\n",
        "we often care about knowing what value to expect *on average*.\n",
        "This quantity is formally called an *expectation*.\n",
        "If we are making investments,\n",
        "the first quantity of interest\n",
        "might be the return we can expect,\n",
        "averaging over all the possible outcomes\n",
        "(and weighting by the appropriate probabilities).\n",
        "For instance, say that with 50% probability,\n",
        "an investment might fail altogether,\n",
        "with 40% probability it might provide a 2$\\times$ return,\n",
        "and with 10% probability it might provide a 10$\\times$ return 10$\\times$.\n",
        "To calculate the expected return,\n",
        "we sum over all returns, multiplying each\n",
        "by the probability that they will occur.\n",
        "This yields the expectation\n",
        "$0.5 \\cdot 0 + 0.4 \\cdot 2 + 0.1 \\cdot 10 = 1.8$.\n",
        "Hence the expected return is 1.8$\\times$.\n",
        "\n",
        "\n",
        "In general, the *expectation* (or average)\n",
        "of the random variable $X$ is defined as\n",
        "\n",
        "$$E[X] = E_{x \\sim P}[x] = \\sum_{x} x P(X = x).$$\n",
        "\n",
        "Likewise, for densities we obtain $E[X] = \\int x \\;dp(x)$.\n",
        "Sometimes we are interested in the expected value\n",
        "of some function of $x$.\n",
        "We can calculate these expectations as\n",
        "\n",
        "$$E_{x \\sim P}[f(x)] = \\sum_x f(x) P(x) \\textrm{ and } E_{x \\sim P}[f(x)] = \\int f(x) p(x) \\;dx$$\n",
        "\n",
        "for discrete probabilities and densities, respectively.\n",
        "Returning to the investment example from above,\n",
        "$f$ might be the *utility* (happiness)\n",
        "associated with the return.\n",
        "Behavior economists have long noted\n",
        "that people associate greater disutility\n",
        "with losing money than the utility gained\n",
        "from earning one dollar relative to their baseline.\n",
        "Moreover, the value of money tends to be sub-linear.\n",
        "Possessing 100k dollars versus zero dollars\n",
        "can make the difference between paying the rent,\n",
        "eating well, and enjoying quality healthcare\n",
        "versus suffering through homelessness.\n",
        "On the other hand, the gains due to possessing\n",
        "200k versus 100k are less dramatic.\n",
        "Reasoning like this motivates the cliché\n",
        "that \"the utility of money is logarithmic\".\n",
        "\n",
        "\n",
        "If  the utility associated with a total loss were $-1$,\n",
        "and the utilities associated with returns of $1$, $2$, and $10$\n",
        "were $1$, $2$ and $4$, respectively,\n",
        "then the expected happiness of investing\n",
        "would be $0.5 \\cdot (-1) + 0.4 \\cdot 2 + 0.1 \\cdot 4 = 0.7$\n",
        "(an expected loss of utility of 30%).\n",
        "If indeed this were your utility function,\n",
        "you might be best off keeping the money in the bank.\n",
        "\n",
        "For financial decisions,\n",
        "we might also want to measure\n",
        "how *risky* an investment is.\n",
        "Here, we care not just about the expected value\n",
        "but how much the actual values tend to *vary*\n",
        "relative to this value.\n",
        "Note that we cannot just take\n",
        "the expectation of the difference\n",
        "between the actual and expected values.\n",
        "This is because the expectation of a difference\n",
        "is the difference of the expectations,\n",
        "i.e., $E[X - E[X]] = E[X] - E[E[X]] = 0$.\n",
        "However, we can look at the expectation\n",
        "of any non-negative function of this difference.\n",
        "The *variance* of a random variable is calculated by looking\n",
        "at the expected value of the *squared* differences:\n",
        "\n",
        "$$\\textrm{Var}[X] = E\\left[(X - E[X])^2\\right] = E[X^2] - E[X]^2.$$\n",
        "\n",
        "Here the equality follows by expanding\n",
        "$(X - E[X])^2 = X^2 - 2 X E[X] + E[X]^2$\n",
        "and taking expectations for each term.\n",
        "The square root of the variance is another\n",
        "useful quantity called the *standard deviation*.\n",
        "While this and the variance\n",
        "convey the same information (either can be calculated from the other),\n",
        "the standard deviation has the nice property\n",
        "that it is expressed in the same units\n",
        "as the original quantity represented\n",
        "by the random variable.\n",
        "\n",
        "Lastly, the variance of a function\n",
        "of a random variable\n",
        "is defined analogously as\n",
        "\n",
        "$$\\textrm{Var}_{x \\sim P}[f(x)] = E_{x \\sim P}[f^2(x)] - E_{x \\sim P}[f(x)]^2.$$\n",
        "\n",
        "Returning to our investment example,\n",
        "we can now compute the variance of the investment.\n",
        "It is given by $0.5 \\cdot 0 + 0.4 \\cdot 2^2 + 0.1 \\cdot 10^2 - 1.8^2 = 8.36$.\n",
        "For all intents and purposes this is a risky investment.\n",
        "Note that by mathematical convention mean and variance\n",
        "are often referenced as $\\mu$ and $\\sigma^2$.\n",
        "This is particularly the case whenever we use it\n",
        "to parametrize a Gaussian distribution.\n",
        "\n",
        "In the same way as we introduced expectations\n",
        "and variance for *scalar* random variables,\n",
        "we can do so for vector-valued ones.\n",
        "Expectations are easy, since we can apply them elementwise.\n",
        "For instance, $\\boldsymbol{\\mu} \\stackrel{\\textrm{def}}{=} E_{\\mathbf{x} \\sim P}[\\mathbf{x}]$\n",
        "has coordinates $\\mu_i = E_{\\mathbf{x} \\sim P}[x_i]$.\n",
        "*Covariances* are more complicated.\n",
        "We define them by taking expectations of the *outer product*\n",
        "of the difference between random variables and their mean:\n",
        "\n",
        "$$\\boldsymbol{\\Sigma} \\stackrel{\\textrm{def}}{=} \\textrm{Cov}_{\\mathbf{x} \\sim P}[\\mathbf{x}] = E_{\\mathbf{x} \\sim P}\\left[(\\mathbf{x} - \\boldsymbol{\\mu}) (\\mathbf{x} - \\boldsymbol{\\mu})^\\top\\right].$$\n",
        "\n",
        "This matrix $\\boldsymbol{\\Sigma}$ is referred to as the covariance matrix.\n",
        "An easy way to see its effect is to consider some vector $\\mathbf{v}$\n",
        "of the same size as $\\mathbf{x}$.\n",
        "It follows that\n",
        "\n",
        "$$\\mathbf{v}^\\top \\boldsymbol{\\Sigma} \\mathbf{v} = E_{\\mathbf{x} \\sim P}\\left[\\mathbf{v}^\\top(\\mathbf{x} - \\boldsymbol{\\mu}) (\\mathbf{x} - \\boldsymbol{\\mu})^\\top \\mathbf{v}\\right] = \\textrm{Var}_{x \\sim P}[\\mathbf{v}^\\top \\mathbf{x}].$$\n",
        "\n",
        "As such, $\\boldsymbol{\\Sigma}$ allows us to compute the variance\n",
        "for any linear function of $\\mathbf{x}$\n",
        "by a simple matrix multiplication.\n",
        "The off-diagonal elements tell us how correlated the coordinates are:\n",
        "a value of 0 means no correlation,\n",
        "where a larger positive value\n",
        "means that they are more strongly correlated.\n",
        "\n",
        "\n",
        "\n",
        "## Discussion\n",
        "\n",
        "In machine learning, there are many things to be uncertain about!\n",
        "We can be uncertain about the value of a label given an input.\n",
        "We can be uncertain about the estimated value of a parameter.\n",
        "We can even be uncertain about whether data arriving at deployment\n",
        "is even from the same distribution as the training data.\n",
        "\n",
        "By *aleatoric uncertainty*, we mean uncertainty\n",
        "that is intrinsic to the problem,\n",
        "and due to genuine randomness\n",
        "unaccounted for by the observed variables.\n",
        "By *epistemic uncertainty*, we mean uncertainty\n",
        "over a model's parameters, the sort of uncertainty\n",
        "that we can hope to reduce by collecting more data.\n",
        "We might have epistemic uncertainty\n",
        "concerning the probability\n",
        "that a coin turns up heads,\n",
        "but even once we know this probability,\n",
        "we are left with aleatoric uncertainty\n",
        "about the outcome of any future toss.\n",
        "No matter how long we watch someone tossing a fair coin,\n",
        "we will never be more or less than 50% certain\n",
        "that the next toss will come up heads.\n",
        "These terms come from mechanical modeling,\n",
        "(see e.g., :citet:`Der-Kiureghian.Ditlevsen.2009` for a review on this aspect of [uncertainty quantification](https://en.wikipedia.org/wiki/Uncertainty_quantification)).\n",
        "It is worth noting, however, that these terms constitute a slight abuse of language.\n",
        "The term *epistemic* refers to anything concerning *knowledge*\n",
        "and thus, in the philosophical sense, all uncertainty is epistemic.\n",
        "\n",
        "\n",
        "We saw that sampling data from some unknown probability distribution\n",
        "can provide us with information that can be used to estimate\n",
        "the parameters of the data generating distribution.\n",
        "That said, the rate at which this is possible can be quite slow.\n",
        "In our coin tossing example (and many others)\n",
        "we can do no better than to design estimators\n",
        "that converge at a rate of $1/\\sqrt{n}$,\n",
        "where $n$ is the sample size (e.g., the number of tosses).\n",
        "This means that by going from 10 to 1000 observations (usually a very achievable task)\n",
        "we see a tenfold reduction of uncertainty,\n",
        "whereas the next 1000 observations help comparatively little,\n",
        "offering only a 1.41 times reduction.\n",
        "This is a persistent feature of machine learning:\n",
        "while there are often easy gains, it takes a very large amount of data,\n",
        "and often with it an enormous amount of computation, to make further gains.\n",
        "For an empirical review of this fact for large scale language models see :citet:`Revels.Lubin.Papamarkou.2016`.\n",
        "\n",
        "We also sharpened our language and tools for statistical modeling.\n",
        "In the process of that we learned about conditional probabilities\n",
        "and about one of the most important equations in statistics---Bayes' theorem.\n",
        "It is an effective tool for decoupling information conveyed by data\n",
        "through a likelihood term $P(B \\mid A)$ that addresses\n",
        "how well observations $B$ match a choice of parameters $A$,\n",
        "and a prior probability $P(A)$ which governs how plausible\n",
        "a particular choice of $A$ was in the first place.\n",
        "In particular, we saw how this rule can be applied\n",
        "to assign probabilities to diagnoses,\n",
        "based on the efficacy of the test *and*\n",
        "the prevalence of the disease itself (i.e., our prior).\n",
        "\n",
        "Lastly, we introduced a first set of nontrivial questions\n",
        "about the effect of a specific probability distribution,\n",
        "namely expectations and variances.\n",
        "While there are many more than just linear and quadratic\n",
        "expectations for a probability distribution,\n",
        "these two already provide a good deal of knowledge\n",
        "about the possible behavior of the distribution.\n",
        "For instance, [Chebyshev's inequality](https://en.wikipedia.org/wiki/Chebyshev%27s_inequality)\n",
        "states that $P(|X - \\mu| \\geq k \\sigma) \\leq 1/k^2$,\n",
        "where $\\mu$ is the expectation, $\\sigma^2$ is the variance of the distribution,\n",
        "and $k > 1$ is a confidence parameter of our choosing.\n",
        "It tells us that draws from a distribution lie\n",
        "with at least 50% probability\n",
        "within a $[-\\sqrt{2} \\sigma, \\sqrt{2} \\sigma]$\n",
        "interval centered on the expectation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Give an example where observing more data can reduce the amount of uncertainty about the outcome to an arbitrarily low level.\n",
        "1. Give an example where observing more data will only reduce the amount of uncertainty up to a point and then no further. Explain why this is the case and where you expect this point to occur.\n",
        "1. We empirically demonstrated convergence to the mean for the toss of a coin. Calculate the variance of the estimate of the probability that we see a head after drawing $n$ samples.\n",
        "    1. How does the variance scale with the number of observations?\n",
        "    1. Use Chebyshev's inequality to bound the deviation from the expectation.\n",
        "    1. How does it relate to the central limit theorem?\n",
        "1. Assume that we draw $m$ samples $x_i$ from a probability distribution with zero mean and unit variance. Compute the averages $z_m \\stackrel{\\textrm{def}}{=} m^{-1} \\sum_{i=1}^m x_i$. Can we apply Chebyshev's inequality for every $z_m$ independently? Why not?\n",
        "1. Given two events with probability $P(\\mathcal{A})$ and $P(\\mathcal{B})$, compute upper and lower bounds on $P(\\mathcal{A} \\cup \\mathcal{B})$ and $P(\\mathcal{A} \\cap \\mathcal{B})$. Hint: graph the situation using a [Venn diagram](https://en.wikipedia.org/wiki/Venn_diagram).\n",
        "1. Assume that we have a sequence of random variables, say $A$, $B$, and $C$, where $B$ only depends on $A$, and $C$ only depends on $B$, can you simplify the joint probability $P(A, B, C)$? Hint: this is a [Markov chain](https://en.wikipedia.org/wiki/Markov_chain).\n",
        "1. In :numref:`subsec_probability_hiv_app`, assume that the outcomes of the two tests are not independent. In particular assume that either test on its own has a false positive rate of 10% and a false negative rate of 1%. That is, assume that $P(D =1 \\mid H=0) = 0.1$ and that $P(D = 0 \\mid H=1) = 0.01$. Moreover, assume that for $H = 1$ (infected) the test outcomes are conditionally independent, i.e., that $P(D_1, D_2 \\mid H=1) = P(D_1 \\mid H=1) P(D_2 \\mid H=1)$ but that for healthy patients the outcomes are coupled via $P(D_1 = D_2 = 1 \\mid H=0) = 0.02$.\n",
        "    1. Work out the joint probability table for $D_1$ and $D_2$, given $H=0$ based on the information you have so far.\n",
        "    1. Derive the probability that the patient is diseased ($H=1$) after one test returns positive. You can assume the same baseline probability $P(H=1) = 0.0015$ as before.\n",
        "    1. Derive the probability that the patient is diseased ($H=1$) after both tests return positive.\n",
        "1. Assume that you are an asset manager for an investment bank and you have a choice of stocks $s_i$ to invest in. Your portfolio needs to add up to $1$ with weights $\\alpha_i$ for each stock. The stocks have an average return $\\boldsymbol{\\mu} = E_{\\mathbf{s} \\sim P}[\\mathbf{s}]$ and covariance $\\boldsymbol{\\Sigma} = \\textrm{Cov}_{\\mathbf{s} \\sim P}[\\mathbf{s}]$.\n",
        "    1. Compute the expected return for a given portfolio $\\boldsymbol{\\alpha}$.\n",
        "    1. If you wanted to maximize the return of the portfolio, how should you choose your investment?\n",
        "    1. Compute the *variance* of the portfolio.\n",
        "    1. Formulate an optimization problem of maximizing the return while keeping the variance constrained to an upper bound. This is the Nobel-Prize winning [Markovitz portfolio](https://en.wikipedia.org/wiki/Markowitz_model) :cite:`Mangram.2013`. To solve it you will need a quadratic programming solver, something way beyond the scope of this book.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "126c2b93",
      "metadata": {
        "origin_pos": 31,
        "tab": [
          "pytorch"
        ],
        "id": "126c2b93"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/37)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}