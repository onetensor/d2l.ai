{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c2ef73a8",
      "metadata": {
        "id": "c2ef73a8"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a66c1f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a66c1f7",
        "outputId": "3b59bdac-a5ce-47db-bc0b-cd5e3dbf5039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: d2l==1.0.3 in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.11/dist-packages (from d2l==1.0.3) (1.0.0)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (from d2l==1.0.3) (1.23.5)\n",
            "Requirement already satisfied: matplotlib==3.7.2 in /usr/local/lib/python3.11/dist-packages (from d2l==1.0.3) (3.7.2)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.11/dist-packages (from d2l==1.0.3) (0.1.6)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.11/dist-packages (from d2l==1.0.3) (2.31.0)\n",
            "Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.11/dist-packages (from d2l==1.0.3) (2.0.3)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.11/dist-packages (from d2l==1.0.3) (1.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.7)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (2.9.0.post0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from matplotlib-inline==0.1.6->d2l==1.0.3) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l==1.0.3) (1.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.4.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.0.15)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (2.19.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.8.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (25.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.1)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from qtconsole->jupyter==1.0.0->d2l==1.0.3) (2.4.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.24.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l==1.0.3) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l==1.0.3) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.25.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad19fa4",
      "metadata": {
        "origin_pos": 1,
        "id": "0ad19fa4"
      },
      "source": [
        "# Probability and Statistics\n",
        ":label:`sec_prob`\n",
        "\n",
        "One way or another,\n",
        "machine learning is all about uncertainty.\n",
        "In supervised learning, we want to predict\n",
        "something unknown (the *target*)\n",
        "given something known (the *features*).\n",
        "Depending on our objective,\n",
        "we might attempt to predict\n",
        "the most likely value of the target.\n",
        "Or we might predict the value with the smallest\n",
        "expected distance from the target.\n",
        "And sometimes we wish not only\n",
        "to predict a specific value\n",
        "but to *quantify our uncertainty*.\n",
        "For example, given some features\n",
        "describing a patient,\n",
        "we might want to know *how likely* they are\n",
        "to suffer a heart attack in the next year.\n",
        "In unsupervised learning,\n",
        "we often care about uncertainty.\n",
        "To determine whether a set of measurements are anomalous,\n",
        "it helps to know how likely one is\n",
        "to observe values in a population of interest.\n",
        "Furthermore, in reinforcement learning,\n",
        "we wish to develop agents\n",
        "that act intelligently in various environments.\n",
        "This requires reasoning about\n",
        "how an environment might be expected to change\n",
        "and what rewards one might expect to encounter\n",
        "in response to each of the available actions.\n",
        "\n",
        "*Probability* is the mathematical field\n",
        "concerned with reasoning under uncertainty.\n",
        "Given a probabilistic model of some process,\n",
        "we can reason about the likelihood of various events.\n",
        "The use of probabilities to describe\n",
        "the frequencies of repeatable events\n",
        "(like coin tosses)\n",
        "is fairly uncontroversial.\n",
        "In fact, *frequentist* scholars adhere\n",
        "to an interpretation of probability\n",
        "that applies *only* to such repeatable events.\n",
        "By contrast *Bayesian* scholars\n",
        "use the language of probability more broadly\n",
        "to formalize reasoning under uncertainty.\n",
        "Bayesian probability is characterized\n",
        "by two unique features:\n",
        "(i) assigning degrees of belief\n",
        "to non-repeatable events,\n",
        "e.g., what is the *probability*\n",
        "that a dam will collapse?;\n",
        "and (ii) subjectivity. While Bayesian\n",
        "probability provides unambiguous rules\n",
        "for how one should update their beliefs\n",
        "in light of new evidence,\n",
        "it allows for different individuals\n",
        "to start off with different *prior* beliefs.\n",
        "*Statistics* helps us to reason backwards,\n",
        "starting off with collection and organization of data\n",
        "and backing out to what inferences\n",
        "we might draw about the process\n",
        "that generated the data.\n",
        "Whenever we analyze a dataset, hunting for patterns\n",
        "that we hope might characterize a broader population,\n",
        "we are employing statistical thinking.\n",
        "Many courses, majors, theses, careers, departments,\n",
        "companies, and institutions have been devoted\n",
        "to the study of probability and statistics.\n",
        "While this section only scratches the surface,\n",
        "we will provide the foundation\n",
        "that you need to begin building models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "15d26295",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:41.010215Z",
          "iopub.status.busy": "2023-08-18T19:35:41.009884Z",
          "iopub.status.idle": "2023-08-18T19:35:44.240517Z",
          "shell.execute_reply": "2023-08-18T19:35:44.239244Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "15d26295"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import random\n",
        "import torch\n",
        "from torch.distributions.multinomial import Multinomial\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "390fa88a",
      "metadata": {
        "origin_pos": 6,
        "id": "390fa88a"
      },
      "source": [
        "## A Simple Example: Tossing Coins\n",
        "\n",
        "Imagine that we plan to toss a coin\n",
        "and want to quantify how likely\n",
        "we are to see heads (vs. tails).\n",
        "If the coin is *fair*,\n",
        "then both outcomes\n",
        "(heads and tails),\n",
        "are equally likely.\n",
        "Moreover if we plan to toss the coin $n$ times\n",
        "then the fraction of heads\n",
        "that we *expect* to see\n",
        "should exactly match\n",
        "the *expected* fraction of tails.\n",
        "One intuitive way to see this\n",
        "is by symmetry:\n",
        "for every possible outcome\n",
        "with $n_\\textrm{h}$ heads and $n_\\textrm{t} = (n - n_\\textrm{h})$ tails,\n",
        "there is an equally likely outcome\n",
        "with $n_\\textrm{t}$ heads and $n_\\textrm{h}$ tails.\n",
        "Note that this is only possible\n",
        "if on average we expect to see\n",
        "$1/2$ of tosses come up heads\n",
        "and $1/2$ come up tails.\n",
        "Of course, if you conduct this experiment\n",
        "many times with $n=1000000$ tosses each,\n",
        "you might never see a trial\n",
        "where $n_\\textrm{h} = n_\\textrm{t}$ exactly.\n",
        "\n",
        "\n",
        "Formally, the quantity $1/2$ is called a *probability*\n",
        "and here it captures the certainty with which\n",
        "any given toss will come up heads.\n",
        "Probabilities assign scores between $0$ and $1$\n",
        "to outcomes of interest, called *events*.\n",
        "Here the event of interest is $\\textrm{heads}$\n",
        "and we denote the corresponding probability $P(\\textrm{heads})$.\n",
        "A probability of $1$ indicates absolute certainty\n",
        "(imagine a trick coin where both sides were heads)\n",
        "and a probability of $0$ indicates impossibility\n",
        "(e.g., if both sides were tails).\n",
        "The frequencies $n_\\textrm{h}/n$ and $n_\\textrm{t}/n$ are not probabilities\n",
        "but rather *statistics*.\n",
        "Probabilities are *theoretical* quantities\n",
        "that underly the data generating process.\n",
        "Here, the probability $1/2$\n",
        "is a property of the coin itself.\n",
        "By contrast, statistics are *empirical* quantities\n",
        "that are computed as functions of the observed data.\n",
        "Our interests in probabilistic and statistical quantities\n",
        "are inextricably intertwined.\n",
        "We often design special statistics called *estimators*\n",
        "that, given a dataset, produce *estimates*\n",
        "of model parameters such as probabilities.\n",
        "Moreover, when those estimators satisfy\n",
        "a nice property called *consistency*,\n",
        "our estimates will converge\n",
        "to the corresponding probability.\n",
        "In turn, these inferred probabilities\n",
        "tell about the likely statistical properties\n",
        "of data from the same population\n",
        "that we might encounter in the future.\n",
        "\n",
        "Suppose that we stumbled upon a real coin\n",
        "for which we did not know\n",
        "the true $P(\\textrm{heads})$.\n",
        "To investigate this quantity\n",
        "with statistical methods,\n",
        "we need to (i) collect some data;\n",
        "and (ii) design an estimator.\n",
        "Data acquisition here is easy;\n",
        "we can toss the coin many times\n",
        "and record all the outcomes.\n",
        "Formally, drawing realizations\n",
        "from some underlying random process\n",
        "is called *sampling*.\n",
        "As you might have guessed,\n",
        "one natural estimator\n",
        "is the ratio of\n",
        "the number of observed *heads*\n",
        "to the total number of tosses.\n",
        "\n",
        "Now, suppose that the coin was in fact fair,\n",
        "i.e., $P(\\textrm{heads}) = 0.5$.\n",
        "To simulate tosses of a fair coin,\n",
        "we can invoke any random number generator.\n",
        "There are some easy ways to draw samples\n",
        "of an event with probability $0.5$.\n",
        "For example Python's `random.random`\n",
        "yields numbers in the interval $[0,1]$\n",
        "where the probability of lying\n",
        "in any sub-interval $[a, b] \\subset [0,1]$\n",
        "is equal to $b-a$.\n",
        "Thus we can get out `0` and `1` with probability `0.5` each\n",
        "by testing whether the returned float number is greater than `0.5`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3a500e66",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.245216Z",
          "iopub.status.busy": "2023-08-18T19:35:44.244448Z",
          "iopub.status.idle": "2023-08-18T19:35:44.250559Z",
          "shell.execute_reply": "2023-08-18T19:35:44.249469Z"
        },
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a500e66",
        "outputId": "f2f224d5-e47b-49e1-95c6-f7957b2957dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heads, tails:  [49, 51]\n"
          ]
        }
      ],
      "source": [
        "num_tosses = 100\n",
        "heads = sum([random.random() > 0.5 for _ in range(num_tosses)])\n",
        "tails = num_tosses - heads\n",
        "print(\"heads, tails: \", [heads, tails])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "096c1837",
      "metadata": {
        "origin_pos": 8,
        "id": "096c1837"
      },
      "source": [
        "More generally, we can simulate multiple draws\n",
        "from any variable with a finite number\n",
        "of possible outcomes\n",
        "(like the toss of a coin or roll of a die)\n",
        "by calling the multinomial function,\n",
        "setting the first argument\n",
        "to the number of draws\n",
        "and the second as a list of probabilities\n",
        "associated with each of the possible outcomes.\n",
        "To simulate ten tosses of a fair coin,\n",
        "we assign probability vector `[0.5, 0.5]`,\n",
        "interpreting index 0 as heads\n",
        "and index 1 as tails.\n",
        "The function returns a vector\n",
        "with length equal to the number\n",
        "of possible outcomes (here, 2),\n",
        "where the first component tells us\n",
        "the number of occurrences of heads\n",
        "and the second component tells us\n",
        "the number of occurrences of tails.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b70ba754",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.256289Z",
          "iopub.status.busy": "2023-08-18T19:35:44.255841Z",
          "iopub.status.idle": "2023-08-18T19:35:44.292323Z",
          "shell.execute_reply": "2023-08-18T19:35:44.291255Z"
        },
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b70ba754",
        "outputId": "c8634885-ac0c-4c96-bb1c-82caabc07fd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([51., 49.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "fair_probs = torch.tensor([0.5, 0.5])\n",
        "Multinomial(100, fair_probs).sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca81b0bc",
      "metadata": {
        "origin_pos": 13,
        "id": "ca81b0bc"
      },
      "source": [
        "Each time you run this sampling process,\n",
        "you will receive a new random value\n",
        "that may differ from the previous outcome.\n",
        "Dividing by the number of tosses\n",
        "gives us the *frequency*\n",
        "of each outcome in our data.\n",
        "Note that these frequencies,\n",
        "just like the probabilities\n",
        "that they are intended\n",
        "to estimate, sum to $1$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d4157453",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.297194Z",
          "iopub.status.busy": "2023-08-18T19:35:44.296806Z",
          "iopub.status.idle": "2023-08-18T19:35:44.309679Z",
          "shell.execute_reply": "2023-08-18T19:35:44.308709Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4157453",
        "outputId": "f3ea46e7-f0d3-4ea3-bab2-d92a5572177e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5000, 0.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "Multinomial(100, fair_probs).sample() / 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5135ef92",
      "metadata": {
        "origin_pos": 18,
        "id": "5135ef92"
      },
      "source": [
        "Here, even though our simulated coin is fair\n",
        "(we ourselves set the probabilities `[0.5, 0.5]`),\n",
        "the counts of heads and tails may not be identical.\n",
        "That is because we only drew a relatively small number of samples.\n",
        "If we did not implement the simulation ourselves,\n",
        "and only saw the outcome,\n",
        "how would we know if the coin were slightly unfair\n",
        "or if the possible deviation from $1/2$ was\n",
        "just an artifact of the small sample size?\n",
        "Let's see what happens when we simulate 10,000 tosses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3b639145",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.313908Z",
          "iopub.status.busy": "2023-08-18T19:35:44.313549Z",
          "iopub.status.idle": "2023-08-18T19:35:44.325094Z",
          "shell.execute_reply": "2023-08-18T19:35:44.324133Z"
        },
        "origin_pos": 20,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b639145",
        "outputId": "1dc9c60e-b557-4b4d-aa4f-d90bde9fe2dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5071, 0.4929])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "counts = Multinomial(10000, fair_probs).sample()\n",
        "counts / 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8725b688",
      "metadata": {
        "origin_pos": 23,
        "id": "8725b688"
      },
      "source": [
        "In general, for averages of repeated events (like coin tosses),\n",
        "as the number of repetitions grows,\n",
        "our estimates are guaranteed to converge\n",
        "to the true underlying probabilities.\n",
        "The mathematical formulation of this phenomenon\n",
        "is called the *law of large numbers*\n",
        "and the *central limit theorem*\n",
        "tells us that in many situations,\n",
        "as the sample size $n$ grows,\n",
        "these errors should go down\n",
        "at a rate of $(1/\\sqrt{n})$.\n",
        "Let's get some more intuition by studying\n",
        "how our estimate evolves as we grow\n",
        "the number of tosses from 1 to 10,000.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fda7f94d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.329246Z",
          "iopub.status.busy": "2023-08-18T19:35:44.328647Z",
          "iopub.status.idle": "2023-08-18T19:35:44.675913Z",
          "shell.execute_reply": "2023-08-18T19:35:44.674711Z"
        },
        "origin_pos": 24,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "fda7f94d",
        "outputId": "2ad01d3b-f8b3-4ec0-db7a-6b94ba1314f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 450x350 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"306.596693pt\" height=\"238.79625pt\" viewBox=\"0 0 306.596693 238.79625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-06-09T02:59:12.031451</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 238.79625 \nL 306.596693 238.79625 \nL 306.596693 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 201.24 \nL 294.88125 201.24 \nL 294.88125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m864fc9c752\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m864fc9c752\" x=\"55.194886\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(52.013636 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m864fc9c752\" x=\"100.853998\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2000 -->\n      <g transform=\"translate(88.128998 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m864fc9c752\" x=\"146.513109\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4000 -->\n      <g transform=\"translate(133.788109 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m864fc9c752\" x=\"192.17222\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6000 -->\n      <g transform=\"translate(179.44722 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m864fc9c752\" x=\"237.831332\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8000 -->\n      <g transform=\"translate(225.106332 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m864fc9c752\" x=\"283.490443\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10000 -->\n      <g transform=\"translate(267.584193 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Samples -->\n     <g transform=\"translate(147.978125 229.516562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"124.755859\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"222.167969\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"285.644531\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"313.427734\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"374.951172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m5712255946\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m5712255946\" x=\"43.78125\" y=\"192.42\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 196.219219) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m5712255946\" x=\"43.78125\" y=\"157.14\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 160.939219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m5712255946\" x=\"43.78125\" y=\"121.86\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 125.659219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m5712255946\" x=\"43.78125\" y=\"86.58\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 90.379219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m5712255946\" x=\"43.78125\" y=\"51.3\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 55.099219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m5712255946\" x=\"43.78125\" y=\"16.02\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 19.819219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- Estimated probability -->\n     <g transform=\"translate(14.798438 157.743437) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"115.283203\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"154.492188\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"182.275391\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"279.6875\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"340.966797\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"380.175781\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"441.699219\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"505.175781\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"536.962891\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"600.439453\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"639.302734\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"700.484375\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"763.960938\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"825.240234\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"888.716797\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"916.5\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"944.283203\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"972.066406\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"1011.275391\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 55.194886 192.42 \nL 55.240545 192.42 \nL 55.354693 104.22 \nL 55.377523 114.019999 \nL 55.446011 89.520004 \nL 55.491671 104.22 \nL 55.53733 115.245 \nL 55.628648 113.040002 \nL 55.788455 94.419995 \nL 55.811284 97.920003 \nL 55.925432 101.547275 \nL 56.085239 86.579996 \nL 56.130898 87.420001 \nL 56.245046 91.083831 \nL 56.290705 88.019997 \nL 56.382023 89.242637 \nL 56.427682 92.994546 \nL 56.473341 90.293685 \nL 56.56466 85.42328 \nL 56.610319 86.019996 \nL 56.633148 87.6825 \nL 56.678807 85.510906 \nL 56.747296 82.48957 \nL 56.770126 84.060001 \nL 56.792955 85.586199 \nL 56.838614 83.680279 \nL 56.861444 85.149731 \nL 56.929933 82.456366 \nL 56.952762 83.86615 \nL 56.975592 85.240258 \nL 57.04408 82.707804 \nL 57.203887 87.372813 \nL 57.226717 86.579996 \nL 57.249546 87.743073 \nL 57.409353 93.420005 \nL 57.432183 92.638186 \nL 57.477842 92.867523 \nL 57.614819 90.206921 \nL 57.683308 92.994546 \nL 57.728967 91.619995 \nL 57.751797 90.950973 \nL 57.820285 92.054487 \nL 57.888774 91.619995 \nL 57.934433 93.286117 \nL 57.980092 93.463902 \nL 58.139899 90.65077 \nL 58.276876 92.54647 \nL 58.482342 89.013101 \nL 58.642149 91.454207 \nL 58.664979 90.961172 \nL 58.710638 92.270323 \nL 58.779127 93.055444 \nL 58.801956 92.570947 \nL 58.938933 90.856366 \nL 58.984593 91.016403 \nL 59.09874 92.93861 \nL 59.12157 92.493993 \nL 59.190059 91.190456 \nL 59.258547 91.901567 \nL 59.441184 95.258508 \nL 59.464013 94.837022 \nL 59.555331 94.113746 \nL 59.509672 94.935793 \nL 59.578161 94.62311 \nL 59.600991 95.127216 \nL 59.64665 94.320005 \nL 59.669479 93.922534 \nL 59.737968 94.517999 \nL 59.760798 94.127468 \nL 59.920604 96.58731 \nL 59.943434 96.201815 \nL 60.034752 96.35239 \nL 60.103241 95.236669 \nL 60.17173 95.762466 \nL 60.194559 95.399998 \nL 60.285877 95.557502 \nL 60.354366 94.506338 \nL 60.377196 94.935793 \nL 60.422855 94.24957 \nL 60.445684 94.674546 \nL 60.468514 94.335513 \nL 60.514173 95.173847 \nL 60.559832 95.997965 \nL 60.605491 95.325883 \nL 60.628321 94.994063 \nL 60.67398 95.802568 \nL 60.719639 95.145921 \nL 60.833787 97.107093 \nL 60.902275 96.840714 \nL 60.993594 96.956466 \nL 61.062082 96.015345 \nL 61.336037 99.646665 \nL 61.358866 99.338082 \nL 61.473014 98.467827 \nL 61.404526 99.373841 \nL 61.518673 98.509212 \nL 61.587162 98.884055 \nL 61.609992 98.590213 \nL 61.792628 96.920686 \nL 61.655651 98.629863 \nL 61.815458 97.248867 \nL 61.975264 98.300535 \nL 61.998094 98.025356 \nL 62.043753 98.652563 \nL 62.066583 98.963049 \nL 62.112242 98.41737 \nL 62.135071 98.147216 \nL 62.18073 98.761365 \nL 62.22639 98.225821 \nL 62.409026 100.046501 \nL 62.431856 99.782268 \nL 62.546003 99.03176 \nL 62.591662 99.063692 \nL 62.72864 100.223025 \nL 62.751469 99.9694 \nL 62.774299 99.7173 \nL 62.819958 100.27075 \nL 62.888447 100.566747 \nL 62.911276 100.317349 \nL 62.934106 100.069412 \nL 63.002594 100.362854 \nL 63.116742 101.685517 \nL 63.162401 101.196004 \nL 63.25372 100.233561 \nL 63.299379 100.751462 \nL 63.390697 101.769999 \nL 63.436356 101.296247 \nL 63.527674 100.364263 \nL 63.618992 100.405942 \nL 63.778799 101.178624 \nL 63.824458 100.729234 \nL 63.870118 101.210556 \nL 64.052754 102.179382 \nL 64.189731 101.317213 \nL 64.23539 101.331838 \nL 64.372368 102.687988 \nL 64.418027 102.259995 \nL 64.440856 102.047586 \nL 64.486516 102.490583 \nL 64.532175 102.068783 \nL 64.691982 103.162444 \nL 64.714811 102.953968 \nL 64.737641 102.74649 \nL 64.7833 103.172496 \nL 64.851788 103.803961 \nL 64.897448 103.391834 \nL 65.057254 102.79413 \nL 65.102914 103.206205 \nL 65.171402 103.011785 \nL 65.239891 103.219999 \nL 65.399698 101.857498 \nL 65.582334 102.672627 \nL 65.605164 102.483023 \nL 65.673652 102.686085 \nL 65.742141 103.267513 \nL 65.7878 102.892259 \nL 65.81063 102.705842 \nL 65.856289 103.089233 \nL 65.970437 103.287648 \nL 66.153073 102.569692 \nL 66.381369 103.681102 \nL 66.541176 103.157345 \nL 66.700982 103.696043 \nL 66.769471 103.872756 \nL 66.883619 103.016496 \nL 66.906448 103.190433 \nL 66.952108 102.852557 \nL 67.020596 103.030406 \nL 67.089085 102.530348 \nL 67.294551 103.389489 \nL 67.36304 103.559326 \nL 67.408699 103.23269 \nL 67.500017 103.566665 \nL 67.522846 103.40484 \nL 67.659824 103.091294 \nL 67.86529 103.902732 \nL 68.025097 103.436698 \nL 68.093585 103.908336 \nL 68.139244 103.59887 \nL 68.321881 102.688745 \nL 68.34471 102.844262 \nL 68.527347 103.767687 \nL 68.550176 103.617954 \nL 68.755642 102.589407 \nL 68.778472 102.740139 \nL 68.801302 102.890356 \nL 68.846961 102.600299 \nL 69.029597 101.749822 \nL 69.052427 101.898946 \nL 69.098086 102.195742 \nL 69.166574 102.061759 \nL 69.212234 101.781954 \nL 69.257893 102.075753 \nL 69.39487 102.379553 \nL 69.554677 101.98 \nL 69.760143 102.701688 \nL 69.942779 102.175176 \nL 69.965609 102.314448 \nL 70.011268 102.048921 \nL 70.125416 101.930835 \nL 70.216734 102.48009 \nL 70.262393 102.218485 \nL 70.4222 101.579281 \nL 70.44503 101.715072 \nL 70.467859 101.850443 \nL 70.513518 101.594999 \nL 70.536348 101.729961 \nL 70.627666 101.484106 \nL 70.650496 101.618225 \nL 70.696155 101.885298 \nL 70.764643 101.766413 \nL 70.901621 101.275734 \nL 70.92445 101.407825 \nL 70.992939 101.292725 \nL 71.061428 101.685517 \nL 71.107087 101.440061 \nL 71.152746 101.699995 \nL 71.175575 101.829415 \nL 71.221234 101.585295 \nL 71.244064 101.46375 \nL 71.289723 101.721412 \nL 71.312553 101.600194 \nL 71.495189 102.122941 \nL 71.563678 102.254538 \nL 71.609337 102.015002 \nL 71.654996 102.265431 \nL 71.700655 102.027178 \nL 72.088758 100.530126 \nL 72.225735 101.032045 \nL 72.248564 100.918396 \nL 72.271394 100.805042 \nL 72.317053 101.049026 \nL 72.47686 101.427392 \nL 72.49969 101.314858 \nL 72.545349 101.554299 \nL 72.750815 102.158185 \nL 72.773644 102.046461 \nL 72.819303 102.280287 \nL 73.070428 103.094995 \nL 73.116088 102.873439 \nL 73.161747 103.100715 \nL 73.184576 103.213912 \nL 73.230235 102.993449 \nL 73.412872 102.343404 \nL 73.435701 102.456002 \nL 73.709656 103.568274 \nL 73.732486 103.460587 \nL 73.915122 103.038271 \nL 74.189077 103.902354 \nL 74.371713 103.485873 \nL 74.53152 103.803961 \nL 74.736986 103.293746 \nL 74.828304 103.502928 \nL 74.851134 103.401433 \nL 74.988111 103.20387 \nL 75.010941 103.306532 \nL 75.0566 103.106109 \nL 75.079429 103.208528 \nL 75.193577 102.711446 \nL 75.262066 102.81682 \nL 75.490361 103.427193 \nL 75.627339 103.235623 \nL 75.718657 103.632001 \nL 75.787146 103.536279 \nL 75.946952 103.250764 \nL 76.129589 103.643524 \nL 76.152418 103.548181 \nL 76.198078 103.74117 \nL 76.220907 103.646027 \nL 76.243737 103.742211 \nL 76.289396 103.552544 \nL 76.403544 103.461291 \nL 76.60901 103.938207 \nL 76.791646 103.568042 \nL 76.974282 104.127643 \nL 76.997112 104.035485 \nL 77.134089 103.853263 \nL 77.430874 104.672308 \nL 77.681999 104.0411 \nL 77.704828 104.130639 \nL 77.750487 103.952454 \nL 77.841806 103.59825 \nL 77.887465 103.776782 \nL 78.024442 103.955661 \nL 78.092931 103.868603 \nL 78.11576 103.956712 \nL 78.275567 104.22 \nL 78.366885 104.046378 \nL 78.389715 104.133278 \nL 78.458204 104.22 \nL 78.481033 104.133615 \nL 78.61801 103.790598 \nL 78.64084 103.876815 \nL 78.800647 104.134782 \nL 78.960454 103.54284 \nL 79.006113 103.713108 \nL 79.16592 104.136075 \nL 79.188749 104.052319 \nL 79.211579 103.96872 \nL 79.257238 104.136401 \nL 79.485534 104.634083 \nL 79.66817 104.1378 \nL 79.691 104.22 \nL 79.919295 104.708193 \nL 80.010613 104.38213 \nL 80.056273 104.543671 \nL 80.17042 104.783838 \nL 80.19325 104.702846 \nL 80.307398 104.460324 \nL 80.330227 104.540143 \nL 80.490034 104.77672 \nL 80.627011 104.615515 \nL 80.763989 104.92812 \nL 80.786818 104.848879 \nL 80.832477 104.690818 \nL 80.878137 104.846645 \nL 80.992284 105.077827 \nL 81.015114 104.999154 \nL 81.129262 104.918152 \nL 81.19775 104.838948 \nL 81.266239 105.068821 \nL 81.403216 104.91086 \nL 81.426046 104.986957 \nL 81.471705 104.832498 \nL 81.517364 104.678579 \nL 81.563023 104.830379 \nL 81.72283 105.054222 \nL 81.882637 104.672308 \nL 81.905467 104.747243 \nL 81.928296 104.822046 \nL 81.973955 104.670767 \nL 82.22508 103.996709 \nL 82.24791 104.071265 \nL 82.430546 104.367741 \nL 82.613183 104.073242 \nL 82.636012 104.146684 \nL 82.681671 104.00041 \nL 82.704501 104.073736 \nL 82.727331 104.000778 \nL 82.77299 104.147052 \nL 82.795819 104.22 \nL 82.841478 104.074451 \nL 82.864308 104.001861 \nL 82.909967 104.14741 \nL 82.978456 104.075177 \nL 83.046944 104.292238 \nL 83.229581 104.0047 \nL 83.25241 104.076586 \nL 83.298069 103.933634 \nL 83.366558 103.862915 \nL 83.389388 103.934559 \nL 83.526365 104.22 \nL 83.549195 104.149039 \nL 83.640513 104.007812 \nL 83.663342 104.078657 \nL 83.754661 104.22 \nL 83.77749 104.149607 \nL 83.845979 104.079551 \nL 83.868808 104.149828 \nL 83.937297 104.080003 \nL 84.051445 104.429171 \nL 84.165593 104.22 \nL 84.188422 104.289394 \nL 84.27974 104.565882 \nL 84.348229 104.496057 \nL 84.393888 104.35781 \nL 84.439547 104.495195 \nL 84.599354 104.698977 \nL 84.82765 104.287896 \nL 84.873309 104.423383 \nL 84.941797 104.355276 \nL 84.987457 104.22 \nL 85.055945 104.287381 \nL 85.124434 104.488902 \nL 85.170093 104.354246 \nL 85.238582 104.420912 \nL 85.284241 104.286871 \nL 85.444048 104.486063 \nL 85.786491 103.759602 \nL 85.900639 104.08895 \nL 85.969127 104.023856 \nL 86.174593 103.700417 \nL 86.243082 103.766362 \nL 86.265912 103.701941 \nL 86.311571 103.573373 \nL 86.380059 103.639308 \nL 86.539866 103.834852 \nL 86.562696 103.770978 \nL 86.608355 103.899736 \nL 86.631185 103.835967 \nL 86.699673 103.772934 \nL 86.745332 103.901124 \nL 86.813821 103.838185 \nL 86.836651 103.902049 \nL 86.85948 103.965818 \nL 86.905139 103.839279 \nL 86.973628 103.650148 \nL 87.019287 103.777423 \nL 87.201923 104.031406 \nL 87.270412 104.094533 \nL 87.316071 103.969435 \nL 87.475878 104.157671 \nL 87.612855 104.033792 \nL 87.841151 104.404904 \nL 87.932469 104.158534 \nL 87.978128 104.281377 \nL 88.000958 104.34267 \nL 88.046617 104.22 \nL 88.183594 104.098003 \nL 88.41189 104.462306 \nL 88.526038 104.280368 \nL 88.548867 104.340656 \nL 88.685845 104.460324 \nL 88.959799 103.981621 \nL 89.096777 104.22 \nL 89.119606 104.160689 \nL 89.165265 104.042299 \nL 89.210924 104.160847 \nL 89.279413 104.33807 \nL 89.325072 104.22 \nL 89.393561 104.278838 \nL 89.530538 103.926978 \nL 89.621856 104.044654 \nL 89.644686 103.986363 \nL 89.827322 103.755175 \nL 89.850152 103.81355 \nL 89.895811 103.698104 \nL 90.124107 103.355854 \nL 90.283913 103.531831 \nL 90.557868 103.081937 \nL 90.580698 103.139534 \nL 90.626357 103.027336 \nL 90.717675 102.917115 \nL 90.740505 102.974554 \nL 90.877482 103.092125 \nL 91.082948 102.818218 \nL 91.151437 102.98878 \nL 91.197096 102.878559 \nL 91.288414 102.770441 \nL 91.311243 102.827071 \nL 91.448221 103.054358 \nL 91.47105 102.99962 \nL 91.539539 102.946555 \nL 91.562369 103.00268 \nL 91.585198 103.058742 \nL 91.630857 102.949741 \nL 91.699346 102.786749 \nL 91.745005 102.898652 \nL 91.813494 103.065986 \nL 91.859153 102.957648 \nL 91.927641 103.014782 \nL 91.99613 102.852978 \nL 92.133107 103.075964 \nL 92.155937 103.022226 \nL 92.315744 102.864744 \nL 92.384233 102.921352 \nL 92.407062 102.868066 \nL 92.475551 102.924528 \nL 92.589699 102.659411 \nL 92.612528 102.714148 \nL 92.658187 102.608553 \nL 92.772335 102.559893 \nL 92.840824 102.616365 \nL 92.863653 102.56391 \nL 93.000631 102.463456 \nL 93.114778 102.734083 \nL 93.183267 102.683783 \nL 93.251756 102.527909 \nL 93.297415 102.635564 \nL 93.388733 102.850108 \nL 93.434392 102.74649 \nL 93.457222 102.694781 \nL 93.502881 102.801658 \nL 93.639858 103.016086 \nL 93.662688 102.964482 \nL 93.731176 102.810048 \nL 93.776835 102.916043 \nL 93.799665 102.96894 \nL 93.845324 102.866279 \nL 94.119279 102.462205 \nL 94.210597 102.672627 \nL 94.279086 102.623851 \nL 94.301915 102.57333 \nL 94.347574 102.678042 \nL 94.370404 102.730308 \nL 94.416063 102.629424 \nL 94.438893 102.681627 \nL 94.461722 102.631274 \nL 94.507381 102.735492 \nL 94.530211 102.685202 \nL 94.644359 102.842674 \nL 94.667188 102.79249 \nL 94.804165 102.594191 \nL 94.826995 102.64591 \nL 94.941143 102.701058 \nL 94.986802 102.601656 \nL 95.032461 102.704538 \nL 95.07812 102.807188 \nL 95.146609 102.759233 \nL 95.169438 102.709721 \nL 95.215097 102.812015 \nL 95.329245 102.966448 \nL 95.352075 102.917041 \nL 95.534711 102.72339 \nL 95.626029 102.826324 \nL 95.648859 102.77736 \nL 95.785836 102.583908 \nL 95.808666 102.634387 \nL 95.877155 102.587588 \nL 95.922814 102.68823 \nL 96.151109 102.401948 \nL 96.265257 102.456002 \nL 96.402234 102.168836 \nL 96.447893 102.268669 \nL 96.516382 102.418014 \nL 96.584871 102.372371 \nL 96.721848 102.281539 \nL 96.790337 102.236348 \nL 96.904485 102.483023 \nL 96.972973 102.534039 \nL 97.064291 102.345455 \nL 97.13278 102.300527 \nL 97.246928 102.545015 \nL 97.292587 102.451218 \nL 97.338246 102.548643 \nL 97.406735 102.503673 \nL 97.452394 102.600773 \nL 97.475223 102.554058 \nL 97.520883 102.650947 \nL 97.589371 102.795886 \nL 97.63503 102.702582 \nL 97.703519 102.562995 \nL 97.749178 102.659358 \nL 97.840496 102.757077 \nL 97.863326 102.710699 \nL 98.023133 102.575349 \nL 98.18294 102.721907 \nL 98.205769 102.675918 \nL 98.251428 102.77103 \nL 98.274258 102.725083 \nL 98.411235 102.916095 \nL 98.434065 102.870242 \nL 98.456894 102.824432 \nL 98.502553 102.918839 \nL 98.571042 103.060088 \nL 98.639531 103.015592 \nL 98.776508 102.927019 \nL 98.890656 103.160678 \nL 98.936315 103.069761 \nL 99.347247 102.442323 \nL 99.415736 102.581605 \nL 99.484224 102.538707 \nL 99.644031 102.408908 \nL 99.758179 102.549032 \nL 99.781009 102.504746 \nL 99.849497 102.46231 \nL 99.872327 102.508258 \nL 99.940816 102.465896 \nL 100.009304 102.603296 \nL 100.054963 102.515218 \nL 100.123452 102.562606 \nL 100.146282 102.608227 \nL 100.191941 102.520402 \nL 100.21477 102.56597 \nL 100.374577 102.43818 \nL 100.420236 102.528981 \nL 100.465895 102.441776 \nL 100.694191 102.185291 \nL 100.71702 102.230523 \nL 100.76268 102.144191 \nL 100.785509 102.189371 \nL 100.853998 102.148333 \nL 100.876827 102.193429 \nL 101.013805 102.463025 \nL 101.082293 102.421788 \nL 101.127952 102.33595 \nL 101.173612 102.425363 \nL 101.424737 102.739845 \nL 101.447566 102.697062 \nL 101.493225 102.785498 \nL 101.607373 102.919113 \nL 101.630203 102.876414 \nL 101.812839 102.622642 \nL 101.835669 102.666571 \nL 101.926987 102.755742 \nL 101.949816 102.713412 \nL 102.063964 102.674141 \nL 102.086794 102.717807 \nL 102.132453 102.633514 \nL 102.155282 102.677148 \nL 102.26943 102.552617 \nL 102.29226 102.596167 \nL 102.360748 102.555845 \nL 102.406408 102.642714 \nL 102.497726 102.560661 \nL 102.520555 102.60399 \nL 102.680362 102.736575 \nL 102.703192 102.694928 \nL 102.748851 102.781039 \nL 102.77168 102.739424 \nL 102.840169 102.783794 \nL 102.862999 102.742263 \nL 102.885828 102.700763 \nL 102.931487 102.786538 \nL 102.954317 102.829363 \nL 102.999976 102.74649 \nL 103.068465 102.706556 \nL 103.091294 102.749297 \nL 103.31959 103.007201 \nL 103.342419 102.965975 \nL 103.388078 103.050678 \nL 103.570715 103.221513 \nL 103.616374 103.139323 \nL 103.662033 103.223385 \nL 103.867499 103.434343 \nL 104.050136 103.272497 \nL 104.095795 103.355696 \nL 104.141454 103.274263 \nL 104.164283 103.233605 \nL 104.209942 103.316646 \nL 104.415408 103.524871 \nL 104.483897 103.485001 \nL 104.506727 103.526154 \nL 104.643704 103.609479 \nL 104.803511 103.489732 \nL 104.963318 103.613401 \nL 105.031806 103.573846 \nL 105.054636 103.614505 \nL 105.282932 103.858362 \nL 105.397079 103.73891 \nL 105.419909 103.7792 \nL 105.534057 103.980107 \nL 105.602545 103.94051 \nL 105.625375 103.900724 \nL 105.671034 103.980759 \nL 105.739523 103.941267 \nL 105.808011 104.06094 \nL 105.830841 104.021259 \nL 105.8765 104.100863 \nL 105.89933 104.140607 \nL 105.944989 104.061371 \nL 105.967818 104.101084 \nL 106.196114 103.785908 \nL 106.218943 103.825547 \nL 106.287432 103.86547 \nL 106.310262 103.826252 \nL 106.492898 103.670714 \nL 106.561387 103.710626 \nL 106.584216 103.671692 \nL 106.744023 103.556256 \nL 106.92666 103.714222 \nL 107.086466 103.599417 \nL 107.246273 103.871999 \nL 107.291932 103.795035 \nL 107.40608 103.757415 \nL 107.657205 104.028178 \nL 107.794183 103.952149 \nL 108.045308 104.22 \nL 108.113796 104.105899 \nL 108.159456 104.182001 \nL 108.319262 104.295771 \nL 108.524728 104.106782 \nL 108.593217 104.22 \nL 108.638876 104.144676 \nL 108.753024 104.107256 \nL 108.867172 104.145002 \nL 109.163956 103.809765 \nL 109.300933 103.885205 \nL 109.392252 103.811489 \nL 109.415081 103.848784 \nL 109.574888 103.960918 \nL 109.689036 103.850655 \nL 109.711865 103.887728 \nL 109.848843 103.962211 \nL 109.96299 103.852495 \nL 109.98582 103.88939 \nL 110.031479 103.963074 \nL 110.077138 103.889936 \nL 110.122797 103.816925 \nL 110.168456 103.890483 \nL 110.328263 104.000956 \nL 110.48807 103.819585 \nL 110.5109 103.856144 \nL 110.762025 104.111335 \nL 110.921832 103.931058 \nL 110.944661 103.967279 \nL 110.967491 104.003469 \nL 111.01315 103.931531 \nL 111.195786 103.788705 \nL 111.378423 103.933402 \nL 111.401252 103.897706 \nL 111.446912 103.969529 \nL 111.698037 104.22 \nL 111.766525 104.18442 \nL 111.789355 104.22 \nL 111.835014 104.291071 \nL 111.880673 104.22 \nL 112.01765 104.07831 \nL 112.04048 104.113774 \nL 112.177457 104.184683 \nL 112.337264 104.079109 \nL 112.519901 104.22 \nL 112.725367 104.045074 \nL 112.839514 104.150164 \nL 112.862344 104.115288 \nL 112.953662 104.115457 \nL 112.999321 104.185177 \nL 113.04498 104.115625 \nL 113.204787 104.011818 \nL 113.387424 104.150827 \nL 113.547231 104.047535 \nL 113.661378 104.082295 \nL 113.866844 103.911249 \nL 114.003822 104.04887 \nL 114.026651 104.01472 \nL 114.209288 103.878928 \nL 114.483242 104.22 \nL 114.506072 104.18606 \nL 114.59739 104.118348 \nL 114.62022 104.152257 \nL 114.825686 104.321263 \nL 114.917004 104.253703 \nL 114.939834 104.287381 \nL 115.031152 104.287275 \nL 115.053981 104.253625 \nL 115.09964 104.3208 \nL 115.236618 104.387618 \nL 115.350766 104.286918 \nL 115.373595 104.320343 \nL 115.533402 104.486868 \nL 115.556232 104.453422 \nL 115.693209 104.386351 \nL 115.716038 104.41955 \nL 115.761698 104.352932 \nL 115.989993 104.153781 \nL 116.12697 104.22 \nL 116.263948 104.154076 \nL 116.423755 104.252873 \nL 116.492243 104.22 \nL 116.515073 104.252826 \nL 116.697709 104.383639 \nL 116.994494 104.089718 \nL 117.085812 104.089907 \nL 117.108641 104.05745 \nL 117.1543 104.122543 \nL 117.245619 104.187564 \nL 117.268448 104.155148 \nL 117.336937 104.122827 \nL 117.359766 104.155243 \nL 117.451085 104.155337 \nL 117.633721 103.962106 \nL 117.656551 103.994427 \nL 117.747869 104.059111 \nL 117.770698 104.027 \nL 117.953335 103.899273 \nL 118.021824 103.931657 \nL 118.044653 103.899736 \nL 118.158801 103.868351 \nL 118.18163 103.90043 \nL 118.22729 103.836797 \nL 118.341437 103.805612 \nL 118.455585 103.838185 \nL 118.478415 103.806516 \nL 118.615392 103.68045 \nL 118.638222 103.712372 \nL 118.70671 103.744619 \nL 118.752369 103.681617 \nL 118.843688 103.619142 \nL 118.866517 103.650968 \nL 119.026324 103.68393 \nL 119.140472 103.653408 \nL 119.391597 103.812394 \nL 119.482915 103.750349 \nL 119.528574 103.813256 \nL 119.551404 103.844683 \nL 119.619893 103.751348 \nL 119.802529 103.628058 \nL 120.007995 103.723096 \nL 120.099313 103.723801 \nL 120.122143 103.754975 \nL 120.25912 103.879695 \nL 120.304779 103.818103 \nL 120.418927 103.787948 \nL 120.441757 103.818955 \nL 120.76137 104.066502 \nL 121.035325 103.883712 \nL 121.263621 104.006739 \nL 121.446257 103.885794 \nL 121.469087 103.916285 \nL 121.651723 104.038272 \nL 121.674553 104.008054 \nL 121.834359 103.978361 \nL 121.925678 104.039018 \nL 121.971337 103.978855 \nL 122.153973 103.859266 \nL 122.176803 103.889442 \nL 122.268121 103.94991 \nL 122.31378 103.890115 \nL 122.473587 103.86098 \nL 122.679053 103.95155 \nL 122.724712 103.892123 \nL 122.793201 103.981778 \nL 122.81603 104.011628 \nL 122.884519 103.922625 \nL 123.021496 103.923235 \nL 123.089985 104.01247 \nL 123.158474 103.923824 \nL 123.272621 103.83562 \nL 123.318281 103.894973 \nL 123.432428 103.984018 \nL 123.478087 103.925212 \nL 123.637894 103.83767 \nL 123.660724 103.867205 \nL 123.86619 103.956187 \nL 124.025997 103.869076 \nL 124.048826 103.898421 \nL 124.162974 103.98651 \nL 124.208633 103.928334 \nL 124.322781 103.841455 \nL 124.36844 103.899904 \nL 124.39127 103.929102 \nL 124.459758 103.842212 \nL 124.505417 103.784373 \nL 124.573906 103.871841 \nL 124.802202 104.046494 \nL 124.825031 104.017643 \nL 124.984838 103.931573 \nL 125.007668 103.960508 \nL 125.235963 104.076302 \nL 125.464259 103.96219 \nL 125.601236 104.019872 \nL 125.624066 103.991357 \nL 125.852361 103.878139 \nL 126.034998 104.049511 \nL 126.080657 103.992829 \nL 126.263293 103.936767 \nL 126.400271 103.937303 \nL 126.491589 103.881199 \nL 126.537248 103.93785 \nL 126.811203 104.163791 \nL 126.834032 104.135707 \nL 127.107987 103.968078 \nL 127.290623 104.080402 \nL 127.313453 104.052529 \nL 127.47326 103.969351 \nL 127.496089 103.997276 \nL 127.564578 104.025297 \nL 127.610237 103.969824 \nL 127.815703 103.887381 \nL 128.021169 103.971233 \nL 128.180976 103.889043 \nL 128.203805 103.916716 \nL 128.47776 104.1376 \nL 128.50059 104.110158 \nL 128.637567 103.945914 \nL 128.706056 104.028325 \nL 128.820203 104.001282 \nL 128.843033 103.974008 \nL 128.911522 104.056156 \nL 129.048499 104.165484 \nL 129.094158 104.111041 \nL 129.208306 104.084019 \nL 129.231135 104.111241 \nL 129.482261 104.301291 \nL 129.50509 104.274175 \nL 129.710556 104.192989 \nL 129.870363 104.22 \nL 130.052999 104.112439 \nL 130.075829 104.139356 \nL 130.281295 104.22 \nL 130.463931 104.166514 \nL 130.852034 104.459457 \nL 131.011841 104.432404 \nL 131.171648 104.511439 \nL 131.194477 104.484865 \nL 131.331455 104.43151 \nL 131.354284 104.45788 \nL 131.491261 104.51022 \nL 131.514091 104.483755 \nL 131.605409 104.48344 \nL 131.628239 104.509699 \nL 131.856534 104.613869 \nL 132.062 104.481879 \nL 132.08483 104.50798 \nL 132.176148 104.559937 \nL 132.221807 104.507465 \nL 132.450103 104.350282 \nL 132.472932 104.376289 \nL 132.60991 104.376016 \nL 132.746887 104.375737 \nL 132.792546 104.42753 \nL 132.861035 104.349594 \nL 133.11216 104.168333 \nL 133.134989 104.194177 \nL 133.249137 104.168417 \nL 133.363285 104.142741 \nL 133.386115 104.168512 \nL 133.431774 104.22 \nL 133.500262 104.142878 \nL 133.682899 104.091768 \nL 133.911194 104.194429 \nL 134.207979 104.016192 \nL 134.596081 104.296055 \nL 134.755888 104.169395 \nL 134.801547 104.22 \nL 134.938524 104.270484 \nL 134.961354 104.245234 \nL 135.189649 104.144508 \nL 135.463604 104.295235 \nL 135.6919 104.194997 \nL 135.828877 104.195039 \nL 136.057173 104.095532 \nL 136.080002 104.120451 \nL 136.148491 104.045936 \nL 136.216979 104.021238 \nL 136.262639 104.071013 \nL 136.536593 104.269496 \nL 136.559423 104.24474 \nL 136.673571 104.22 \nL 136.6964 104.244698 \nL 136.833377 104.293973 \nL 136.856207 104.269301 \nL 136.993184 104.22 \nL 137.016014 104.244603 \nL 137.152991 104.244561 \nL 137.289969 104.244519 \nL 137.404116 104.22 \nL 137.678071 104.073568 \nL 137.74656 104.146842 \nL 137.815048 104.07381 \nL 138.043344 103.977026 \nL 138.271639 104.074619 \nL 138.340128 104.050521 \nL 138.385787 104.099012 \nL 138.545594 104.171697 \nL 138.568424 104.147567 \nL 138.819549 104.027421 \nL 138.979356 104.051814 \nL 139.161992 104.004237 \nL 139.25331 104.052361 \nL 139.298969 104.004584 \nL 139.504436 103.933486 \nL 139.618583 104.005404 \nL 139.664242 103.957858 \nL 139.846879 103.91086 \nL 139.869708 103.934717 \nL 139.938197 103.863682 \nL 140.075174 103.864261 \nL 140.120834 103.911859 \nL 140.189322 103.841056 \nL 140.349129 103.818124 \nL 140.554595 103.937009 \nL 140.577425 103.913509 \nL 140.80572 103.820269 \nL 140.919868 103.891251 \nL 140.965527 103.844483 \nL 141.170993 103.775142 \nL 141.376459 103.846271 \nL 141.604755 103.707482 \nL 141.627584 103.730908 \nL 141.673243 103.777718 \nL 141.741732 103.708292 \nL 142.015687 103.524419 \nL 142.038516 103.547781 \nL 142.175494 103.595127 \nL 142.198323 103.572153 \nL 142.312471 103.549895 \nL 142.3353 103.573173 \nL 142.472278 103.574183 \nL 142.88321 103.301727 \nL 143.020187 103.303157 \nL 143.40829 103.056166 \nL 143.545267 103.057975 \nL 143.842051 102.9029 \nL 143.933369 102.858887 \nL 144.161665 102.771871 \nL 144.367131 102.842937 \nL 144.572597 102.778527 \nL 144.686745 102.757877 \nL 144.800892 102.782196 \nL 145.006358 102.852736 \nL 145.211824 102.788767 \nL 145.371631 102.813623 \nL 145.531438 102.793825 \nL 145.622756 102.750737 \nL 145.851052 102.665624 \nL 146.079348 102.758118 \nL 146.307643 102.673405 \nL 146.44462 102.675729 \nL 146.581598 102.678042 \nL 146.809893 102.769779 \nL 147.106678 102.621139 \nL 147.380632 102.75692 \nL 147.540439 102.737647 \nL 147.700246 102.761967 \nL 147.951371 102.657402 \nL 148.065519 102.637646 \nL 148.248155 102.597482 \nL 148.407962 102.621864 \nL 148.613428 102.560724 \nL 148.818894 102.628877 \nL 149.001531 102.589049 \nL 149.115678 102.569598 \nL 149.321144 102.509036 \nL 149.663588 102.70703 \nL 149.869054 102.64652 \nL 150.120179 102.75672 \nL 150.279986 102.738005 \nL 150.508281 102.82603 \nL 150.690918 102.786538 \nL 150.782236 102.745785 \nL 151.033361 102.644627 \nL 151.170338 102.646878 \nL 151.398634 102.566906 \nL 151.62693 102.654322 \nL 151.718248 102.697514 \nL 151.923714 102.763176 \nL 152.12918 102.70397 \nL 152.288987 102.727196 \nL 152.585771 102.587051 \nL 152.814066 102.673352 \nL 152.905385 102.716009 \nL 153.13368 102.801732 \nL 153.384805 102.702845 \nL 153.544612 102.725777 \nL 153.68159 102.727858 \nL 153.818567 102.72993 \nL 154.024033 102.671912 \nL 154.18384 102.694749 \nL 154.366476 102.656961 \nL 154.526283 102.679745 \nL 154.640431 102.701751 \nL 154.823067 102.744944 \nL 154.937215 102.766824 \nL 155.233999 102.911995 \nL 155.416636 102.874206 \nL 155.553613 102.876036 \nL 155.667761 102.897601 \nL 155.781909 102.879085 \nL 155.964545 102.84156 \nL 156.2385 102.964839 \nL 156.375477 102.966543 \nL 156.512454 102.968235 \nL 156.74075 102.891744 \nL 157.014705 103.013951 \nL 157.197341 102.976636 \nL 157.288659 102.938312 \nL 157.448466 102.920627 \nL 157.585444 102.922362 \nL 157.76808 102.885425 \nL 158.042035 103.006423 \nL 158.27033 102.930983 \nL 158.430137 102.952474 \nL 158.658433 102.877445 \nL 159.092194 103.134939 \nL 159.457467 102.945661 \nL 159.708592 103.045032 \nL 160.073865 102.857173 \nL 160.256502 102.897863 \nL 160.461968 102.843074 \nL 160.85007 103.057722 \nL 161.146854 102.927966 \nL 161.329491 102.96813 \nL 161.557786 102.895109 \nL 161.694764 102.896812 \nL 161.808911 102.917115 \nL 161.945889 102.918776 \nL 162.128525 102.883354 \nL 162.311162 102.923213 \nL 162.516628 102.869422 \nL 162.676435 102.890167 \nL 162.859071 102.855018 \nL 162.973219 102.837785 \nL 163.224344 102.747825 \nL 163.361321 102.749686 \nL 163.521128 102.733273 \nL 163.726594 102.791732 \nL 163.817912 102.830004 \nL 164.023378 102.888117 \nL 164.228844 102.835241 \nL 164.320163 102.799503 \nL 164.43431 102.819417 \nL 164.548458 102.802468 \nL 164.731095 102.768075 \nL 164.868072 102.769884 \nL 165.050708 102.735649 \nL 165.279004 102.811867 \nL 165.46164 102.777685 \nL 165.644277 102.816525 \nL 165.849743 102.764553 \nL 165.98672 102.766351 \nL 166.169357 102.732464 \nL 166.374823 102.789535 \nL 166.557459 102.755721 \nL 166.694436 102.757519 \nL 166.877073 102.723863 \nL 167.082539 102.780587 \nL 167.219516 102.782343 \nL 167.356493 102.784099 \nL 167.5163 102.768223 \nL 167.744596 102.842716 \nL 167.904403 102.826808 \nL 168.087039 102.864722 \nL 168.201187 102.883911 \nL 168.406653 102.939679 \nL 168.520801 102.95873 \nL 168.771926 103.050141 \nL 168.931733 103.034086 \nL 169.09154 103.053422 \nL 169.251347 103.037409 \nL 169.411153 103.056692 \nL 169.616619 103.005992 \nL 169.890574 103.079108 \nL 170.004722 103.097771 \nL 170.255847 103.152708 \nL 170.347165 103.18852 \nL 170.575461 103.225456 \nL 170.712438 103.226634 \nL 170.917904 103.245801 \nL 171.100541 103.212597 \nL 171.328836 103.24925 \nL 171.465813 103.285019 \nL 171.694109 103.321409 \nL 171.808257 103.374086 \nL 172.013723 103.392801 \nL 172.219189 103.377051 \nL 172.607291 103.534155 \nL 173.063882 103.33185 \nL 173.223689 103.315994 \nL 173.429155 103.300539 \nL 173.634621 103.319128 \nL 173.840087 103.303724 \nL 173.954235 103.25375 \nL 174.319508 103.121512 \nL 174.616292 103.208528 \nL 174.890247 103.143571 \nL 175.072883 103.145211 \nL 175.278349 103.130281 \nL 175.529474 103.182747 \nL 175.712111 103.184314 \nL 176.077384 103.320684 \nL 176.374168 103.239819 \nL 176.488316 103.190948 \nL 176.7851 103.110672 \nL 176.922077 103.078845 \nL 177.081884 103.096856 \nL 177.378668 103.181969 \nL 177.698282 103.086069 \nL 177.903748 103.104374 \nL 178.31468 102.944578 \nL 178.428828 102.896759 \nL 178.634294 102.882649 \nL 179.022396 103.033161 \nL 179.296351 102.970895 \nL 179.524647 103.005572 \nL 179.84426 102.911774 \nL 180.095386 102.962768 \nL 180.232363 102.99634 \nL 180.483488 103.046998 \nL 180.688954 103.032877 \nL 180.87159 103.034601 \nL 181.054227 103.036326 \nL 181.259693 103.054221 \nL 181.510818 103.008726 \nL 181.739114 103.042729 \nL 181.876091 103.075786 \nL 182.378341 103.301905 \nL 182.606637 103.27195 \nL 182.743614 103.241406 \nL 183.017569 103.180497 \nL 183.337182 103.277355 \nL 183.565478 103.247662 \nL 183.793774 103.280698 \nL 184.044899 103.235655 \nL 184.227535 103.237053 \nL 184.410172 103.238441 \nL 184.775444 103.365496 \nL 184.889592 103.41282 \nL 185.072229 103.413956 \nL 185.323354 103.369092 \nL 185.597308 103.43264 \nL 185.871263 103.372666 \nL 186.0539 103.373844 \nL 186.236536 103.375022 \nL 186.487661 103.422641 \nL 186.715957 103.393411 \nL 187.0584 103.502433 \nL 187.218207 103.518552 \nL 187.378014 103.504168 \nL 187.674798 103.42979 \nL 187.925923 103.476789 \nL 188.154219 103.44778 \nL 188.359685 103.464088 \nL 188.542321 103.465118 \nL 188.839105 103.542114 \nL 189.044571 103.52812 \nL 189.318526 103.589576 \nL 189.523992 103.57555 \nL 189.797947 103.63669 \nL 189.980583 103.637478 \nL 190.11756 103.608228 \nL 190.414345 103.535122 \nL 190.733958 103.62586 \nL 190.962254 103.597198 \nL 191.122061 103.58312 \nL 191.259038 103.613359 \nL 191.510163 103.65878 \nL 191.784118 103.600952 \nL 192.126561 103.705411 \nL 192.354857 103.676917 \nL 192.514664 103.662881 \nL 192.788618 103.605463 \nL 193.016914 103.635702 \nL 193.290869 103.578546 \nL 193.450676 103.56473 \nL 193.656142 103.551156 \nL 193.907267 103.595905 \nL 194.27254 103.481741 \nL 194.500835 103.511854 \nL 194.729131 103.48416 \nL 194.957426 103.514167 \nL 195.25421 103.443795 \nL 195.391188 103.415827 \nL 195.528165 103.445309 \nL 195.710802 103.446319 \nL 195.893438 103.447318 \nL 196.098904 103.462731 \nL 196.258711 103.477862 \nL 196.418518 103.464445 \nL 196.692472 103.408993 \nL 197.034916 103.510309 \nL 197.217552 103.511223 \nL 197.491507 103.569178 \nL 197.742632 103.527962 \nL 197.879609 103.500404 \nL 198.107905 103.473382 \nL 198.3362 103.502696 \nL 198.632985 103.434007 \nL 198.929769 103.505661 \nL 199.203724 103.451103 \nL 199.40919 103.466149 \nL 199.637485 103.439474 \nL 199.842951 103.454499 \nL 200.094076 103.414145 \nL 200.299542 103.429159 \nL 200.43652 103.457622 \nL 200.778963 103.556214 \nL 200.893111 103.598197 \nL 201.189895 103.668401 \nL 201.486679 103.60071 \nL 201.623657 103.573794 \nL 201.760634 103.601877 \nL 201.988929 103.630266 \nL 202.171566 103.630991 \nL 202.354202 103.631727 \nL 202.605327 103.591752 \nL 202.810793 103.606272 \nL 202.99343 103.607029 \nL 203.244555 103.648865 \nL 203.404362 103.66306 \nL 203.655487 103.704686 \nL 203.929442 103.651494 \nL 204.134908 103.665793 \nL 204.271885 103.693309 \nL 204.500181 103.721088 \nL 204.682817 103.721698 \nL 204.865453 103.722308 \nL 204.979601 103.763008 \nL 205.253556 103.817504 \nL 205.459022 103.804655 \nL 205.664488 103.818608 \nL 206.006931 103.726072 \nL 206.143909 103.699839 \nL 206.326545 103.700469 \nL 206.463522 103.67432 \nL 206.874454 103.543071 \nL 207.148409 103.597282 \nL 207.285386 103.624325 \nL 207.673489 103.744671 \nL 207.878955 103.732128 \nL 208.038762 103.719458 \nL 208.175739 103.746227 \nL 208.335546 103.733579 \nL 208.472523 103.760285 \nL 208.65516 103.760832 \nL 208.906285 103.722287 \nL 209.111751 103.736029 \nL 209.340046 103.710626 \nL 209.68249 103.802983 \nL 209.910785 103.77757 \nL 210.230399 103.856396 \nL 210.481524 103.818092 \nL 210.823967 103.909524 \nL 211.120752 103.845556 \nL 211.349047 103.871894 \nL 211.531684 103.872304 \nL 211.851297 103.95012 \nL 212.033934 103.950435 \nL 212.2394 103.96361 \nL 212.490525 103.925611 \nL 212.650332 103.913131 \nL 212.924287 103.86261 \nL 213.129753 103.875816 \nL 213.380878 103.838185 \nL 213.654832 103.86425 \nL 213.883128 103.864765 \nL 214.179912 103.903416 \nL 214.316889 103.954294 \nL 214.613674 103.992682 \nL 214.864799 103.980433 \nL 215.138753 104.006014 \nL 215.435538 103.96872 \nL 215.84647 104.069615 \nL 216.051936 104.082326 \nL 216.34872 104.120051 \nL 216.691163 104.057933 \nL 216.896629 104.045695 \nL 217.307561 103.946776 \nL 217.581516 103.972042 \nL 217.923959 103.910702 \nL 218.471869 104.084366 \nL 218.791482 104.035401 \nL 219.088267 104.07259 \nL 219.362221 104.048313 \nL 219.704665 104.109853 \nL 219.95579 104.097803 \nL 220.161256 104.085754 \nL 220.321063 104.122459 \nL 220.640676 104.171329 \nL 220.98312 104.110704 \nL 221.325563 104.171529 \nL 221.736495 104.074935 \nL 222.147427 104.171761 \nL 222.444211 104.135739 \nL 222.695336 104.147883 \nL 222.855143 104.183978 \nL 223.03778 104.160027 \nL 223.288905 104.148135 \nL 223.56286 104.172171 \nL 223.813985 104.1603 \nL 224.202087 104.243825 \nL 224.407553 104.255696 \nL 224.635849 104.255643 \nL 224.932633 104.22 \nL 225.138099 104.20815 \nL 225.549031 104.113638 \nL 225.777326 104.113774 \nL 226.074111 104.078615 \nL 226.348065 104.102366 \nL 226.553531 104.114258 \nL 226.781827 104.114395 \nL 227.12427 104.056062 \nL 227.375395 104.067995 \nL 227.535202 104.103176 \nL 227.740668 104.091652 \nL 228.014623 104.068553 \nL 228.242918 104.068752 \nL 228.471214 104.068952 \nL 228.813657 104.127233 \nL 229.110442 104.092662 \nL 229.293078 104.069667 \nL 229.658351 104.000736 \nL 229.886646 104.00103 \nL 230.274749 103.921017 \nL 230.503044 103.921406 \nL 230.73134 103.921795 \nL 231.028124 103.956649 \nL 231.187931 103.99121 \nL 231.439056 104.002954 \nL 231.73584 103.969109 \nL 231.986966 103.980853 \nL 232.28375 103.947144 \nL 232.512045 103.947502 \nL 232.76317 103.936546 \nL 232.991466 103.936904 \nL 233.196932 103.948543 \nL 233.402398 103.937566 \nL 233.722012 103.892954 \nL 234.018796 103.927273 \nL 234.292751 103.905245 \nL 234.589535 103.939427 \nL 234.749342 103.973314 \nL 234.977637 103.97363 \nL 235.137444 104.007412 \nL 235.434228 104.041279 \nL 235.708183 104.019241 \nL 235.959308 104.030659 \nL 236.256092 103.997613 \nL 236.735513 104.120188 \nL 237.032297 104.087131 \nL 237.351911 104.131575 \nL 237.580207 104.131691 \nL 237.785673 104.120766 \nL 238.150946 104.054937 \nL 238.402071 104.066145 \nL 238.561878 104.099223 \nL 238.744514 104.077406 \nL 238.92715 104.099465 \nL 239.47506 104.252778 \nL 239.703355 104.252736 \nL 240.022969 104.296249 \nL 240.228435 104.307048 \nL 240.47956 104.317793 \nL 240.822004 104.263382 \nL 241.095958 104.284978 \nL 241.52972 104.187585 \nL 241.758015 104.187627 \nL 241.986311 104.187669 \nL 242.214607 104.1877 \nL 242.397243 104.209244 \nL 242.785345 104.284395 \nL 243.08213 104.252147 \nL 243.287596 104.241407 \nL 243.607209 104.198625 \nL 243.926823 104.241333 \nL 244.155119 104.241307 \nL 244.337755 104.22 \nL 244.520392 104.24127 \nL 244.908494 104.315512 \nL 245.250937 104.262372 \nL 245.661869 104.346844 \nL 245.821676 104.378424 \nL 246.027142 104.367704 \nL 246.392415 104.30424 \nL 246.734859 104.356649 \nL 247.122961 104.282938 \nL 247.511063 104.356097 \nL 247.716529 104.366406 \nL 247.921995 104.355807 \nL 248.127461 104.366096 \nL 248.401416 104.38673 \nL 248.6982 104.355261 \nL 248.926496 104.355103 \nL 249.131962 104.365339 \nL 249.291769 104.334101 \nL 249.862508 104.178626 \nL 250.204951 104.230325 \nL 250.387587 104.250943 \nL 250.798519 104.333223 \nL 250.981156 104.353684 \nL 251.323599 104.404778 \nL 251.551895 104.404562 \nL 251.711702 104.373676 \nL 251.894338 104.394006 \nL 252.487907 104.556756 \nL 252.761861 104.535911 \nL 253.012986 104.545684 \nL 253.286941 104.524908 \nL 253.720703 104.615515 \nL 254.040316 104.574378 \nL 254.474078 104.664538 \nL 254.725203 104.674069 \nL 255.044817 104.693489 \nL 255.38726 104.662508 \nL 255.684044 104.671898 \nL 255.980829 104.661199 \nL 256.231954 104.650633 \nL 256.528738 104.640003 \nL 256.802693 104.63943 \nL 257.053818 104.648882 \nL 257.419091 104.687932 \nL 257.738704 104.667313 \nL 257.967 104.646953 \nL 258.195295 104.666304 \nL 258.423591 104.64599 \nL 258.857353 104.575887 \nL 259.245455 104.624541 \nL 259.542239 104.614101 \nL 259.770535 104.593976 \nL 260.02166 104.60335 \nL 260.341274 104.622381 \nL 260.592399 104.631691 \nL 260.866354 104.631144 \nL 261.117479 104.640418 \nL 261.459922 104.669006 \nL 261.962172 104.57054 \nL 262.395934 104.637826 \nL 262.738377 104.608034 \nL 263.240627 104.703871 \nL 263.742878 104.606162 \nL 264.062491 104.624852 \nL 264.290787 104.643667 \nL 264.541912 104.633542 \nL 264.815867 104.633 \nL 265.226799 104.689709 \nL 265.432265 104.717982 \nL 265.751878 104.73635 \nL 266.025833 104.735677 \nL 266.368276 104.763445 \nL 266.573742 104.791492 \nL 266.847697 104.790751 \nL 267.258629 104.732681 \nL 267.464095 104.70373 \nL 267.829368 104.665027 \nL 268.080493 104.655043 \nL 268.331618 104.663975 \nL 268.719721 104.710317 \nL 268.879528 104.757058 \nL 269.221971 104.784421 \nL 269.404607 104.821537 \nL 269.747051 104.848726 \nL 270.180812 104.781903 \nL 270.523256 104.809061 \nL 270.911358 104.761332 \nL 271.436438 104.862437 \nL 271.893029 104.786755 \nL 272.281131 104.832114 \nL 272.85187 104.710259 \nL 273.194314 104.737191 \nL 273.35412 104.78296 \nL 273.696564 104.809719 \nL 274.039007 104.781199 \nL 274.335791 104.789626 \nL 274.746723 104.733537 \nL 275.180485 104.796591 \nL 275.728394 104.685603 \nL 276.002349 104.685025 \nL 276.367622 104.647846 \nL 276.687236 104.66541 \nL 277.075338 104.619258 \nL 277.372122 104.62779 \nL 277.805884 104.563685 \nL 278.102668 104.572259 \nL 278.399452 104.56277 \nL 278.673407 104.56235 \nL 278.901702 104.579998 \nL 279.221316 104.597462 \nL 279.677907 104.52494 \nL 280.088839 104.5781 \nL 280.385624 104.56869 \nL 280.56826 104.532673 \nL 280.728067 104.577085 \nL 281.138999 104.629898 \nL 281.321635 104.665184 \nL 281.892374 104.779522 \nL 282.143499 104.787775 \nL 282.668579 104.883823 \nL 283.011023 104.856312 \nL 283.330636 104.873072 \nL 283.467614 104.85504 \nL 283.467614 104.85504 \n\" clip-path=\"url(#pe69abb95a9)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 55.194886 16.02 \nL 55.240545 16.02 \nL 55.354693 104.22 \nL 55.377523 94.419995 \nL 55.446011 118.920002 \nL 55.491671 104.22 \nL 55.53733 93.195 \nL 55.628648 95.399998 \nL 55.788455 114.019999 \nL 55.811284 110.520002 \nL 55.925432 106.892725 \nL 56.085239 121.859999 \nL 56.130898 121.019999 \nL 56.245046 117.356169 \nL 56.290705 120.419998 \nL 56.382023 119.197357 \nL 56.427682 115.445454 \nL 56.473341 118.146315 \nL 56.56466 123.01672 \nL 56.610319 122.419999 \nL 56.633148 120.7575 \nL 56.678807 122.929089 \nL 56.747296 125.950435 \nL 56.770126 124.379999 \nL 56.792955 122.853801 \nL 56.838614 124.759727 \nL 56.861444 123.290269 \nL 56.929933 125.983639 \nL 56.952762 124.573845 \nL 56.975592 123.199747 \nL 57.04408 125.732196 \nL 57.203887 121.067192 \nL 57.226717 121.859999 \nL 57.249546 120.696922 \nL 57.409353 115.02 \nL 57.432183 115.801819 \nL 57.477842 115.572477 \nL 57.614819 118.233084 \nL 57.683308 115.445454 \nL 57.728967 116.819999 \nL 57.751797 117.489027 \nL 57.820285 116.385519 \nL 57.888774 116.819999 \nL 57.934433 115.153883 \nL 57.980092 114.976098 \nL 58.139899 117.78923 \nL 58.276876 115.89353 \nL 58.482342 119.426894 \nL 58.642149 116.985788 \nL 58.664979 117.478823 \nL 58.710638 116.169677 \nL 58.779127 115.384556 \nL 58.801956 115.869058 \nL 58.938933 117.583634 \nL 58.984593 117.423591 \nL 59.09874 115.501395 \nL 59.12157 115.946012 \nL 59.190059 117.249544 \nL 59.258547 116.538438 \nL 59.441184 113.181498 \nL 59.464013 113.602978 \nL 59.555331 114.326248 \nL 59.509672 113.504212 \nL 59.578161 113.81689 \nL 59.600991 113.312784 \nL 59.64665 114.120001 \nL 59.669479 114.517461 \nL 59.737968 113.922001 \nL 59.760798 114.312538 \nL 59.920604 111.85269 \nL 59.943434 112.238179 \nL 60.034752 112.087605 \nL 60.103241 113.203336 \nL 60.17173 112.677534 \nL 60.194559 113.040002 \nL 60.285877 112.882498 \nL 60.354366 113.933656 \nL 60.377196 113.504212 \nL 60.422855 114.190436 \nL 60.445684 113.765454 \nL 60.468514 114.104481 \nL 60.514173 113.266153 \nL 60.559832 112.442035 \nL 60.605491 113.114117 \nL 60.628321 113.445942 \nL 60.67398 112.637427 \nL 60.719639 113.294074 \nL 60.833787 111.332902 \nL 60.902275 111.59928 \nL 60.993594 111.483529 \nL 61.062082 112.42465 \nL 61.336037 108.793335 \nL 61.358866 109.101918 \nL 61.473014 109.972173 \nL 61.404526 109.066154 \nL 61.518673 109.930794 \nL 61.587162 109.555945 \nL 61.609992 109.849787 \nL 61.792628 111.519309 \nL 61.655651 109.810143 \nL 61.815458 111.191133 \nL 61.975264 110.139465 \nL 61.998094 110.414649 \nL 62.043753 109.787442 \nL 62.066583 109.476956 \nL 62.112242 110.02263 \nL 62.135071 110.292789 \nL 62.18073 109.67863 \nL 62.22639 110.214174 \nL 62.409026 108.393504 \nL 62.431856 108.657738 \nL 62.546003 109.408235 \nL 62.591662 109.376308 \nL 62.72864 108.21698 \nL 62.751469 108.470605 \nL 62.774299 108.722705 \nL 62.819958 108.169256 \nL 62.888447 107.873253 \nL 62.911276 108.122656 \nL 62.934106 108.370588 \nL 63.002594 108.07714 \nL 63.116742 106.754483 \nL 63.162401 107.244001 \nL 63.25372 108.206439 \nL 63.299379 107.688538 \nL 63.390697 106.670001 \nL 63.436356 107.143758 \nL 63.527674 108.075737 \nL 63.618992 108.034053 \nL 63.778799 107.261381 \nL 63.824458 107.710766 \nL 63.870118 107.229449 \nL 64.052754 106.260618 \nL 64.189731 107.122787 \nL 64.23539 107.108162 \nL 64.372368 105.752012 \nL 64.418027 106.18 \nL 64.440856 106.392414 \nL 64.486516 105.949412 \nL 64.532175 106.371217 \nL 64.691982 105.277556 \nL 64.714811 105.486027 \nL 64.737641 105.69351 \nL 64.7833 105.267504 \nL 64.851788 104.636039 \nL 64.897448 105.048171 \nL 65.057254 105.645865 \nL 65.102914 105.233795 \nL 65.171402 105.42822 \nL 65.239891 105.220001 \nL 65.399698 106.582502 \nL 65.582334 105.767368 \nL 65.605164 105.956982 \nL 65.673652 105.753915 \nL 65.742141 105.172481 \nL 65.7878 105.547741 \nL 65.81063 105.734164 \nL 65.856289 105.350772 \nL 65.970437 105.152347 \nL 66.153073 105.870313 \nL 66.381369 104.758898 \nL 66.541176 105.28265 \nL 66.700982 104.743962 \nL 66.769471 104.567244 \nL 66.883619 105.423509 \nL 66.906448 105.249572 \nL 66.952108 105.587443 \nL 67.020596 105.409594 \nL 67.089085 105.909657 \nL 67.294551 105.050511 \nL 67.36304 104.880674 \nL 67.408699 105.207315 \nL 67.500017 104.873335 \nL 67.522846 105.035155 \nL 67.659824 105.3487 \nL 67.86529 104.537268 \nL 68.025097 105.003302 \nL 68.093585 104.531658 \nL 68.139244 104.841125 \nL 68.321881 105.751249 \nL 68.34471 105.595738 \nL 68.527347 104.672308 \nL 68.550176 104.822046 \nL 68.755642 105.850588 \nL 68.778472 105.699866 \nL 68.801302 105.549649 \nL 68.846961 105.839701 \nL 69.029597 106.690183 \nL 69.052427 106.541054 \nL 69.098086 106.244263 \nL 69.166574 106.378236 \nL 69.212234 106.658046 \nL 69.257893 106.364247 \nL 69.39487 106.060447 \nL 69.554677 106.46 \nL 69.760143 105.738312 \nL 69.942779 106.264824 \nL 69.965609 106.125557 \nL 70.011268 106.391079 \nL 70.125416 106.509159 \nL 70.216734 105.95991 \nL 70.262393 106.221515 \nL 70.4222 106.860719 \nL 70.44503 106.724933 \nL 70.467859 106.589551 \nL 70.513518 106.845001 \nL 70.536348 106.710045 \nL 70.627666 106.955894 \nL 70.650496 106.821769 \nL 70.696155 106.554707 \nL 70.764643 106.673587 \nL 70.901621 107.164266 \nL 70.92445 107.032175 \nL 70.992939 107.147275 \nL 71.061428 106.754483 \nL 71.107087 106.999944 \nL 71.152746 106.74 \nL 71.175575 106.610585 \nL 71.221234 106.85471 \nL 71.244064 106.97625 \nL 71.289723 106.718582 \nL 71.312553 106.839801 \nL 71.495189 106.317064 \nL 71.563678 106.185462 \nL 71.609337 106.424998 \nL 71.654996 106.174569 \nL 71.700655 106.412817 \nL 72.088758 107.909879 \nL 72.225735 107.40795 \nL 72.248564 107.521604 \nL 72.271394 107.634953 \nL 72.317053 107.390974 \nL 72.47686 107.012614 \nL 72.49969 107.125137 \nL 72.545349 106.885701 \nL 72.750815 106.28182 \nL 72.773644 106.393539 \nL 72.819303 106.159718 \nL 73.070428 105.344999 \nL 73.116088 105.566566 \nL 73.161747 105.33929 \nL 73.184576 105.226083 \nL 73.230235 105.446546 \nL 73.412872 106.096596 \nL 73.435701 105.983998 \nL 73.709656 104.871726 \nL 73.732486 104.979408 \nL 73.915122 105.401729 \nL 74.189077 104.537646 \nL 74.371713 104.954127 \nL 74.53152 104.636039 \nL 74.736986 105.146254 \nL 74.828304 104.937072 \nL 74.851134 105.038561 \nL 74.988111 105.23613 \nL 75.010941 105.133463 \nL 75.0566 105.333891 \nL 75.079429 105.231466 \nL 75.193577 105.728554 \nL 75.262066 105.62318 \nL 75.490361 105.012807 \nL 75.627339 105.204377 \nL 75.718657 104.807999 \nL 75.787146 104.903721 \nL 75.946952 105.189231 \nL 76.129589 104.796471 \nL 76.152418 104.891819 \nL 76.198078 104.69883 \nL 76.220907 104.793968 \nL 76.243737 104.697789 \nL 76.289396 104.887461 \nL 76.403544 104.978709 \nL 76.60901 104.501787 \nL 76.791646 104.871952 \nL 76.974282 104.312357 \nL 76.997112 104.40452 \nL 77.134089 104.586737 \nL 77.430874 103.767687 \nL 77.681999 104.398905 \nL 77.704828 104.309361 \nL 77.750487 104.487541 \nL 77.841806 104.84175 \nL 77.887465 104.663218 \nL 78.024442 104.484334 \nL 78.092931 104.571392 \nL 78.11576 104.483282 \nL 78.275567 104.22 \nL 78.366885 104.393622 \nL 78.389715 104.306727 \nL 78.458204 104.22 \nL 78.481033 104.306385 \nL 78.61801 104.649408 \nL 78.64084 104.563191 \nL 78.800647 104.305218 \nL 78.960454 104.89716 \nL 79.006113 104.726898 \nL 79.16592 104.30392 \nL 79.188749 104.387681 \nL 79.211579 104.47128 \nL 79.257238 104.303604 \nL 79.485534 103.805917 \nL 79.66817 104.3022 \nL 79.691 104.22 \nL 79.919295 103.731812 \nL 80.010613 104.05787 \nL 80.056273 103.896329 \nL 80.17042 103.656162 \nL 80.19325 103.737154 \nL 80.307398 103.979676 \nL 80.330227 103.899851 \nL 80.490034 103.66328 \nL 80.627011 103.824485 \nL 80.763989 103.511886 \nL 80.786818 103.591121 \nL 80.832477 103.749182 \nL 80.878137 103.593361 \nL 80.992284 103.362173 \nL 81.015114 103.440851 \nL 81.129262 103.521843 \nL 81.19775 103.601057 \nL 81.266239 103.371184 \nL 81.403216 103.52914 \nL 81.426046 103.453048 \nL 81.471705 103.607502 \nL 81.517364 103.761421 \nL 81.563023 103.609616 \nL 81.72283 103.385778 \nL 81.882637 103.767687 \nL 81.905467 103.692762 \nL 81.928296 103.617954 \nL 81.973955 103.769233 \nL 82.22508 104.443291 \nL 82.24791 104.368735 \nL 82.430546 104.072264 \nL 82.613183 104.366758 \nL 82.636012 104.293316 \nL 82.681671 104.439585 \nL 82.704501 104.366269 \nL 82.727331 104.439222 \nL 82.77299 104.292953 \nL 82.795819 104.22 \nL 82.841478 104.365544 \nL 82.864308 104.438139 \nL 82.909967 104.29259 \nL 82.978456 104.364829 \nL 83.046944 104.147767 \nL 83.229581 104.435295 \nL 83.25241 104.363414 \nL 83.298069 104.506361 \nL 83.366558 104.577085 \nL 83.389388 104.505436 \nL 83.526365 104.22 \nL 83.549195 104.290955 \nL 83.640513 104.432188 \nL 83.663342 104.361348 \nL 83.754661 104.22 \nL 83.77749 104.290393 \nL 83.845979 104.360444 \nL 83.868808 104.290167 \nL 83.937297 104.360003 \nL 84.051445 104.010829 \nL 84.165593 104.22 \nL 84.188422 104.150606 \nL 84.27974 103.874112 \nL 84.348229 103.943948 \nL 84.393888 104.08219 \nL 84.439547 103.9448 \nL 84.599354 103.741023 \nL 84.82765 104.152099 \nL 84.873309 104.016623 \nL 84.941797 104.084724 \nL 84.987457 104.22 \nL 85.055945 104.152625 \nL 85.124434 103.951098 \nL 85.170093 104.085754 \nL 85.238582 104.019094 \nL 85.284241 104.153129 \nL 85.444048 103.953937 \nL 85.786491 104.680404 \nL 85.900639 104.351055 \nL 85.969127 104.416144 \nL 86.174593 104.739588 \nL 86.243082 104.673638 \nL 86.265912 104.738064 \nL 86.311571 104.866627 \nL 86.380059 104.800687 \nL 86.539866 104.605153 \nL 86.562696 104.669017 \nL 86.608355 104.540259 \nL 86.631185 104.604033 \nL 86.699673 104.667066 \nL 86.745332 104.538871 \nL 86.813821 104.60182 \nL 86.836651 104.537951 \nL 86.85948 104.474177 \nL 86.905139 104.600721 \nL 86.973628 104.789852 \nL 87.019287 104.662582 \nL 87.201923 104.408594 \nL 87.270412 104.345461 \nL 87.316071 104.470571 \nL 87.475878 104.282334 \nL 87.612855 104.406208 \nL 87.841151 104.035096 \nL 87.932469 104.281461 \nL 87.978128 104.158618 \nL 88.000958 104.09733 \nL 88.046617 104.22 \nL 88.183594 104.341992 \nL 88.41189 103.977688 \nL 88.526038 104.159627 \nL 88.548867 104.099338 \nL 88.685845 103.979676 \nL 88.959799 104.458379 \nL 89.096777 104.22 \nL 89.119606 104.279316 \nL 89.165265 104.397701 \nL 89.210924 104.279153 \nL 89.279413 104.101925 \nL 89.325072 104.22 \nL 89.393561 104.161162 \nL 89.530538 104.513022 \nL 89.621856 104.395346 \nL 89.644686 104.453643 \nL 89.827322 104.68482 \nL 89.850152 104.62645 \nL 89.895811 104.741891 \nL 90.124107 105.084141 \nL 90.283913 104.908169 \nL 90.557868 105.358063 \nL 90.580698 105.300466 \nL 90.626357 105.412659 \nL 90.717675 105.52289 \nL 90.740505 105.46544 \nL 90.877482 105.347875 \nL 91.082948 105.621782 \nL 91.151437 105.45122 \nL 91.197096 105.561446 \nL 91.288414 105.669559 \nL 91.311243 105.612924 \nL 91.448221 105.385637 \nL 91.47105 105.44038 \nL 91.539539 105.493445 \nL 91.562369 105.437315 \nL 91.585198 105.381253 \nL 91.630857 105.490259 \nL 91.699346 105.653251 \nL 91.745005 105.541348 \nL 91.813494 105.374019 \nL 91.859153 105.482352 \nL 91.927641 105.425218 \nL 91.99613 105.587017 \nL 92.133107 105.364041 \nL 92.155937 105.417779 \nL 92.315744 105.575256 \nL 92.384233 105.518648 \nL 92.407062 105.571929 \nL 92.475551 105.515472 \nL 92.589699 105.780584 \nL 92.612528 105.725852 \nL 92.658187 105.831447 \nL 92.772335 105.880107 \nL 92.840824 105.823635 \nL 92.863653 105.876085 \nL 93.000631 105.976549 \nL 93.114778 105.705922 \nL 93.183267 105.756217 \nL 93.251756 105.912086 \nL 93.297415 105.804431 \nL 93.388733 105.589892 \nL 93.434392 105.69351 \nL 93.457222 105.745225 \nL 93.502881 105.638342 \nL 93.639858 105.423919 \nL 93.662688 105.475518 \nL 93.731176 105.629946 \nL 93.776835 105.523963 \nL 93.799665 105.471065 \nL 93.845324 105.573721 \nL 94.119279 105.977795 \nL 94.210597 105.767368 \nL 94.279086 105.816149 \nL 94.301915 105.866675 \nL 94.347574 105.761958 \nL 94.370404 105.709692 \nL 94.416063 105.810576 \nL 94.438893 105.758373 \nL 94.461722 105.808726 \nL 94.507381 105.704503 \nL 94.530211 105.754803 \nL 94.644359 105.597326 \nL 94.667188 105.647516 \nL 94.804165 105.845804 \nL 94.826995 105.794095 \nL 94.941143 105.738942 \nL 94.986802 105.83835 \nL 95.032461 105.735462 \nL 95.07812 105.632817 \nL 95.146609 105.680767 \nL 95.169438 105.730273 \nL 95.215097 105.62798 \nL 95.329245 105.473552 \nL 95.352075 105.522953 \nL 95.534711 105.716605 \nL 95.626029 105.613681 \nL 95.648859 105.66264 \nL 95.785836 105.856087 \nL 95.808666 105.805619 \nL 95.877155 105.852418 \nL 95.922814 105.751765 \nL 96.151109 106.038052 \nL 96.265257 105.983998 \nL 96.402234 106.271164 \nL 96.447893 106.171326 \nL 96.516382 106.021986 \nL 96.584871 106.067629 \nL 96.721848 106.158461 \nL 96.790337 106.203652 \nL 96.904485 105.956982 \nL 96.972973 105.905961 \nL 97.064291 106.09455 \nL 97.13278 106.139478 \nL 97.246928 105.894985 \nL 97.292587 105.988782 \nL 97.338246 105.891357 \nL 97.406735 105.936327 \nL 97.452394 105.839222 \nL 97.475223 105.885948 \nL 97.520883 105.789059 \nL 97.589371 105.644114 \nL 97.63503 105.737418 \nL 97.703519 105.877005 \nL 97.749178 105.780642 \nL 97.840496 105.682923 \nL 97.863326 105.729306 \nL 98.023133 105.864646 \nL 98.18294 105.718087 \nL 98.205769 105.764087 \nL 98.251428 105.668965 \nL 98.274258 105.714917 \nL 98.411235 105.523905 \nL 98.434065 105.569763 \nL 98.456894 105.615568 \nL 98.502553 105.521161 \nL 98.571042 105.379917 \nL 98.639531 105.424414 \nL 98.776508 105.512986 \nL 98.890656 105.279322 \nL 98.936315 105.370234 \nL 99.347247 105.997672 \nL 99.415736 105.85839 \nL 99.484224 105.901298 \nL 99.644031 106.031086 \nL 99.758179 105.890968 \nL 99.781009 105.935249 \nL 99.849497 105.97769 \nL 99.872327 105.931748 \nL 99.940816 105.974104 \nL 100.009304 105.836699 \nL 100.054963 105.924782 \nL 100.123452 105.877389 \nL 100.146282 105.831778 \nL 100.191941 105.919593 \nL 100.21477 105.87403 \nL 100.374577 106.00182 \nL 100.420236 105.911019 \nL 100.465895 105.998224 \nL 100.694191 106.254704 \nL 100.71702 106.209471 \nL 100.76268 106.295814 \nL 100.785509 106.250629 \nL 100.853998 106.291667 \nL 100.876827 106.246571 \nL 101.013805 105.97697 \nL 101.082293 106.018212 \nL 101.127952 106.104055 \nL 101.173612 106.014642 \nL 101.424737 105.700155 \nL 101.447566 105.742938 \nL 101.493225 105.654497 \nL 101.607373 105.520887 \nL 101.630203 105.563586 \nL 101.812839 105.817358 \nL 101.835669 105.773424 \nL 101.926987 105.684258 \nL 101.949816 105.726588 \nL 102.063964 105.765864 \nL 102.086794 105.722188 \nL 102.132453 105.806486 \nL 102.155282 105.762857 \nL 102.26943 105.887378 \nL 102.29226 105.843838 \nL 102.360748 105.88415 \nL 102.406408 105.797286 \nL 102.497726 105.879334 \nL 102.520555 105.83601 \nL 102.680362 105.70342 \nL 102.703192 105.745072 \nL 102.748851 105.658966 \nL 102.77168 105.700576 \nL 102.840169 105.656206 \nL 102.862999 105.697742 \nL 102.885828 105.739237 \nL 102.931487 105.653462 \nL 102.954317 105.610637 \nL 102.999976 105.69351 \nL 103.068465 105.733444 \nL 103.091294 105.690698 \nL 103.31959 105.432804 \nL 103.342419 105.47403 \nL 103.388078 105.389317 \nL 103.570715 105.218492 \nL 103.616374 105.300677 \nL 103.662033 105.21661 \nL 103.867499 105.005652 \nL 104.050136 105.167503 \nL 104.095795 105.084304 \nL 104.141454 105.165737 \nL 104.164283 105.206395 \nL 104.209942 105.123354 \nL 104.415408 104.915134 \nL 104.483897 104.954999 \nL 104.506727 104.913846 \nL 104.643704 104.830521 \nL 104.803511 104.950268 \nL 104.963318 104.826604 \nL 105.031806 104.866154 \nL 105.054636 104.82549 \nL 105.282932 104.581638 \nL 105.397079 104.70109 \nL 105.419909 104.6608 \nL 105.534057 104.459893 \nL 105.602545 104.499495 \nL 105.625375 104.539276 \nL 105.671034 104.459241 \nL 105.739523 104.498738 \nL 105.808011 104.37906 \nL 105.830841 104.418741 \nL 105.8765 104.339137 \nL 105.89933 104.299388 \nL 105.944989 104.378634 \nL 105.967818 104.338922 \nL 106.196114 104.654092 \nL 106.218943 104.614453 \nL 106.287432 104.574536 \nL 106.310262 104.613748 \nL 106.492898 104.769286 \nL 106.561387 104.729374 \nL 106.584216 104.768313 \nL 106.744023 104.883744 \nL 106.92666 104.725778 \nL 107.086466 104.840578 \nL 107.246273 104.568006 \nL 107.291932 104.644965 \nL 107.40608 104.682585 \nL 107.657205 104.411822 \nL 107.794183 104.487851 \nL 108.045308 104.22 \nL 108.113796 104.334101 \nL 108.159456 104.257999 \nL 108.319262 104.144224 \nL 108.524728 104.333223 \nL 108.593217 104.22 \nL 108.638876 104.295319 \nL 108.753024 104.332739 \nL 108.867172 104.294998 \nL 109.163956 104.630235 \nL 109.300933 104.554795 \nL 109.392252 104.628505 \nL 109.415081 104.591211 \nL 109.574888 104.479087 \nL 109.689036 104.589345 \nL 109.711865 104.552272 \nL 109.848843 104.477789 \nL 109.96299 104.5875 \nL 109.98582 104.55061 \nL 110.031479 104.476926 \nL 110.077138 104.550064 \nL 110.122797 104.623075 \nL 110.168456 104.549517 \nL 110.328263 104.439038 \nL 110.48807 104.620415 \nL 110.5109 104.583862 \nL 110.762025 104.328665 \nL 110.921832 104.508942 \nL 110.944661 104.472721 \nL 110.967491 104.436531 \nL 111.01315 104.508469 \nL 111.195786 104.651295 \nL 111.378423 104.506598 \nL 111.401252 104.542288 \nL 111.446912 104.470465 \nL 111.698037 104.22 \nL 111.766525 104.25558 \nL 111.789355 104.22 \nL 111.835014 104.148924 \nL 111.880673 104.22 \nL 112.01765 104.361685 \nL 112.04048 104.32622 \nL 112.177457 104.255323 \nL 112.337264 104.360896 \nL 112.519901 104.22 \nL 112.725367 104.394931 \nL 112.839514 104.289836 \nL 112.862344 104.324712 \nL 112.953662 104.324543 \nL 112.999321 104.254818 \nL 113.04498 104.32438 \nL 113.204787 104.428182 \nL 113.387424 104.289179 \nL 113.547231 104.392465 \nL 113.661378 104.357705 \nL 113.866844 104.528751 \nL 114.003822 104.39113 \nL 114.026651 104.425275 \nL 114.209288 104.561067 \nL 114.483242 104.22 \nL 114.506072 104.253935 \nL 114.59739 104.321652 \nL 114.62022 104.287743 \nL 114.825686 104.118737 \nL 114.917004 104.186302 \nL 114.939834 104.152625 \nL 115.031152 104.152719 \nL 115.053981 104.186375 \nL 115.09964 104.1192 \nL 115.236618 104.052382 \nL 115.350766 104.153077 \nL 115.373595 104.119662 \nL 115.533402 103.953127 \nL 115.556232 103.986583 \nL 115.693209 104.053643 \nL 115.716038 104.02045 \nL 115.761698 104.087068 \nL 115.989993 104.286219 \nL 116.12697 104.22 \nL 116.263948 104.285919 \nL 116.423755 104.187122 \nL 116.492243 104.22 \nL 116.515073 104.187174 \nL 116.697709 104.056367 \nL 116.994494 104.350282 \nL 117.085812 104.350088 \nL 117.108641 104.38255 \nL 117.1543 104.317457 \nL 117.245619 104.252436 \nL 117.268448 104.284852 \nL 117.336937 104.317173 \nL 117.359766 104.284757 \nL 117.451085 104.284663 \nL 117.633721 104.477894 \nL 117.656551 104.445573 \nL 117.747869 104.380889 \nL 117.770698 104.413 \nL 117.953335 104.540727 \nL 118.021824 104.508338 \nL 118.044653 104.540259 \nL 118.158801 104.571649 \nL 118.18163 104.539565 \nL 118.22729 104.603203 \nL 118.341437 104.634383 \nL 118.455585 104.60182 \nL 118.478415 104.633489 \nL 118.615392 104.759544 \nL 118.638222 104.727628 \nL 118.70671 104.695386 \nL 118.752369 104.758383 \nL 118.843688 104.820858 \nL 118.866517 104.789032 \nL 119.026324 104.756075 \nL 119.140472 104.786598 \nL 119.391597 104.627606 \nL 119.482915 104.689651 \nL 119.528574 104.626739 \nL 119.551404 104.595317 \nL 119.619893 104.688652 \nL 119.802529 104.811948 \nL 120.007995 104.716904 \nL 120.099313 104.716205 \nL 120.122143 104.685025 \nL 120.25912 104.560299 \nL 120.304779 104.621892 \nL 120.418927 104.652052 \nL 120.441757 104.621051 \nL 120.76137 104.373498 \nL 121.035325 104.556293 \nL 121.263621 104.433266 \nL 121.446257 104.554206 \nL 121.469087 104.52372 \nL 121.651723 104.401728 \nL 121.674553 104.431946 \nL 121.834359 104.461644 \nL 121.925678 104.400987 \nL 121.971337 104.46115 \nL 122.153973 104.580734 \nL 122.176803 104.550563 \nL 122.268121 104.49009 \nL 122.31378 104.54989 \nL 122.473587 104.579025 \nL 122.679053 104.48845 \nL 122.724712 104.547882 \nL 122.793201 104.458216 \nL 122.81603 104.428372 \nL 122.884519 104.51737 \nL 123.021496 104.51677 \nL 123.089985 104.42753 \nL 123.158474 104.516171 \nL 123.272621 104.60438 \nL 123.318281 104.545027 \nL 123.432428 104.455987 \nL 123.478087 104.514788 \nL 123.637894 104.60233 \nL 123.660724 104.572801 \nL 123.86619 104.483808 \nL 124.025997 104.570929 \nL 124.048826 104.541579 \nL 124.162974 104.45349 \nL 124.208633 104.511666 \nL 124.322781 104.59854 \nL 124.36844 104.540091 \nL 124.39127 104.510898 \nL 124.459758 104.597793 \nL 124.505417 104.655627 \nL 124.573906 104.568159 \nL 124.802202 104.393506 \nL 124.825031 104.422357 \nL 124.984838 104.508422 \nL 125.007668 104.479497 \nL 125.235963 104.363693 \nL 125.464259 104.47781 \nL 125.601236 104.420128 \nL 125.624066 104.448643 \nL 125.852361 104.561861 \nL 126.034998 104.390489 \nL 126.080657 104.447171 \nL 126.263293 104.503238 \nL 126.400271 104.502692 \nL 126.491589 104.558796 \nL 126.537248 104.50215 \nL 126.811203 104.276214 \nL 126.834032 104.304293 \nL 127.107987 104.471922 \nL 127.290623 104.359603 \nL 127.313453 104.387466 \nL 127.47326 104.470649 \nL 127.496089 104.442729 \nL 127.564578 104.414703 \nL 127.610237 104.470171 \nL 127.815703 104.552619 \nL 128.021169 104.468762 \nL 128.180976 104.550957 \nL 128.203805 104.523284 \nL 128.47776 104.302406 \nL 128.50059 104.329837 \nL 128.637567 104.494086 \nL 128.706056 104.41168 \nL 128.820203 104.438723 \nL 128.843033 104.465986 \nL 128.911522 104.383838 \nL 129.048499 104.274511 \nL 129.094158 104.328954 \nL 129.208306 104.355986 \nL 129.231135 104.328754 \nL 129.482261 104.138714 \nL 129.50509 104.16582 \nL 129.710556 104.247016 \nL 129.870363 104.22 \nL 130.052999 104.327561 \nL 130.075829 104.300644 \nL 130.281295 104.22 \nL 130.463931 104.273486 \nL 130.852034 103.980538 \nL 131.011841 104.007601 \nL 131.171648 103.928566 \nL 131.194477 103.955135 \nL 131.331455 104.008485 \nL 131.354284 103.982125 \nL 131.491261 103.929785 \nL 131.514091 103.956239 \nL 131.605409 103.956555 \nL 131.628239 103.930301 \nL 131.856534 103.826136 \nL 132.062 103.958121 \nL 132.08483 103.932025 \nL 132.176148 103.880063 \nL 132.221807 103.93253 \nL 132.450103 104.089718 \nL 132.472932 104.063706 \nL 132.60991 104.063989 \nL 132.746887 104.064263 \nL 132.792546 104.01247 \nL 132.861035 104.090412 \nL 133.11216 104.271667 \nL 133.134989 104.245828 \nL 133.249137 104.271578 \nL 133.363285 104.297254 \nL 133.386115 104.271488 \nL 133.431774 104.22 \nL 133.500262 104.297122 \nL 133.682899 104.348237 \nL 133.911194 104.245571 \nL 134.207979 104.423814 \nL 134.596081 104.14394 \nL 134.755888 104.2706 \nL 134.801547 104.22 \nL 134.938524 104.169511 \nL 134.961354 104.194766 \nL 135.189649 104.295492 \nL 135.463604 104.14477 \nL 135.6919 104.245008 \nL 135.828877 104.244966 \nL 136.057173 104.344473 \nL 136.080002 104.319549 \nL 136.148491 104.394064 \nL 136.216979 104.418762 \nL 136.262639 104.368987 \nL 136.536593 104.170509 \nL 136.559423 104.19526 \nL 136.673571 104.22 \nL 136.6964 104.195302 \nL 136.833377 104.146032 \nL 136.856207 104.170699 \nL 136.993184 104.22 \nL 137.016014 104.195397 \nL 137.152991 104.195439 \nL 137.289969 104.195481 \nL 137.404116 104.22 \nL 137.678071 104.366432 \nL 137.74656 104.293153 \nL 137.815048 104.36619 \nL 138.043344 104.462974 \nL 138.271639 104.365386 \nL 138.340128 104.389474 \nL 138.385787 104.340988 \nL 138.545594 104.268303 \nL 138.568424 104.292433 \nL 138.819549 104.412574 \nL 138.979356 104.388181 \nL 139.161992 104.435763 \nL 139.25331 104.387634 \nL 139.298969 104.435416 \nL 139.504436 104.506519 \nL 139.618583 104.434596 \nL 139.664242 104.482147 \nL 139.846879 104.52914 \nL 139.869708 104.505283 \nL 139.938197 104.576318 \nL 140.075174 104.575739 \nL 140.120834 104.528141 \nL 140.189322 104.59895 \nL 140.349129 104.621876 \nL 140.554595 104.502997 \nL 140.577425 104.526496 \nL 140.80572 104.619731 \nL 140.919868 104.548755 \nL 140.965527 104.595517 \nL 141.170993 104.664864 \nL 141.376459 104.593729 \nL 141.604755 104.732518 \nL 141.627584 104.709092 \nL 141.673243 104.662282 \nL 141.741732 104.731708 \nL 142.015687 104.915581 \nL 142.038516 104.892219 \nL 142.175494 104.844873 \nL 142.198323 104.867847 \nL 142.312471 104.890105 \nL 142.3353 104.866832 \nL 142.472278 104.865817 \nL 142.88321 105.138273 \nL 143.020187 105.136838 \nL 143.40829 105.383829 \nL 143.545267 105.382025 \nL 143.842051 105.537095 \nL 143.933369 105.581113 \nL 144.161665 105.668129 \nL 144.367131 105.597068 \nL 144.572597 105.661473 \nL 144.686745 105.682129 \nL 144.800892 105.657799 \nL 145.006358 105.587269 \nL 145.211824 105.651238 \nL 145.371631 105.626377 \nL 145.531438 105.646175 \nL 145.622756 105.689257 \nL 145.851052 105.774381 \nL 146.079348 105.681876 \nL 146.307643 105.766595 \nL 146.44462 105.764271 \nL 146.581598 105.761958 \nL 146.809893 105.670227 \nL 147.106678 105.818856 \nL 147.380632 105.683085 \nL 147.540439 105.702353 \nL 147.700246 105.678033 \nL 147.951371 105.782598 \nL 148.065519 105.802354 \nL 148.248155 105.842518 \nL 148.407962 105.818141 \nL 148.613428 105.879271 \nL 148.818894 105.811128 \nL 149.001531 105.850951 \nL 149.115678 105.870402 \nL 149.321144 105.930959 \nL 149.663588 105.732976 \nL 149.869054 105.79348 \nL 150.120179 105.683285 \nL 150.279986 105.701995 \nL 150.508281 105.613965 \nL 150.690918 105.653462 \nL 150.782236 105.69421 \nL 151.033361 105.795373 \nL 151.170338 105.793128 \nL 151.398634 105.873094 \nL 151.62693 105.785678 \nL 151.718248 105.742486 \nL 151.923714 105.676819 \nL 152.12918 105.736035 \nL 152.288987 105.712809 \nL 152.585771 105.852949 \nL 152.814066 105.766642 \nL 152.905385 105.723996 \nL 153.13368 105.638268 \nL 153.384805 105.737155 \nL 153.544612 105.714223 \nL 153.68159 105.712142 \nL 153.818567 105.71007 \nL 154.024033 105.768083 \nL 154.18384 105.745246 \nL 154.366476 105.783039 \nL 154.526283 105.760255 \nL 154.640431 105.738249 \nL 154.823067 105.695051 \nL 154.937215 105.673181 \nL 155.233999 105.528011 \nL 155.416636 105.565799 \nL 155.553613 105.563964 \nL 155.667761 105.542399 \nL 155.781909 105.56091 \nL 155.964545 105.598435 \nL 156.2385 105.475161 \nL 156.375477 105.473463 \nL 156.512454 105.47177 \nL 156.74075 105.548256 \nL 157.014705 105.426054 \nL 157.197341 105.463364 \nL 157.288659 105.501688 \nL 157.448466 105.519373 \nL 157.585444 105.517638 \nL 157.76808 105.55458 \nL 158.042035 105.433582 \nL 158.27033 105.509017 \nL 158.430137 105.48752 \nL 158.658433 105.562555 \nL 159.092194 105.305061 \nL 159.457467 105.494344 \nL 159.708592 105.394974 \nL 160.073865 105.582827 \nL 160.256502 105.542137 \nL 160.461968 105.596932 \nL 160.85007 105.382283 \nL 161.146854 105.512029 \nL 161.329491 105.47187 \nL 161.557786 105.544891 \nL 161.694764 105.543188 \nL 161.808911 105.52289 \nL 161.945889 105.521218 \nL 162.128525 105.556652 \nL 162.311162 105.516781 \nL 162.516628 105.570572 \nL 162.676435 105.549838 \nL 162.859071 105.584977 \nL 162.973219 105.60221 \nL 163.224344 105.692175 \nL 163.361321 105.690309 \nL 163.521128 105.706727 \nL 163.726594 105.648268 \nL 163.817912 105.609996 \nL 164.023378 105.551878 \nL 164.228844 105.604759 \nL 164.320163 105.640497 \nL 164.43431 105.620583 \nL 164.548458 105.637532 \nL 164.731095 105.67193 \nL 164.868072 105.670116 \nL 165.050708 105.704356 \nL 165.279004 105.628127 \nL 165.46164 105.662309 \nL 165.644277 105.62347 \nL 165.849743 105.675447 \nL 165.98672 105.673649 \nL 166.169357 105.707536 \nL 166.374823 105.650465 \nL 166.557459 105.684274 \nL 166.694436 105.682476 \nL 166.877073 105.716137 \nL 167.082539 105.659413 \nL 167.219516 105.657651 \nL 167.356493 105.655896 \nL 167.5163 105.671777 \nL 167.744596 105.597289 \nL 167.904403 105.613197 \nL 168.087039 105.575278 \nL 168.201187 105.556094 \nL 168.406653 105.500321 \nL 168.520801 105.48127 \nL 168.771926 105.389853 \nL 168.931733 105.405914 \nL 169.09154 105.386573 \nL 169.251347 105.402591 \nL 169.411153 105.383308 \nL 169.616619 105.434003 \nL 169.890574 105.360897 \nL 170.004722 105.342229 \nL 170.255847 105.287287 \nL 170.347165 105.251475 \nL 170.575461 105.214539 \nL 170.712438 105.213361 \nL 170.917904 105.194199 \nL 171.100541 105.227403 \nL 171.328836 105.190755 \nL 171.465813 105.154981 \nL 171.694109 105.118591 \nL 171.808257 105.065919 \nL 172.013723 105.047199 \nL 172.219189 105.062949 \nL 172.607291 104.905845 \nL 173.063882 105.10815 \nL 173.223689 105.124006 \nL 173.429155 105.139461 \nL 173.634621 105.120867 \nL 173.840087 105.136276 \nL 173.954235 105.18625 \nL 174.319508 105.318488 \nL 174.616292 105.231466 \nL 174.890247 105.296429 \nL 175.072883 105.294789 \nL 175.278349 105.309719 \nL 175.529474 105.257253 \nL 175.712111 105.255681 \nL 176.077384 105.119321 \nL 176.374168 105.200187 \nL 176.488316 105.249057 \nL 176.7851 105.329328 \nL 176.922077 105.36116 \nL 177.081884 105.343144 \nL 177.378668 105.258036 \nL 177.698282 105.353931 \nL 177.903748 105.335626 \nL 178.31468 105.495416 \nL 178.428828 105.543246 \nL 178.634294 105.557351 \nL 179.022396 105.406839 \nL 179.296351 105.46911 \nL 179.524647 105.434428 \nL 179.84426 105.528221 \nL 180.095386 105.477237 \nL 180.232363 105.44366 \nL 180.483488 105.393002 \nL 180.688954 105.407123 \nL 180.87159 105.405399 \nL 181.054227 105.40368 \nL 181.259693 105.385779 \nL 181.510818 105.431274 \nL 181.739114 105.397271 \nL 181.876091 105.364214 \nL 182.378341 105.138089 \nL 182.606637 105.16805 \nL 182.743614 105.198599 \nL 183.017569 105.259498 \nL 183.337182 105.162645 \nL 183.565478 105.192332 \nL 183.793774 105.159297 \nL 184.044899 105.20434 \nL 184.227535 105.202947 \nL 184.410172 105.201559 \nL 184.775444 105.074499 \nL 184.889592 105.02718 \nL 185.072229 105.026044 \nL 185.323354 105.070903 \nL 185.597308 105.00736 \nL 185.871263 105.067334 \nL 186.0539 105.066156 \nL 186.236536 105.064973 \nL 186.487661 105.017359 \nL 186.715957 105.046589 \nL 187.0584 104.937572 \nL 187.218207 104.921454 \nL 187.378014 104.935837 \nL 187.674798 105.010215 \nL 187.925923 104.963216 \nL 188.154219 104.992225 \nL 188.359685 104.975912 \nL 188.542321 104.974877 \nL 188.839105 104.897881 \nL 189.044571 104.91188 \nL 189.318526 104.85043 \nL 189.523992 104.86445 \nL 189.797947 104.803315 \nL 189.980583 104.802522 \nL 190.11756 104.831772 \nL 190.414345 104.904873 \nL 190.733958 104.81414 \nL 190.962254 104.842796 \nL 191.122061 104.856875 \nL 191.259038 104.826641 \nL 191.510163 104.78122 \nL 191.784118 104.839053 \nL 192.126561 104.734584 \nL 192.354857 104.763088 \nL 192.514664 104.777114 \nL 192.788618 104.834532 \nL 193.016914 104.804298 \nL 193.290869 104.861454 \nL 193.450676 104.875275 \nL 193.656142 104.888844 \nL 193.907267 104.84409 \nL 194.27254 104.958259 \nL 194.500835 104.928146 \nL 194.729131 104.95584 \nL 194.957426 104.925833 \nL 195.25421 104.996205 \nL 195.391188 105.024167 \nL 195.528165 104.994691 \nL 195.710802 104.993687 \nL 195.893438 104.992682 \nL 196.098904 104.977263 \nL 196.258711 104.962138 \nL 196.418518 104.975549 \nL 196.692472 105.031002 \nL 197.034916 104.929686 \nL 197.217552 104.928777 \nL 197.491507 104.870817 \nL 197.742632 104.912043 \nL 197.879609 104.939596 \nL 198.107905 104.966623 \nL 198.3362 104.937304 \nL 198.632985 105.005999 \nL 198.929769 104.934339 \nL 199.203724 104.988903 \nL 199.40919 104.973846 \nL 199.637485 105.000531 \nL 199.842951 104.985506 \nL 200.094076 105.02586 \nL 200.299542 105.010846 \nL 200.43652 104.982378 \nL 200.778963 104.883781 \nL 200.893111 104.841808 \nL 201.189895 104.771594 \nL 201.486679 104.839285 \nL 201.623657 104.866206 \nL 201.760634 104.838128 \nL 201.988929 104.80974 \nL 202.171566 104.809004 \nL 202.354202 104.808273 \nL 202.605327 104.848243 \nL 202.810793 104.833733 \nL 202.99343 104.832971 \nL 203.244555 104.79114 \nL 203.404362 104.77694 \nL 203.655487 104.735314 \nL 203.929442 104.788506 \nL 204.134908 104.774207 \nL 204.271885 104.746686 \nL 204.500181 104.718912 \nL 204.682817 104.718308 \nL 204.865453 104.717698 \nL 204.979601 104.676997 \nL 205.253556 104.622496 \nL 205.459022 104.635345 \nL 205.664488 104.621398 \nL 206.006931 104.713928 \nL 206.143909 104.740156 \nL 206.326545 104.739531 \nL 206.463522 104.765674 \nL 206.874454 104.896929 \nL 207.148409 104.842712 \nL 207.285386 104.81568 \nL 207.673489 104.695329 \nL 207.878955 104.707877 \nL 208.038762 104.720537 \nL 208.175739 104.693767 \nL 208.335546 104.706421 \nL 208.472523 104.679715 \nL 208.65516 104.679168 \nL 208.906285 104.717713 \nL 209.111751 104.703966 \nL 209.340046 104.729374 \nL 209.68249 104.637022 \nL 209.910785 104.66243 \nL 210.230399 104.583604 \nL 210.481524 104.621913 \nL 210.823967 104.53047 \nL 211.120752 104.594439 \nL 211.349047 104.568106 \nL 211.531684 104.567701 \nL 211.851297 104.48988 \nL 212.033934 104.48957 \nL 212.2394 104.476395 \nL 212.490525 104.514383 \nL 212.650332 104.526869 \nL 212.924287 104.577395 \nL 213.129753 104.564184 \nL 213.380878 104.60182 \nL 213.654832 104.57575 \nL 213.883128 104.575235 \nL 214.179912 104.536584 \nL 214.316889 104.485701 \nL 214.613674 104.447318 \nL 214.864799 104.459573 \nL 215.138753 104.433986 \nL 215.435538 104.47128 \nL 215.84647 104.370385 \nL 216.051936 104.357674 \nL 216.34872 104.319943 \nL 216.691163 104.382062 \nL 216.896629 104.394311 \nL 217.307561 104.493218 \nL 217.581516 104.467963 \nL 217.923959 104.529298 \nL 218.471869 104.355634 \nL 218.791482 104.404594 \nL 219.088267 104.36741 \nL 219.362221 104.391693 \nL 219.704665 104.330142 \nL 219.95579 104.342197 \nL 220.161256 104.354246 \nL 220.321063 104.317541 \nL 220.640676 104.268676 \nL 220.98312 104.329296 \nL 221.325563 104.268476 \nL 221.736495 104.365065 \nL 222.147427 104.268234 \nL 222.444211 104.304261 \nL 222.695336 104.292117 \nL 222.855143 104.256027 \nL 223.03778 104.279973 \nL 223.288905 104.291865 \nL 223.56286 104.267829 \nL 223.813985 104.2797 \nL 224.202087 104.196175 \nL 224.407553 104.184304 \nL 224.635849 104.184357 \nL 224.932633 104.22 \nL 225.138099 104.231844 \nL 225.549031 104.326362 \nL 225.777326 104.32622 \nL 226.074111 104.361385 \nL 226.348065 104.337634 \nL 226.553531 104.325742 \nL 226.781827 104.3256 \nL 227.12427 104.383938 \nL 227.375395 104.37201 \nL 227.535202 104.336819 \nL 227.740668 104.348353 \nL 228.014623 104.371447 \nL 228.242918 104.371248 \nL 228.471214 104.371048 \nL 228.813657 104.312767 \nL 229.110442 104.347338 \nL 229.293078 104.370333 \nL 229.658351 104.439259 \nL 229.886646 104.438975 \nL 230.274749 104.518983 \nL 230.503044 104.518594 \nL 230.73134 104.518205 \nL 231.028124 104.483351 \nL 231.187931 104.448796 \nL 231.439056 104.437046 \nL 231.73584 104.470891 \nL 231.986966 104.459147 \nL 232.28375 104.492856 \nL 232.512045 104.492503 \nL 232.76317 104.503454 \nL 232.991466 104.503091 \nL 233.196932 104.491452 \nL 233.402398 104.502439 \nL 233.722012 104.547041 \nL 234.018796 104.512722 \nL 234.292751 104.53476 \nL 234.589535 104.500568 \nL 234.749342 104.46668 \nL 234.977637 104.46637 \nL 235.137444 104.432583 \nL 235.434228 104.398721 \nL 235.708183 104.420759 \nL 235.959308 104.409341 \nL 236.256092 104.442392 \nL 236.735513 104.319812 \nL 237.032297 104.352863 \nL 237.351911 104.30842 \nL 237.580207 104.308309 \nL 237.785673 104.319239 \nL 238.150946 104.385063 \nL 238.402071 104.37385 \nL 238.561878 104.340777 \nL 238.744514 104.362594 \nL 238.92715 104.340535 \nL 239.47506 104.187227 \nL 239.703355 104.187269 \nL 240.022969 104.143751 \nL 240.228435 104.132952 \nL 240.47956 104.122207 \nL 240.822004 104.176618 \nL 241.095958 104.155022 \nL 241.52972 104.252415 \nL 241.758015 104.252373 \nL 241.986311 104.252337 \nL 242.214607 104.252295 \nL 242.397243 104.230756 \nL 242.785345 104.1556 \nL 243.08213 104.187858 \nL 243.287596 104.198593 \nL 243.607209 104.24137 \nL 243.926823 104.198667 \nL 244.155119 104.198688 \nL 244.337755 104.22 \nL 244.520392 104.19873 \nL 244.908494 104.124488 \nL 245.250937 104.177628 \nL 245.661869 104.093156 \nL 245.821676 104.061571 \nL 246.027142 104.072296 \nL 246.392415 104.13576 \nL 246.734859 104.083357 \nL 247.122961 104.157062 \nL 247.511063 104.083903 \nL 247.716529 104.073589 \nL 247.921995 104.084198 \nL 248.127461 104.073904 \nL 248.401416 104.053275 \nL 248.6982 104.084745 \nL 248.926496 104.084902 \nL 249.131962 104.074661 \nL 249.291769 104.105899 \nL 249.862508 104.261368 \nL 250.204951 104.209675 \nL 250.387587 104.189057 \nL 250.798519 104.106782 \nL 250.981156 104.086322 \nL 251.323599 104.035222 \nL 251.551895 104.035443 \nL 251.711702 104.066324 \nL 251.894338 104.046 \nL 252.487907 103.883239 \nL 252.761861 103.904089 \nL 253.012986 103.89431 \nL 253.286941 103.915086 \nL 253.720703 103.824485 \nL 254.040316 103.865617 \nL 254.474078 103.775468 \nL 254.725203 103.765931 \nL 255.044817 103.746511 \nL 255.38726 103.777486 \nL 255.684044 103.768108 \nL 255.980829 103.778801 \nL 256.231954 103.789367 \nL 256.528738 103.799997 \nL 256.802693 103.800576 \nL 257.053818 103.791123 \nL 257.419091 103.752073 \nL 257.738704 103.772692 \nL 257.967 103.793047 \nL 258.195295 103.773691 \nL 258.423591 103.794004 \nL 258.857353 103.864113 \nL 259.245455 103.815453 \nL 259.542239 103.825894 \nL 259.770535 103.846018 \nL 260.02166 103.83665 \nL 260.341274 103.817619 \nL 260.592399 103.808304 \nL 260.866354 103.808861 \nL 261.117479 103.799577 \nL 261.459922 103.770999 \nL 261.962172 103.869455 \nL 262.395934 103.802174 \nL 262.738377 103.831971 \nL 263.240627 103.736134 \nL 263.742878 103.833832 \nL 264.062491 103.815148 \nL 264.290787 103.796328 \nL 264.541912 103.806453 \nL 264.815867 103.807 \nL 265.226799 103.750286 \nL 265.432265 103.722024 \nL 265.751878 103.703655 \nL 266.025833 103.704318 \nL 266.368276 103.67656 \nL 266.573742 103.648508 \nL 266.847697 103.649254 \nL 267.258629 103.707325 \nL 267.464095 103.73627 \nL 267.829368 103.774973 \nL 268.080493 103.784962 \nL 268.331618 103.776025 \nL 268.719721 103.729689 \nL 268.879528 103.682942 \nL 269.221971 103.655584 \nL 269.404607 103.618469 \nL 269.747051 103.591268 \nL 270.180812 103.658097 \nL 270.523256 103.630939 \nL 270.911358 103.678663 \nL 271.436438 103.577568 \nL 271.893029 103.65325 \nL 272.281131 103.607891 \nL 272.85187 103.729741 \nL 273.194314 103.702804 \nL 273.35412 103.657046 \nL 273.696564 103.630276 \nL 274.039007 103.658801 \nL 274.335791 103.650379 \nL 274.746723 103.706463 \nL 275.180485 103.643409 \nL 275.728394 103.754397 \nL 276.002349 103.754975 \nL 276.367622 103.792154 \nL 276.687236 103.774595 \nL 277.075338 103.820742 \nL 277.372122 103.812215 \nL 277.805884 103.87632 \nL 278.102668 103.867741 \nL 278.399452 103.877235 \nL 278.673407 103.877656 \nL 278.901702 103.860002 \nL 279.221316 103.842538 \nL 279.677907 103.915055 \nL 280.088839 103.861905 \nL 280.385624 103.871316 \nL 280.56826 103.907327 \nL 280.728067 103.862915 \nL 281.138999 103.810102 \nL 281.321635 103.774816 \nL 281.892374 103.660484 \nL 282.143499 103.65223 \nL 282.668579 103.556172 \nL 283.011023 103.583688 \nL 283.330636 103.566928 \nL 283.467614 103.58496 \nL 283.467614 103.58496 \n\" clip-path=\"url(#pe69abb95a9)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 43.78125 104.22 \nL 294.88125 104.22 \n\" clip-path=\"url(#pe69abb95a9)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 201.24 \nL 43.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 294.88125 201.24 \nL 294.88125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 201.24 \nL 294.88125 201.24 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 294.88125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 182.759375 44.55625 \nL 287.88125 44.55625 \nQ 289.88125 44.55625 289.88125 42.55625 \nL 289.88125 14.2 \nQ 289.88125 12.2 287.88125 12.2 \nL 182.759375 12.2 \nQ 180.759375 12.2 180.759375 14.2 \nL 180.759375 42.55625 \nQ 180.759375 44.55625 182.759375 44.55625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 184.759375 20.298438 \nL 194.759375 20.298438 \nL 204.759375 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_15\">\n     <!-- P(coin=heads) -->\n     <g transform=\"translate(212.759375 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \nL 1259 2394 \nL 2053 2394 \nQ 2494 2394 2734 2622 \nQ 2975 2850 2975 3272 \nQ 2975 3691 2734 3919 \nQ 2494 4147 2053 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2053 4666 \nQ 2838 4666 3239 4311 \nQ 3641 3956 3641 3272 \nQ 3641 2581 3239 2228 \nQ 2838 1875 2053 1875 \nL 1259 1875 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \nL 4684 2906 \nL 4684 2381 \nL 678 2381 \nL 678 2906 \nz\nM 678 1631 \nL 4684 1631 \nL 4684 1100 \nL 678 1100 \nL 678 1631 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"390.429688\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"453.808594\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"515.332031\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"576.611328\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"640.087891\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"692.1875\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 184.759375 34.976562 \nL 194.759375 34.976562 \nL 204.759375 34.976562 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_16\">\n     <!-- P(coin=tails) -->\n     <g transform=\"translate(212.759375 38.476562) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"390.429688\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"429.638672\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"490.917969\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"518.701172\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"546.484375\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"598.583984\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe69abb95a9\">\n   <rect x=\"43.78125\" y=\"7.2\" width=\"251.1\" height=\"194.04\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "counts = Multinomial(1, fair_probs).sample((10000,))\n",
        "cum_counts = counts.cumsum(dim=0)\n",
        "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
        "estimates = estimates.numpy()\n",
        "\n",
        "d2l.set_figsize((4.5, 3.5))\n",
        "d2l.plt.plot(estimates[:, 0], label=(\"P(coin=heads)\"))\n",
        "d2l.plt.plot(estimates[:, 1], label=(\"P(coin=tails)\"))\n",
        "d2l.plt.axhline(y=0.5, color='black', linestyle='dashed')\n",
        "d2l.plt.gca().set_xlabel('Samples')\n",
        "d2l.plt.gca().set_ylabel('Estimated probability')\n",
        "d2l.plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec40585d",
      "metadata": {
        "origin_pos": 29,
        "id": "ec40585d"
      },
      "source": [
        "Each solid curve corresponds to one of the two values of the coin\n",
        "and gives our estimated probability that the coin turns up that value\n",
        "after each group of experiments.\n",
        "The dashed black line gives the true underlying probability.\n",
        "As we get more data by conducting more experiments,\n",
        "the curves converge towards the true probability.\n",
        "You might already begin to see the shape\n",
        "of some of the more advanced questions\n",
        "that preoccupy statisticians:\n",
        "How quickly does this convergence happen?\n",
        "If we had already tested many coins\n",
        "manufactured at the same plant,\n",
        "how might we incorporate this information?\n",
        "\n",
        "##  A More Formal Treatment\n",
        "\n",
        "We have already gotten pretty far: posing\n",
        "a probabilistic model,\n",
        "generating synthetic data,\n",
        "running a statistical estimator,\n",
        "empirically assessing convergence,\n",
        "and reporting error metrics (checking the deviation).\n",
        "However, to go much further,\n",
        "we will need to be more precise.\n",
        "\n",
        "\n",
        "When dealing with randomness,\n",
        "we denote the set of possible outcomes $\\mathcal{S}$\n",
        "and call it the *sample space* or *outcome space*.\n",
        "Here, each element is a distinct possible *outcome*.\n",
        "In the case of rolling a single coin,\n",
        "$\\mathcal{S} = \\{\\textrm{heads}, \\textrm{tails}\\}$.\n",
        "For a single die, $\\mathcal{S} = \\{1, 2, 3, 4, 5, 6\\}$.\n",
        "When flipping two coins, possible outcomes are\n",
        "$\\{(\\textrm{heads}, \\textrm{heads}), (\\textrm{heads}, \\textrm{tails}), (\\textrm{tails}, \\textrm{heads}),  (\\textrm{tails}, \\textrm{tails})\\}$.\n",
        "*Events* are subsets of the sample space.\n",
        "For instance, the event \"the first coin toss comes up heads\"\n",
        "corresponds to the set $\\{(\\textrm{heads}, \\textrm{heads}), (\\textrm{heads}, \\textrm{tails})\\}$.\n",
        "Whenever the outcome $z$ of a random experiment satisfies\n",
        "$z \\in \\mathcal{A}$, then event $\\mathcal{A}$ has occurred.\n",
        "For a single roll of a die, we could define the events\n",
        "\"seeing a $5$\" ($\\mathcal{A} = \\{5\\}$)\n",
        "and \"seeing an odd number\"  ($\\mathcal{B} = \\{1, 3, 5\\}$).\n",
        "In this case, if the die came up $5$,\n",
        "we would say that both $\\mathcal{A}$ and $\\mathcal{B}$ occurred.\n",
        "On the other hand, if $z = 3$,\n",
        "then $\\mathcal{A}$ did not occur\n",
        "but $\\mathcal{B}$ did.\n",
        "\n",
        "\n",
        "A *probability* function maps events\n",
        "onto real values ${P: \\mathcal{A} \\subseteq \\mathcal{S} \\rightarrow [0,1]}$.\n",
        "The probability, denoted $P(\\mathcal{A})$, of an event $\\mathcal{A}$\n",
        "in the given sample space $\\mathcal{S}$,\n",
        "has the following properties:\n",
        "\n",
        "* The probability of any event $\\mathcal{A}$ is a nonnegative real number, i.e., $P(\\mathcal{A}) \\geq 0$;\n",
        "* The probability of the entire sample space is $1$, i.e., $P(\\mathcal{S}) = 1$;\n",
        "* For any countable sequence of events $\\mathcal{A}_1, \\mathcal{A}_2, \\ldots$ that are *mutually exclusive* (i.e., $\\mathcal{A}_i \\cap \\mathcal{A}_j = \\emptyset$ for all $i \\neq j$), the probability that any of them happens is equal to the sum of their individual probabilities, i.e., $P(\\bigcup_{i=1}^{\\infty} \\mathcal{A}_i) = \\sum_{i=1}^{\\infty} P(\\mathcal{A}_i)$.\n",
        "\n",
        "These axioms of probability theory,\n",
        "proposed by :citet:`Kolmogorov.1933`,\n",
        "can be applied to rapidly derive a number of important consequences.\n",
        "For instance, it follows immediately\n",
        "that the probability of any event $\\mathcal{A}$\n",
        "*or* its complement $\\mathcal{A}'$ occurring is 1\n",
        "(because $\\mathcal{A} \\cup \\mathcal{A}' = \\mathcal{S}$).\n",
        "We can also prove that $P(\\emptyset) = 0$\n",
        "because $1 = P(\\mathcal{S} \\cup \\mathcal{S}') = P(\\mathcal{S} \\cup \\emptyset) = P(\\mathcal{S}) + P(\\emptyset) = 1 + P(\\emptyset)$.\n",
        "Consequently, the probability of any event $\\mathcal{A}$\n",
        "*and* its complement $\\mathcal{A}'$ occurring simultaneously\n",
        "is $P(\\mathcal{A} \\cap \\mathcal{A}') = 0$.\n",
        "Informally, this tells us that impossible events\n",
        "have zero probability of occurring.\n",
        "\n",
        "\n",
        "\n",
        "## Random Variables\n",
        "\n",
        "When we spoke about events like the roll of a die\n",
        "coming up odds or the first coin toss coming up heads,\n",
        "we were invoking the idea of a *random variable*.\n",
        "Formally, random variables are mappings\n",
        "from an underlying sample space\n",
        "to a set of (possibly many) values.\n",
        "You might wonder how a random variable\n",
        "is different from the sample space,\n",
        "since both are collections of outcomes.\n",
        "Importantly, random variables can be much coarser\n",
        "than the raw sample space.\n",
        "We can define a binary random variable like \"greater than 0.5\"\n",
        "even when the underlying sample space is infinite,\n",
        "e.g., points on the line segment between $0$ and $1$.\n",
        "Additionally, multiple random variables\n",
        "can share the same underlying sample space.\n",
        "For example \"whether my home alarm goes off\"\n",
        "and \"whether my house was burgled\"\n",
        "are both binary random variables\n",
        "that share an underlying sample space.\n",
        "Consequently, knowing the value taken by one random variable\n",
        "can tell us something about the likely value of another random variable.\n",
        "Knowing that the alarm went off,\n",
        "we might suspect that the house was likely burgled.\n",
        "\n",
        "\n",
        "Every value taken by a random variable corresponds\n",
        "to a subset of the underlying sample space.\n",
        "Thus the occurrence where the random variable $X$\n",
        "takes value $v$, denoted by $X=v$, is an *event*\n",
        "and $P(X=v)$ denotes its probability.\n",
        "Sometimes this notation can get clunky,\n",
        "and we can abuse notation when the context is clear.\n",
        "For example, we might use $P(X)$ to refer broadly\n",
        "to the *distribution* of $X$, i.e.,\n",
        "the function that tells us the probability\n",
        "that $X$ takes any given value.\n",
        "Other times we write expressions\n",
        "like $P(X,Y) = P(X) P(Y)$,\n",
        "as a shorthand to express a statement\n",
        "that is true for all of the values\n",
        "that the random variables $X$ and $Y$ can take, i.e.,\n",
        "for all $i,j$ it holds that $P(X=i \\textrm{ and } Y=j) = P(X=i)P(Y=j)$.\n",
        "Other times, we abuse notation by writing\n",
        "$P(v)$ when the random variable is clear from the context.\n",
        "Since an event in probability theory is a set of outcomes from the sample space,\n",
        "we can specify a range of values for a random variable to take.\n",
        "For example, $P(1 \\leq X \\leq 3)$ denotes the probability of the event $\\{1 \\leq X \\leq 3\\}$.\n",
        "\n",
        "\n",
        "Note that there is a subtle difference\n",
        "between *discrete* random variables,\n",
        "like flips of a coin or tosses of a die,\n",
        "and *continuous* ones,\n",
        "like the weight and the height of a person\n",
        "sampled at random from the population.\n",
        "In this case we seldom really care about\n",
        "someone's exact height.\n",
        "Moreover, if we took precise enough measurements,\n",
        "we would find that no two people on the planet\n",
        "have the exact same height.\n",
        "In fact, with fine enough measurements,\n",
        "you would never have the same height\n",
        "when you wake up and when you go to sleep.\n",
        "There is little point in asking about\n",
        "the exact probability that someone\n",
        "is 1.801392782910287192 meters tall.\n",
        "Instead, we typically care more about being able to say\n",
        "whether someone's height falls into a given interval,\n",
        "say between 1.79 and 1.81 meters.\n",
        "In these cases we work with probability *densities*.\n",
        "The height of exactly 1.80 meters\n",
        "has no probability, but nonzero density.\n",
        "To work out the probability assigned to an interval,\n",
        "we must take an *integral* of the density\n",
        "over that interval.\n",
        "\n",
        "## Multiple Random Variables\n",
        "\n",
        "You might have noticed that we could not even\n",
        "make it through the previous section without\n",
        "making statements involving interactions\n",
        "among multiple random variables\n",
        "(recall $P(X,Y) = P(X) P(Y)$).\n",
        "Most of machine learning\n",
        "is concerned with such relationships.\n",
        "Here, the sample space would be\n",
        "the population of interest,\n",
        "say customers who transact with a business,\n",
        "photographs on the Internet,\n",
        "or proteins known to biologists.\n",
        "Each random variable would represent\n",
        "the (unknown) value of a different attribute.\n",
        "Whenever we sample an individual from the population,\n",
        "we observe a realization of each of the random variables.\n",
        "Because the values taken by random variables\n",
        "correspond to subsets of the sample space\n",
        "that could be overlapping, partially overlapping,\n",
        "or entirely disjoint,\n",
        "knowing the value taken by one random variable\n",
        "can cause us to update our beliefs\n",
        "about which values of another random variable are likely.\n",
        "If a patient walks into a hospital\n",
        "and we observe that they\n",
        "are having trouble breathing\n",
        "and have lost their sense of smell,\n",
        "then we believe that they are more likely\n",
        "to have COVID-19 than we might\n",
        "if they had no trouble breathing\n",
        "and a perfectly ordinary sense of smell.\n",
        "\n",
        "\n",
        "When working with multiple random variables,\n",
        "we can construct events corresponding\n",
        "to every combination of values\n",
        "that the variables can jointly take.\n",
        "The probability function that assigns\n",
        "probabilities to each of these combinations\n",
        "(e.g. $A=a$ and $B=b$)\n",
        "is called the *joint probability* function\n",
        "and simply returns the probability assigned\n",
        "to the intersection of the corresponding subsets\n",
        "of the sample space.\n",
        "The *joint probability* assigned to the event\n",
        "where random variables $A$ and $B$\n",
        "take values $a$ and $b$, respectively,\n",
        "is denoted $P(A = a, B = b)$,\n",
        "where the comma indicates \"and\".\n",
        "Note that for any values $a$ and $b$,\n",
        "it follows that\n",
        "\n",
        "$$P(A=a, B=b) \\leq P(A=a) \\textrm{ and } P(A=a, B=b) \\leq P(B = b),$$\n",
        "\n",
        "since for $A=a$ and $B=b$ to happen,\n",
        "$A=a$ has to happen *and* $B=b$ also has to happen.\n",
        "Interestingly, the joint probability\n",
        "tells us all that we can know about these\n",
        "random variables in a probabilistic sense,\n",
        "and can be used to derive many other\n",
        "useful quantities, including recovering the\n",
        "individual distributions $P(A)$ and $P(B)$.\n",
        "To recover $P(A=a)$ we simply sum up\n",
        "$P(A=a, B=v)$ over all values $v$\n",
        "that the random variable $B$ can take:\n",
        "$P(A=a) = \\sum_v P(A=a, B=v)$.\n",
        "\n",
        "\n",
        "The ratio $\\frac{P(A=a, B=b)}{P(A=a)} \\leq 1$\n",
        "turns out to be extremely important.\n",
        "It is called the *conditional probability*,\n",
        "and is denoted via the \"$\\mid$\" symbol:\n",
        "\n",
        "$$P(B=b \\mid A=a) = P(A=a,B=b)/P(A=a).$$\n",
        "\n",
        "It tells us the new probability\n",
        "associated with the event $B=b$,\n",
        "once we condition on the fact $A=a$ took place.\n",
        "We can think of this conditional probability\n",
        "as restricting attention only to the subset\n",
        "of the sample space associated with $A=a$\n",
        "and then renormalizing so that\n",
        "all probabilities sum to 1.\n",
        "Conditional probabilities\n",
        "are in fact just ordinary probabilities\n",
        "and thus respect all of the axioms,\n",
        "as long as we condition all terms\n",
        "on the same event and thus\n",
        "restrict attention to the same sample space.\n",
        "For instance, for disjoint events\n",
        "$\\mathcal{B}$ and $\\mathcal{B}'$, we have that\n",
        "$P(\\mathcal{B} \\cup \\mathcal{B}' \\mid A = a) = P(\\mathcal{B} \\mid A = a) + P(\\mathcal{B}' \\mid A = a)$.\n",
        "\n",
        "\n",
        "Using the definition of conditional probabilities,\n",
        "we can derive the famous result called *Bayes' theorem*.\n",
        "By construction, we have that $P(A, B) = P(B\\mid A) P(A)$\n",
        "and $P(A, B) = P(A\\mid B) P(B)$.\n",
        "Combining both equations yields\n",
        "$P(B\\mid A) P(A) = P(A\\mid B) P(B)$ and hence\n",
        "\n",
        "$$P(A \\mid B) = \\frac{P(B\\mid A) P(A)}{P(B)}.$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This simple equation has profound implications because\n",
        "it allows us to reverse the order of conditioning.\n",
        "If we know how to estimate $P(B\\mid A)$, $P(A)$, and $P(B)$,\n",
        "then we can estimate $P(A\\mid B)$.\n",
        "We often find it easier to estimate one term directly\n",
        "but not the other and Bayes' theorem can come to the rescue here.\n",
        "For instance, if we know the prevalence of symptoms for a given disease,\n",
        "and the overall prevalences of the disease and symptoms, respectively,\n",
        "we can determine how likely someone is\n",
        "to have the disease based on their symptoms.\n",
        "In some cases we might not have direct access to $P(B)$,\n",
        "such as the prevalence of symptoms.\n",
        "In this case a simplified version of Bayes' theorem comes in handy:\n",
        "\n",
        "$$P(A \\mid B) \\propto P(B \\mid A) P(A).$$\n",
        "\n",
        "Since we know that $P(A \\mid B)$ must be normalized to $1$, i.e., $\\sum_a P(A=a \\mid B) = 1$,\n",
        "we can use it to compute\n",
        "\n",
        "$$P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{\\sum_a P(B \\mid A=a) P(A = a)}.$$\n",
        "\n",
        "In Bayesian statistics, we think of an observer\n",
        "as possessing some (subjective) prior beliefs\n",
        "about the plausibility of the available hypotheses\n",
        "encoded in the *prior* $P(H)$,\n",
        "and a *likelihood function* that says how likely\n",
        "one is to observe any value of the collected evidence\n",
        "for each of the hypotheses in the class $P(E \\mid H)$.\n",
        "Bayes' theorem is then interpreted as telling us\n",
        "how to update the initial *prior* $P(H)$\n",
        "in light of the available evidence $E$\n",
        "to produce *posterior* beliefs\n",
        "$P(H \\mid E) = \\frac{P(E \\mid H) P(H)}{P(E)}$.\n",
        "Informally, this can be stated as\n",
        "\"posterior equals prior times likelihood, divided by the evidence\".\n",
        "Now, because the evidence $P(E)$ is the same for all hypotheses,\n",
        "we can get away with simply normalizing over the hypotheses.\n",
        "\n",
        "Note that $\\sum_a P(A=a \\mid B) = 1$ also allows us to *marginalize* over random variables. That is, we can drop variables from a joint distribution such as $P(A, B)$. After all, we have that\n",
        "\n",
        "$$\\sum_a P(B \\mid A=a) P(A=a) = \\sum_a P(B, A=a) = P(B).$$\n",
        "\n",
        "Independence is another fundamentally important concept\n",
        "that forms the backbone of\n",
        "many important ideas in statistics.\n",
        "In short, two variables are *independent*\n",
        "if conditioning on the value of $A$ does not\n",
        "cause any change to the probability distribution\n",
        "associated with $B$ and vice versa.\n",
        "More formally, independence, denoted $A \\perp B$,\n",
        "requires that $P(A \\mid B) = P(A)$ and, consequently,\n",
        "that $P(A,B) = P(A \\mid B) P(B) = P(A) P(B)$.\n",
        "Independence is often an appropriate assumption.\n",
        "For example, if the random variable $A$\n",
        "represents the outcome from tossing one fair coin\n",
        "and the random variable $B$\n",
        "represents the outcome from tossing another,\n",
        "then knowing whether $A$ came up heads\n",
        "should not influence the probability\n",
        "of $B$ coming up heads.\n",
        "\n",
        "\n",
        "Independence is especially useful when it holds among the successive\n",
        "draws of our data from some underlying distribution\n",
        "(allowing us to make strong statistical conclusions)\n",
        "or when it holds among various variables in our data,\n",
        "allowing us to work with simpler models\n",
        "that encode this independence structure.\n",
        "On the other hand, estimating the dependencies\n",
        "among random variables is often the very aim of learning.\n",
        "We care to estimate the probability of disease given symptoms\n",
        "specifically because we believe\n",
        "that diseases and symptoms are *not* independent.\n",
        "\n",
        "\n",
        "Note that because conditional probabilities are proper probabilities,\n",
        "the concepts of independence and dependence also apply to them.\n",
        "Two random variables $A$ and $B$ are *conditionally independent*\n",
        "given a third variable $C$ if and only if $P(A, B \\mid C) = P(A \\mid C)P(B \\mid C)$.\n",
        "Interestingly, two variables can be independent in general\n",
        "but become dependent when conditioning on a third.\n",
        "This often occurs when the two random variables $A$ and $B$\n",
        "correspond to causes of some third variable $C$.\n",
        "For example, broken bones and lung cancer might be independent\n",
        "in the general population but if we condition on being in the hospital\n",
        "then we might find that broken bones are negatively correlated with lung cancer.\n",
        "That is because the broken bone *explains away* why some person is in the hospital\n",
        "and thus lowers the probability that they are hospitalized because of having lung cancer.\n",
        "\n",
        "\n",
        "And conversely, two dependent random variables\n",
        "can become independent upon conditioning on a third.\n",
        "This often happens when two otherwise unrelated events\n",
        "have a common cause.\n",
        "Shoe size and reading level are highly correlated\n",
        "among elementary school students,\n",
        "but this correlation disappears if we condition on age.\n",
        "\n",
        "\n",
        "\n",
        "## An Example\n",
        ":label:`subsec_probability_hiv_app`\n",
        "\n",
        "Let's put our skills to the test.\n",
        "Assume that a doctor administers an HIV test to a patient.\n",
        "This test is fairly accurate and fails only with 1% probability\n",
        "if the patient is healthy but reported as diseased,\n",
        "i.e., healthy patients test positive in 1% of cases.\n",
        "Moreover, it never fails to detect HIV if the patient actually has it.\n",
        "We use $D_1 \\in \\{0, 1\\}$ to indicate the diagnosis\n",
        "($0$ if negative and $1$ if positive)\n",
        "and $H \\in \\{0, 1\\}$ to denote the HIV status.\n",
        "\n",
        "| Conditional probability | $H=1$ | $H=0$ |\n",
        "|:------------------------|------:|------:|\n",
        "| $P(D_1 = 1 \\mid H)$        |     1 |  0.01 |\n",
        "| $P(D_1 = 0 \\mid H)$        |     0 |  0.99 |\n",
        "\n",
        "Note that the column sums are all 1 (but the row sums do not),\n",
        "since they are conditional probabilities.\n",
        "Let's compute the probability of the patient having HIV\n",
        "if the test comes back positive, i.e., $P(H = 1 \\mid D_1 = 1)$.\n",
        "Intuitively this is going to depend on how common the disease is,\n",
        "since it affects the number of false alarms.\n",
        "Assume that the population is fairly free of the disease, e.g., $P(H=1) = 0.0015$.\n",
        "To apply Bayes' theorem, we need to apply marginalization\n",
        "to determine\n",
        "\n",
        "$$\\begin{aligned}\n",
        "P(D_1 = 1)\n",
        "=& P(D_1=1, H=0) + P(D_1=1, H=1)  \\\\\n",
        "=& P(D_1=1 \\mid H=0) P(H=0) + P(D_1=1 \\mid H=1) P(H=1) \\\\\n",
        "=& 0.011485.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This leads us to\n",
        "\n",
        "$$P(H = 1 \\mid D_1 = 1) = \\frac{P(D_1=1 \\mid H=1) P(H=1)}{P(D_1=1)} = 0.1306.$$\n",
        "\n",
        "In other words, there is only a 13.06% chance\n",
        "that the patient actually has HIV,\n",
        "despite the test being pretty accurate.\n",
        "As we can see, probability can be counterintuitive.\n",
        "What should a patient do upon receiving such terrifying news?\n",
        "Likely, the patient would ask the physician\n",
        "to administer another test to get clarity.\n",
        "The second test has different characteristics\n",
        "and it is not as good as the first one.\n",
        "\n",
        "| Conditional probability | $H=1$ | $H=0$ |\n",
        "|:------------------------|------:|------:|\n",
        "| $P(D_2 = 1 \\mid H)$          |  0.98 |  0.03 |\n",
        "| $P(D_2 = 0 \\mid H)$          |  0.02 |  0.97 |\n",
        "\n",
        "Unfortunately, the second test comes back positive, too.\n",
        "Let's calculate the requisite probabilities to invoke Bayes' theorem\n",
        "by assuming conditional independence:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "P(D_1 = 1, D_2 = 1 \\mid H = 0)\n",
        "& = P(D_1 = 1 \\mid H = 0) P(D_2 = 1 \\mid H = 0)\n",
        "=& 0.0003, \\\\\n",
        "P(D_1 = 1, D_2 = 1 \\mid H = 1)\n",
        "& = P(D_1 = 1 \\mid H = 1) P(D_2 = 1 \\mid H = 1)\n",
        "=& 0.98.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Now we can apply marginalization to obtain the probability\n",
        "that both tests come back positive:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "&P(D_1 = 1, D_2 = 1)\\\\\n",
        "&= P(D_1 = 1, D_2 = 1, H = 0) + P(D_1 = 1, D_2 = 1, H = 1)  \\\\\n",
        "&= P(D_1 = 1, D_2 = 1 \\mid H = 0)P(H=0) + P(D_1 = 1, D_2 = 1 \\mid H = 1)P(H=1)\\\\\n",
        "&= 0.00176955.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Finally, the probability of the patient having HIV given that both tests are positive is\n",
        "\n",
        "$$P(H = 1 \\mid D_1 = 1, D_2 = 1)\n",
        "= \\frac{P(D_1 = 1, D_2 = 1 \\mid H=1) P(H=1)}{P(D_1 = 1, D_2 = 1)}\n",
        "= 0.8307.$$\n",
        "\n",
        "That is, the second test allowed us to gain much higher confidence that not all is well.\n",
        "Despite the second test being considerably less accurate than the first one,\n",
        "it still significantly improved our estimate.\n",
        "The assumption of both tests being conditionally independent of each other\n",
        "was crucial for our ability to generate a more accurate estimate.\n",
        "Take the extreme case where we run the same test twice.\n",
        "In this situation we would expect the same outcome both times,\n",
        "hence no additional insight is gained from running the same test again.\n",
        "The astute reader might have noticed that the diagnosis behaved\n",
        "like a classifier hiding in plain sight\n",
        "where our ability to decide whether a patient is healthy\n",
        "increases as we obtain more features (test outcomes).\n",
        "\n",
        "\n",
        "## Expectations\n",
        "\n",
        "Often, making decisions requires not just looking\n",
        "at the probabilities assigned to individual events\n",
        "but composing them together into useful aggregates\n",
        "that can provide us with guidance.\n",
        "For example, when random variables take continuous scalar values,\n",
        "we often care about knowing what value to expect *on average*.\n",
        "This quantity is formally called an *expectation*.\n",
        "If we are making investments,\n",
        "the first quantity of interest\n",
        "might be the return we can expect,\n",
        "averaging over all the possible outcomes\n",
        "(and weighting by the appropriate probabilities).\n",
        "For instance, say that with 50% probability,\n",
        "an investment might fail altogether,\n",
        "with 40% probability it might provide a 2$\\times$ return,\n",
        "and with 10% probability it might provide a 10$\\times$ return 10$\\times$.\n",
        "To calculate the expected return,\n",
        "we sum over all returns, multiplying each\n",
        "by the probability that they will occur.\n",
        "This yields the expectation\n",
        "$0.5 \\cdot 0 + 0.4 \\cdot 2 + 0.1 \\cdot 10 = 1.8$.\n",
        "Hence the expected return is 1.8$\\times$.\n",
        "\n",
        "\n",
        "In general, the *expectation* (or average)\n",
        "of the random variable $X$ is defined as\n",
        "\n",
        "$$E[X] = E_{x \\sim P}[x] = \\sum_{x} x P(X = x).$$\n",
        "\n",
        "Likewise, for densities we obtain $E[X] = \\int x \\;dp(x)$.\n",
        "Sometimes we are interested in the expected value\n",
        "of some function of $x$.\n",
        "We can calculate these expectations as\n",
        "\n",
        "$$E_{x \\sim P}[f(x)] = \\sum_x f(x) P(x) \\textrm{ and } E_{x \\sim P}[f(x)] = \\int f(x) p(x) \\;dx$$\n",
        "\n",
        "for discrete probabilities and densities, respectively.\n",
        "Returning to the investment example from above,\n",
        "$f$ might be the *utility* (happiness)\n",
        "associated with the return.\n",
        "Behavior economists have long noted\n",
        "that people associate greater disutility\n",
        "with losing money than the utility gained\n",
        "from earning one dollar relative to their baseline.\n",
        "Moreover, the value of money tends to be sub-linear.\n",
        "Possessing 100k dollars versus zero dollars\n",
        "can make the difference between paying the rent,\n",
        "eating well, and enjoying quality healthcare\n",
        "versus suffering through homelessness.\n",
        "On the other hand, the gains due to possessing\n",
        "200k versus 100k are less dramatic.\n",
        "Reasoning like this motivates the clich\n",
        "that \"the utility of money is logarithmic\".\n",
        "\n",
        "\n",
        "If  the utility associated with a total loss were $-1$,\n",
        "and the utilities associated with returns of $1$, $2$, and $10$\n",
        "were $1$, $2$ and $4$, respectively,\n",
        "then the expected happiness of investing\n",
        "would be $0.5 \\cdot (-1) + 0.4 \\cdot 2 + 0.1 \\cdot 4 = 0.7$\n",
        "(an expected loss of utility of 30%).\n",
        "If indeed this were your utility function,\n",
        "you might be best off keeping the money in the bank.\n",
        "\n",
        "For financial decisions,\n",
        "we might also want to measure\n",
        "how *risky* an investment is.\n",
        "Here, we care not just about the expected value\n",
        "but how much the actual values tend to *vary*\n",
        "relative to this value.\n",
        "Note that we cannot just take\n",
        "the expectation of the difference\n",
        "between the actual and expected values.\n",
        "This is because the expectation of a difference\n",
        "is the difference of the expectations,\n",
        "i.e., $E[X - E[X]] = E[X] - E[E[X]] = 0$.\n",
        "However, we can look at the expectation\n",
        "of any non-negative function of this difference.\n",
        "The *variance* of a random variable is calculated by looking\n",
        "at the expected value of the *squared* differences:\n",
        "\n",
        "$$\\textrm{Var}[X] = E\\left[(X - E[X])^2\\right] = E[X^2] - E[X]^2.$$\n",
        "\n",
        "Here the equality follows by expanding\n",
        "$(X - E[X])^2 = X^2 - 2 X E[X] + E[X]^2$\n",
        "and taking expectations for each term.\n",
        "The square root of the variance is another\n",
        "useful quantity called the *standard deviation*.\n",
        "While this and the variance\n",
        "convey the same information (either can be calculated from the other),\n",
        "the standard deviation has the nice property\n",
        "that it is expressed in the same units\n",
        "as the original quantity represented\n",
        "by the random variable.\n",
        "\n",
        "Lastly, the variance of a function\n",
        "of a random variable\n",
        "is defined analogously as\n",
        "\n",
        "$$\\textrm{Var}_{x \\sim P}[f(x)] = E_{x \\sim P}[f^2(x)] - E_{x \\sim P}[f(x)]^2.$$\n",
        "\n",
        "Returning to our investment example,\n",
        "we can now compute the variance of the investment.\n",
        "It is given by $0.5 \\cdot 0 + 0.4 \\cdot 2^2 + 0.1 \\cdot 10^2 - 1.8^2 = 8.36$.\n",
        "For all intents and purposes this is a risky investment.\n",
        "Note that by mathematical convention mean and variance\n",
        "are often referenced as $\\mu$ and $\\sigma^2$.\n",
        "This is particularly the case whenever we use it\n",
        "to parametrize a Gaussian distribution.\n",
        "\n",
        "In the same way as we introduced expectations\n",
        "and variance for *scalar* random variables,\n",
        "we can do so for vector-valued ones.\n",
        "Expectations are easy, since we can apply them elementwise.\n",
        "For instance, $\\boldsymbol{\\mu} \\stackrel{\\textrm{def}}{=} E_{\\mathbf{x} \\sim P}[\\mathbf{x}]$\n",
        "has coordinates $\\mu_i = E_{\\mathbf{x} \\sim P}[x_i]$.\n",
        "*Covariances* are more complicated.\n",
        "We define them by taking expectations of the *outer product*\n",
        "of the difference between random variables and their mean:\n",
        "\n",
        "$$\\boldsymbol{\\Sigma} \\stackrel{\\textrm{def}}{=} \\textrm{Cov}_{\\mathbf{x} \\sim P}[\\mathbf{x}] = E_{\\mathbf{x} \\sim P}\\left[(\\mathbf{x} - \\boldsymbol{\\mu}) (\\mathbf{x} - \\boldsymbol{\\mu})^\\top\\right].$$\n",
        "\n",
        "This matrix $\\boldsymbol{\\Sigma}$ is referred to as the covariance matrix.\n",
        "An easy way to see its effect is to consider some vector $\\mathbf{v}$\n",
        "of the same size as $\\mathbf{x}$.\n",
        "It follows that\n",
        "\n",
        "$$\\mathbf{v}^\\top \\boldsymbol{\\Sigma} \\mathbf{v} = E_{\\mathbf{x} \\sim P}\\left[\\mathbf{v}^\\top(\\mathbf{x} - \\boldsymbol{\\mu}) (\\mathbf{x} - \\boldsymbol{\\mu})^\\top \\mathbf{v}\\right] = \\textrm{Var}_{x \\sim P}[\\mathbf{v}^\\top \\mathbf{x}].$$\n",
        "\n",
        "As such, $\\boldsymbol{\\Sigma}$ allows us to compute the variance\n",
        "for any linear function of $\\mathbf{x}$\n",
        "by a simple matrix multiplication.\n",
        "The off-diagonal elements tell us how correlated the coordinates are:\n",
        "a value of 0 means no correlation,\n",
        "where a larger positive value\n",
        "means that they are more strongly correlated.\n",
        "\n",
        "\n",
        "\n",
        "## Discussion\n",
        "\n",
        "In machine learning, there are many things to be uncertain about!\n",
        "We can be uncertain about the value of a label given an input.\n",
        "We can be uncertain about the estimated value of a parameter.\n",
        "We can even be uncertain about whether data arriving at deployment\n",
        "is even from the same distribution as the training data.\n",
        "\n",
        "By *aleatoric uncertainty*, we mean uncertainty\n",
        "that is intrinsic to the problem,\n",
        "and due to genuine randomness\n",
        "unaccounted for by the observed variables.\n",
        "By *epistemic uncertainty*, we mean uncertainty\n",
        "over a model's parameters, the sort of uncertainty\n",
        "that we can hope to reduce by collecting more data.\n",
        "We might have epistemic uncertainty\n",
        "concerning the probability\n",
        "that a coin turns up heads,\n",
        "but even once we know this probability,\n",
        "we are left with aleatoric uncertainty\n",
        "about the outcome of any future toss.\n",
        "No matter how long we watch someone tossing a fair coin,\n",
        "we will never be more or less than 50% certain\n",
        "that the next toss will come up heads.\n",
        "These terms come from mechanical modeling,\n",
        "(see e.g., :citet:`Der-Kiureghian.Ditlevsen.2009` for a review on this aspect of [uncertainty quantification](https://en.wikipedia.org/wiki/Uncertainty_quantification)).\n",
        "It is worth noting, however, that these terms constitute a slight abuse of language.\n",
        "The term *epistemic* refers to anything concerning *knowledge*\n",
        "and thus, in the philosophical sense, all uncertainty is epistemic.\n",
        "\n",
        "\n",
        "We saw that sampling data from some unknown probability distribution\n",
        "can provide us with information that can be used to estimate\n",
        "the parameters of the data generating distribution.\n",
        "That said, the rate at which this is possible can be quite slow.\n",
        "In our coin tossing example (and many others)\n",
        "we can do no better than to design estimators\n",
        "that converge at a rate of $1/\\sqrt{n}$,\n",
        "where $n$ is the sample size (e.g., the number of tosses).\n",
        "This means that by going from 10 to 1000 observations (usually a very achievable task)\n",
        "we see a tenfold reduction of uncertainty,\n",
        "whereas the next 1000 observations help comparatively little,\n",
        "offering only a 1.41 times reduction.\n",
        "This is a persistent feature of machine learning:\n",
        "while there are often easy gains, it takes a very large amount of data,\n",
        "and often with it an enormous amount of computation, to make further gains.\n",
        "For an empirical review of this fact for large scale language models see :citet:`Revels.Lubin.Papamarkou.2016`.\n",
        "\n",
        "We also sharpened our language and tools for statistical modeling.\n",
        "In the process of that we learned about conditional probabilities\n",
        "and about one of the most important equations in statistics---Bayes' theorem.\n",
        "It is an effective tool for decoupling information conveyed by data\n",
        "through a likelihood term $P(B \\mid A)$ that addresses\n",
        "how well observations $B$ match a choice of parameters $A$,\n",
        "and a prior probability $P(A)$ which governs how plausible\n",
        "a particular choice of $A$ was in the first place.\n",
        "In particular, we saw how this rule can be applied\n",
        "to assign probabilities to diagnoses,\n",
        "based on the efficacy of the test *and*\n",
        "the prevalence of the disease itself (i.e., our prior).\n",
        "\n",
        "Lastly, we introduced a first set of nontrivial questions\n",
        "about the effect of a specific probability distribution,\n",
        "namely expectations and variances.\n",
        "While there are many more than just linear and quadratic\n",
        "expectations for a probability distribution,\n",
        "these two already provide a good deal of knowledge\n",
        "about the possible behavior of the distribution.\n",
        "For instance, [Chebyshev's inequality](https://en.wikipedia.org/wiki/Chebyshev%27s_inequality)\n",
        "states that $P(|X - \\mu| \\geq k \\sigma) \\leq 1/k^2$,\n",
        "where $\\mu$ is the expectation, $\\sigma^2$ is the variance of the distribution,\n",
        "and $k > 1$ is a confidence parameter of our choosing.\n",
        "It tells us that draws from a distribution lie\n",
        "with at least 50% probability\n",
        "within a $[-\\sqrt{2} \\sigma, \\sqrt{2} \\sigma]$\n",
        "interval centered on the expectation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Give an example where observing more data can reduce the amount of uncertainty about the outcome to an arbitrarily low level.\n",
        "1. Give an example where observing more data will only reduce the amount of uncertainty up to a point and then no further. Explain why this is the case and where you expect this point to occur.\n",
        "1. We empirically demonstrated convergence to the mean for the toss of a coin. Calculate the variance of the estimate of the probability that we see a head after drawing $n$ samples.\n",
        "    1. How does the variance scale with the number of observations?\n",
        "    1. Use Chebyshev's inequality to bound the deviation from the expectation.\n",
        "    1. How does it relate to the central limit theorem?\n",
        "1. Assume that we draw $m$ samples $x_i$ from a probability distribution with zero mean and unit variance. Compute the averages $z_m \\stackrel{\\textrm{def}}{=} m^{-1} \\sum_{i=1}^m x_i$. Can we apply Chebyshev's inequality for every $z_m$ independently? Why not?\n",
        "1. Given two events with probability $P(\\mathcal{A})$ and $P(\\mathcal{B})$, compute upper and lower bounds on $P(\\mathcal{A} \\cup \\mathcal{B})$ and $P(\\mathcal{A} \\cap \\mathcal{B})$. Hint: graph the situation using a [Venn diagram](https://en.wikipedia.org/wiki/Venn_diagram).\n",
        "1. Assume that we have a sequence of random variables, say $A$, $B$, and $C$, where $B$ only depends on $A$, and $C$ only depends on $B$, can you simplify the joint probability $P(A, B, C)$? Hint: this is a [Markov chain](https://en.wikipedia.org/wiki/Markov_chain).\n",
        "1. In :numref:`subsec_probability_hiv_app`, assume that the outcomes of the two tests are not independent. In particular assume that either test on its own has a false positive rate of 10% and a false negative rate of 1%. That is, assume that $P(D =1 \\mid H=0) = 0.1$ and that $P(D = 0 \\mid H=1) = 0.01$. Moreover, assume that for $H = 1$ (infected) the test outcomes are conditionally independent, i.e., that $P(D_1, D_2 \\mid H=1) = P(D_1 \\mid H=1) P(D_2 \\mid H=1)$ but that for healthy patients the outcomes are coupled via $P(D_1 = D_2 = 1 \\mid H=0) = 0.02$.\n",
        "    1. Work out the joint probability table for $D_1$ and $D_2$, given $H=0$ based on the information you have so far.\n",
        "    1. Derive the probability that the patient is diseased ($H=1$) after one test returns positive. You can assume the same baseline probability $P(H=1) = 0.0015$ as before.\n",
        "    1. Derive the probability that the patient is diseased ($H=1$) after both tests return positive.\n",
        "1. Assume that you are an asset manager for an investment bank and you have a choice of stocks $s_i$ to invest in. Your portfolio needs to add up to $1$ with weights $\\alpha_i$ for each stock. The stocks have an average return $\\boldsymbol{\\mu} = E_{\\mathbf{s} \\sim P}[\\mathbf{s}]$ and covariance $\\boldsymbol{\\Sigma} = \\textrm{Cov}_{\\mathbf{s} \\sim P}[\\mathbf{s}]$.\n",
        "    1. Compute the expected return for a given portfolio $\\boldsymbol{\\alpha}$.\n",
        "    1. If you wanted to maximize the return of the portfolio, how should you choose your investment?\n",
        "    1. Compute the *variance* of the portfolio.\n",
        "    1. Formulate an optimization problem of maximizing the return while keeping the variance constrained to an upper bound. This is the Nobel-Prize winning [Markovitz portfolio](https://en.wikipedia.org/wiki/Markowitz_model) :cite:`Mangram.2013`. To solve it you will need a quadratic programming solver, something way beyond the scope of this book.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "'''\n",
        "for an event with a deterministic or fixed outcome\n",
        ", observing more and more data will bring it to an arbitrarily low level\n",
        "'''\n",
        "#2\n",
        "'''\n",
        "any event with aleatoric uncertainty\n",
        "'''\n",
        "#3\n",
        "'''\n",
        "1.\n",
        "mean = [0.5, 0.5], assuming infinite examples. so variance = covariance matrix of [1, 0] - [0.5, 0.5].\n",
        "= [0.25, 0.25], [0.25, 0.25]\n",
        "the mean for less observations will not be 0.5 for both, it will be something like [0.4, 0.6]\n",
        "variance = covariant matrix of [1, 0] - [0.4, 0.6]\n",
        "= [0.16, 0.24], [0.24, 0.36]\n",
        "\n",
        "we can clearly see variance decreases with more samples.\n",
        "\n",
        "2.variance is 0.25, so stdev is 0.5, as per the previous part\n",
        "\n",
        "so draws lie +/- 0.5*sqrt(2) of the expectation\n",
        "\n",
        "3.central limit theorem tells us that we need atleast 30 samples for statistical significant\n",
        "this relates, as variance must go down to a certain point to be statistically significant\n",
        "'''\n",
        "\n",
        "#5\n",
        "'''\n",
        "the upper bound for the union is 1. the lower bound is also p(a) + p(b) - intersection p(a and b)\n",
        "the upper bound for the intersection is 1. the lower bound is zero, or independance.\n",
        "'''\n",
        "\n",
        "#6\n",
        "'''\n",
        "use the chain rule of probability, where you start from base and work up\n",
        "P(A, B, C) = P(A) * P(B|A) * P(C|A, B)\n",
        "however, as C is only dependent on B, we can simplify to:\n",
        "P(A) * P(B|A) * P(C| B)\n",
        "'''\n",
        "\n",
        "#7\n"
      ],
      "metadata": {
        "id": "zKrrk8DwwMop",
        "outputId": "6f743deb-23db-498d-d12f-ff5f239fb507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "id": "zKrrk8DwwMop",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nuse the chain rule of probability, where you start from base and work up\\nP(A, B, C) = P(A) * P(B|A) * P(C|A, B)\\nhowever, as C is only dependent on B, we can simplify to:\\nP(A) * P(B|A) * P(C| B)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "126c2b93",
      "metadata": {
        "origin_pos": 31,
        "tab": [
          "pytorch"
        ],
        "id": "126c2b93"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/37)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}